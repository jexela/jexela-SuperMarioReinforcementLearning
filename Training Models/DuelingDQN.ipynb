{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg-w9qRveWN0"
      },
      "source": [
        "Uninstall existing versions and install specific versions of gym and related packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fDVIyoBBUKL5",
        "outputId": "ba93214f-e8d8-4045-f149-a46e7c0925d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: gym 0.26.2\n",
            "Uninstalling gym-0.26.2:\n",
            "  Successfully uninstalled gym-0.26.2\n",
            "Found existing installation: gym-super-mario-bros 7.4.0\n",
            "Uninstalling gym-super-mario-bros-7.4.0:\n",
            "  Successfully uninstalled gym-super-mario-bros-7.4.0\n",
            "Collecting gym==0.26.2\n",
            "  Using cached gym-0.26.2-py3-none-any.whl\n",
            "Requirement already satisfied: gym-notices in /usr/local/lib/python3.10/dist-packages (0.0.8)\n",
            "Collecting gym-super-mario-bros==7.4.0\n",
            "  Using cached gym_super_mario_bros-7.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2) (3.1.0)\n",
            "Requirement already satisfied: nes-py>=8.1.4 in /usr/local/lib/python3.10/dist-packages (from gym-super-mario-bros==7.4.0) (8.2.1)\n",
            "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (1.5.21)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.4->gym-super-mario-bros==7.4.0) (4.66.5)\n",
            "Using cached gym_super_mario_bros-7.4.0-py3-none-any.whl (199 kB)\n",
            "Installing collected packages: gym, gym-super-mario-bros\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.9 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gym-0.26.2 gym-super-mario-bros-7.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gym",
                  "gym_super_mario_bros"
                ]
              },
              "id": "6653e7a83e13440cb2dcc906d2a57858"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: gym_super_mario_bros in /usr/local/lib/python3.10/dist-packages (7.4.0)\n",
            "Requirement already satisfied: nes_py in /usr/local/lib/python3.10/dist-packages (8.2.1)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.4.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (3.7.1)\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.10/dist-packages (from nes_py) (0.26.2)\n",
            "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from nes_py) (1.5.21)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from nes_py) (4.66.5)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes_py) (0.0.8)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2024.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y gym gym-super-mario-bros\n",
        "!pip install gym==0.26.2 gym-notices gym-super-mario-bros==7.4.0\n",
        "!pip install stable-baselines3 gym_super_mario_bros nes_py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMPPnJbLUabE"
      },
      "outputs": [],
      "source": [
        "# Importiere grundlegende Bibliotheken\n",
        "import gym\n",
        "import gym_super_mario_bros\n",
        "from gym.wrappers import FrameStack, GrayScaleObservation\n",
        "from gym.spaces import Box\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT\n",
        "\n",
        "# Importiere Bibliotheken für numerische Berechnungen und Deep Learning\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Importiere weitere Hilfsbibliotheken\n",
        "import random\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as T\n",
        "import time\n",
        "\n",
        "# Importiere Bibliotheken für die Interaktion mit Google Colab\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "768Y6ONnWT1X"
      },
      "source": [
        "Neural network definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6NekZkwWNWg"
      },
      "outputs": [],
      "source": [
        "#Dueling DQN Neural Network\n",
        "class DuelingDQN(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "        super(DuelingDQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "\n",
        "        # Compute the output size after convolutional layers\n",
        "        def conv2d_size_out(size, kernel_size, stride):\n",
        "            return (size - (kernel_size - 1) - 1) // stride + 1\n",
        "\n",
        "        conv_h = conv2d_size_out(conv2d_size_out(conv2d_size_out(input_shape[1], 8, 4), 4, 2), 3, 1)\n",
        "        conv_w = conv2d_size_out(conv2d_size_out(conv2d_size_out(input_shape[2], 8, 4), 4, 2), 3, 1)\n",
        "        linear_input_size = conv_w * conv_h * 64\n",
        "\n",
        "        self.fc1 = nn.Linear(linear_input_size, 512)\n",
        "\n",
        "        # Define the advantage and value streams\n",
        "        self.advantage_stream = nn.Linear(512, num_actions)\n",
        "        self.value_stream = nn.Linear(512, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = x / 255.0  # Normalize input\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.relu(self.conv3(x))\n",
        "        x = x.view(x.size(0), -1)  # flatten\n",
        "        x = torch.relu(self.fc1(x))\n",
        "\n",
        "        # Separate into advantage and value streams\n",
        "        advantage = self.advantage_stream(x)\n",
        "        value = self.value_stream(x)\n",
        "\n",
        "        # Combine advantage and value to get final Q values\n",
        "        q_values = value + (advantage - advantage.mean(dim=1, keepdim=True))\n",
        "        return q_values\n",
        "\n",
        "# class DuelingDQN(nn.Module):\n",
        "#     def __init__(self, input_shape, num_actions):\n",
        "#         super(DuelingDQN, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4)\n",
        "#         self.bn1 = nn.BatchNorm2d(32)  # Add BatchNorm after conv1\n",
        "\n",
        "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "#         self.bn2 = nn.BatchNorm2d(64)  # Add BatchNorm after conv2\n",
        "\n",
        "#         self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "#         self.bn3 = nn.BatchNorm2d(64)  # Add BatchNorm after conv3\n",
        "\n",
        "#         # Compute the output size after convolutional layers\n",
        "#         def conv2d_size_out(size, kernel_size, stride):\n",
        "#             return (size - (kernel_size - 1) - 1) // stride + 1\n",
        "\n",
        "#         conv_h = conv2d_size_out(conv2d_size_out(conv2d_size_out(input_shape[1], 8, 4), 4, 2), 3, 1)\n",
        "#         conv_w = conv2d_size_out(conv2d_size_out(conv2d_size_out(input_shape[2], 8, 4), 4, 2), 3, 1)\n",
        "#         linear_input_size = conv_w * conv_h * 64\n",
        "\n",
        "#         self.fc1 = nn.Linear(linear_input_size, 512)\n",
        "\n",
        "#         # Define the advantage and value streams\n",
        "#         self.advantage_stream = nn.Linear(512, num_actions)\n",
        "#         self.value_stream = nn.Linear(512, 1)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = x / 255.0  # Normalize input to [0, 1]\n",
        "\n",
        "#         # Apply convolutional layers with BatchNorm and ReLU activations\n",
        "#         x = F.relu(self.bn1(self.conv1(x)))\n",
        "#         x = F.relu(self.bn2(self.conv2(x)))\n",
        "#         x = F.relu(self.bn3(self.conv3(x)))\n",
        "\n",
        "#         x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "\n",
        "#         x = F.relu(self.fc1(x))\n",
        "\n",
        "#         # Separate into advantage and value streams\n",
        "#         advantage = self.advantage_stream(x)\n",
        "#         value = self.value_stream(x)\n",
        "\n",
        "#         # Combine advantage and value to get final Q-values\n",
        "#         q_values = value + (advantage - advantage.mean(dim=1, keepdim=True))\n",
        "#         return q_values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbsXWPGPW0Ss"
      },
      "source": [
        "Epsilon greedy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEoiVJ-XWzaO"
      },
      "outputs": [],
      "source": [
        "# Select action\n",
        "def select_action(state, epsilon):\n",
        "    if random.random() < epsilon:\n",
        "        action = env.action_space.sample()\n",
        "        return action\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            return policy_net(state).argmax().item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAmfCGCWW-AA"
      },
      "source": [
        "Preprocess wrappers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6LLd9maW6VM"
      },
      "outputs": [],
      "source": [
        "# Define Wrappers\n",
        "class SkipFrame(gym.Wrapper):\n",
        "    def __init__(self, env, skip):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        super().__init__(env)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Repeat action, and sum reward\"\"\"\n",
        "        total_reward = 0.0\n",
        "        for i in range(self._skip):\n",
        "            obs, reward, done, truncated, info = self.env.step(action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        return obs, total_reward, done, truncated, info\n",
        "\n",
        "class GrayScaleObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        obs_shape = self.observation_space.shape[:2]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def permute_orientation(self, observation):\n",
        "        observation = np.transpose(observation, (2, 0, 1))\n",
        "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
        "        return observation\n",
        "\n",
        "    def observation(self, observation):\n",
        "        observation = self.permute_orientation(observation)\n",
        "        transform = T.Grayscale()\n",
        "        observation = transform(observation)\n",
        "        return observation\n",
        "\n",
        "class ResizeObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env, shape):\n",
        "        super().__init__(env)\n",
        "        if isinstance(shape, int):\n",
        "            self.shape = (shape, shape)\n",
        "        else:\n",
        "            self.shape = tuple(shape)\n",
        "\n",
        "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
        "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        transforms = T.Compose(\n",
        "            [T.Resize(self.shape, antialias=True), T.Normalize(0, 255)]\n",
        "        )\n",
        "        observation = transforms(observation).squeeze(0)\n",
        "        return observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Vmi7jBXfbK"
      },
      "source": [
        "Environment configuration + hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uopQTfWXXwj",
        "outputId": "88c15a18-6c58-4ebc-dde8-a1ae36d421a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment SuperMarioBrosRandomStages-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Configure environment\n",
        "\n",
        "#env = gym_super_mario_bros.make('SuperMarioBros-v0', apply_api_compatibility=True, render_mode=\"none\")\n",
        "#env = gym_super_mario_bros.make('SuperMarioBrosRandomStages-v0', apply_api_compatibility=True, render_mode=\"none\")\n",
        "#env = gym_super_mario_bros.make('SuperMarioBrosRandomStages-v0', stages=['1-1'], apply_api_compatibility=True, render_mode=\"none\")\n",
        "env = gym_super_mario_bros.make('SuperMarioBrosRandomStages-v0', stages=['1-4'], apply_api_compatibility=True, render_mode=\"none\")\n",
        "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Apply Wrappers to environment\n",
        "env = SkipFrame(env, skip=4)\n",
        "env = GrayScaleObservation(env)\n",
        "env = ResizeObservation(env, shape=84)\n",
        "if gym.__version__ < '0.26':\n",
        "    env = FrameStack(env, num_stack=4, new_step_api=True)\n",
        "else:\n",
        "    env = FrameStack(env, num_stack=4)\n",
        "\n",
        "# Hyperparameters\n",
        "state_space = env.observation_space.shape  # (4, 84, 84)\n",
        "action_space = env.action_space.n\n",
        "learning_rate = 0.00015\n",
        "gamma = 0.99\n",
        "\n",
        "epsilon = 1.0\n",
        "epsilon_min = 0.02\n",
        "epsilon_decay = 0.99997\n",
        "batch_size = 32\n",
        "target_update = 20\n",
        "replayBuffer_size = 300000\n",
        "num_episodes = 50000\n",
        "start_learning = 0\n",
        "save_weights = 500\n",
        "step_count = 0\n",
        "\n",
        "\n",
        "# Moving average array\n",
        "moving_average = []\n",
        "\n",
        "# Replay Buffer\n",
        "replayBuffer = deque(maxlen=replayBuffer_size)\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate Q-networks\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "policy_net = DuelingDQN((4, 84, 84), action_space).to(device)  # Adjusted input shape to (4, 84, 84)\n",
        "target_net = DuelingDQN((4, 84, 84), action_space).to(device)  # Adjusted input shape to (4, 84, 84)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
        "#loss_fn = nn.MSELoss()\n",
        "loss_fn = nn.SmoothL1Loss()\n",
        "\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "# Training loop with evaluation\n",
        "training_rewards = []\n",
        "evaluation_rewards = []\n",
        "moving_average_training = []\n",
        "moving_average_evaluation = []\n",
        "min_training_rewards = []\n",
        "max_training_rewards = []\n",
        "min_moving_average_training = []\n",
        "max_moving_average_training = []\n",
        "min_moving_average_evaluation = []\n",
        "max_moving_average_evaluation = []\n",
        "\n",
        "start_episode = 23000\n",
        "step_count = 1379678\n",
        "epsilon = 0.02\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------Additional features-------------------------------\n",
        "\n",
        "# Reward adjustment parameters - Currently not in use\n",
        "# time_penalty = -1  # Time penalty for taking too long in the environment\n",
        "# position_penalty = -5  # Position penalty for moving backwards or losing ground\n",
        "\n",
        "# These parameters are commented out because we're experimenting without penalties.\n",
        "# If you want to reintroduce them, simply uncomment the lines above.\n",
        "\n",
        "# Reward adjustment logic - Currently commented out for testing purposes\n",
        "# Uncomment if you want to penalize standing still or time spent.\n",
        "\n",
        "# if next_info['time'] < time_last:\n",
        "#     reward += time_penalty  # Apply time penalty if agent takes too long\n",
        "#\n",
        "# if next_info['x_pos'] == x_pos_last:\n",
        "#     reward += position_penalty  # Apply penalty for not moving forward\n",
        "#     standing_still_counter += 1  # Count how long agent stands still\n",
        "# else:\n",
        "#     standing_still_counter = 0  # Reset the counter if the agent moves\n",
        "#\n",
        "# if standing_still_counter >= 4:\n",
        "#     reward += -10  # Additional penalty for standing still too long\n",
        "#\n",
        "# x_pos_last = next_info['x_pos']  # Update last known position\n",
        "# time_last = next_info['time']  # Update last known time\n",
        "\n",
        "# This logic is commented out because we're testing the behavior without time or position penalties.\n",
        "# To re-enable, simply uncomment the relevant lines above.\n"
      ],
      "metadata": {
        "id": "Zy5SLTpDrUQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQmNY4YaYBjd"
      },
      "source": [
        "Converts state to a contiguous PyTorch tensor, adds a batch dimension, and moves it to the specified device for neural network processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m03Ng1tiX_n5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf43b725-f6dc-48f2-f1b6-07a064d9122f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-0de6e5a10367>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  policy_net.load_state_dict(torch.load(policy_net_weights_path))\n",
            "<ipython-input-7-0de6e5a10367>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  target_net.load_state_dict(torch.load(target_net_weights_path))\n"
          ]
        }
      ],
      "source": [
        "# Preprocess state\n",
        "def preprocess_state(state):\n",
        "    state = np.ascontiguousarray(state)  # Remove negative strides\n",
        "    state = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    return state\n",
        "\n",
        "    # Load pretrained networks if necessary\n",
        "policy_net_weights_path = '/content/policy_net_weights.pth'\n",
        "target_net_weights_path = '/content/policy_net_weights.pth'\n",
        "\n",
        "policy_net.load_state_dict(torch.load(policy_net_weights_path))\n",
        "target_net.load_state_dict(torch.load(target_net_weights_path))\n",
        "\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Initialize log file\n",
        "\n",
        "file_path = \"training_log_dueling_14.txt\"\n",
        "if os.path.exists(file_path):\n",
        "    os.remove(file_path)\n",
        "\n",
        "with open(file_path, 'a') as file:\n",
        "    file.write(\"Episode,Total_Reward,Moving_Average,Episode_Length,Step_Count,Success\\n\")\n"
      ],
      "metadata": {
        "id": "h4rCvFhGAQtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvHGaqUdYOBW"
      },
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WYadVnwIVjS_",
        "outputId": "909d40f9-ac14-4b81-af9b-a555fbd61a01"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mDie letzten 5000 Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n",
            "Replay Buffer Memory: 300000, Episode Length: 881, Step Count: 3542923\n",
            "Moving Average (Training): 1595.68, Success: 1\n",
            "Episode: 39706, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3543124\n",
            "Moving Average (Training): 1605.86, Success: 1\n",
            "Episode: 39707, Total Reward: 2165.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3543325\n",
            "Moving Average (Training): 1605.64, Success: 1\n",
            "Episode: 39708, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3543514\n",
            "Moving Average (Training): 1605.1, Success: 0\n",
            "Episode: 39709, Total Reward: 1144.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3543622\n",
            "Moving Average (Training): 1594.69, Success: 0\n",
            "Episode: 39710, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3543824\n",
            "Moving Average (Training): 1594.79, Success: 1\n",
            "Episode: 39711, Total Reward: 2124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3544012\n",
            "Moving Average (Training): 1594.93, Success: 0\n",
            "Episode: 39712, Total Reward: 2125.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3544201\n",
            "Moving Average (Training): 1594.52, Success: 0\n",
            "Episode: 39713, Total Reward: 2088.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3544390\n",
            "Moving Average (Training): 1593.62, Success: 0\n",
            "Episode: 39714, Total Reward: 2136.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3544579\n",
            "Moving Average (Training): 1593.19, Success: 0\n",
            "Episode: 39715, Total Reward: 2189.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3544778\n",
            "Moving Average (Training): 1603.4, Success: 1\n",
            "Episode: 39716, Total Reward: 1136.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3544888\n",
            "Moving Average (Training): 1603.05, Success: 0\n",
            "Episode: 39717, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3545078\n",
            "Moving Average (Training): 1603.11, Success: 0\n",
            "Episode: 39718, Total Reward: 1132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3545192\n",
            "Moving Average (Training): 1592.56, Success: 0\n",
            "Episode: 39719, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3545385\n",
            "Moving Average (Training): 1607.19, Success: 0\n",
            "Episode: 39720, Total Reward: 2168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3545576\n",
            "Moving Average (Training): 1607.07, Success: 1\n",
            "Episode: 39721, Total Reward: 484.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 51, Step Count: 3545627\n",
            "Moving Average (Training): 1600.2, Success: 0\n",
            "Episode: 39722, Total Reward: 1153.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3545733\n",
            "Moving Average (Training): 1590.35, Success: 0\n",
            "Episode: 39723, Total Reward: 2157.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 239, Step Count: 3545972\n",
            "Moving Average (Training): 1590.78, Success: 1\n",
            "Episode: 39724, Total Reward: 492.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3546027\n",
            "Moving Average (Training): 1573.84, Success: 0\n",
            "Episode: 39725, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3546218\n",
            "Moving Average (Training): 1583.67, Success: 0\n",
            "Episode: 39726, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 206, Step Count: 3546424\n",
            "Moving Average (Training): 1593.52, Success: 0\n",
            "Episode: 39727, Total Reward: 2102.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3546622\n",
            "Moving Average (Training): 1603.12, Success: 0\n",
            "Episode: 39728, Total Reward: 2177.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 213, Step Count: 3546835\n",
            "Moving Average (Training): 1609.88, Success: 1\n",
            "Episode: 39729, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3547034\n",
            "Moving Average (Training): 1609.79, Success: 1\n",
            "Episode: 39730, Total Reward: 1866.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 182, Step Count: 3547216\n",
            "Moving Average (Training): 1621.43, Success: 0\n",
            "Episode: 39731, Total Reward: 1166.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3547323\n",
            "Moving Average (Training): 1618.08, Success: 0\n",
            "Episode: 39732, Total Reward: 2118.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 187, Step Count: 3547510\n",
            "Moving Average (Training): 1626.64, Success: 0\n",
            "Episode: 39733, Total Reward: 975.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 90, Step Count: 3547600\n",
            "Moving Average (Training): 1615.2, Success: 0\n",
            "Episode: 39734, Total Reward: 2160.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 227, Step Count: 3547827\n",
            "Moving Average (Training): 1614.93, Success: 1\n",
            "Episode: 39735, Total Reward: 975.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 92, Step Count: 3547919\n",
            "Moving Average (Training): 1613.0, Success: 0\n",
            "Episode: 39736, Total Reward: 676.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 64, Step Count: 3547983\n",
            "Moving Average (Training): 1608.32, Success: 0\n",
            "Episode: 39737, Total Reward: 1234.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3548096\n",
            "Moving Average (Training): 1618.97, Success: 0\n",
            "Episode: 39738, Total Reward: 1124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 117, Step Count: 3548213\n",
            "Moving Average (Training): 1626.31, Success: 0\n",
            "Episode: 39739, Total Reward: 2099.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 192, Step Count: 3548405\n",
            "Moving Average (Training): 1626.3, Success: 0\n",
            "Episode: 39740, Total Reward: 1216.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 117, Step Count: 3548522\n",
            "Moving Average (Training): 1626.29, Success: 0\n",
            "Episode: 39741, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3548713\n",
            "Moving Average (Training): 1625.77, Success: 0\n",
            "Episode: 39742, Total Reward: 2134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3548903\n",
            "Moving Average (Training): 1625.81, Success: 0\n",
            "Episode: 39743, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3549105\n",
            "Moving Average (Training): 1625.81, Success: 1\n",
            "Episode: 39744, Total Reward: 2176.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 215, Step Count: 3549320\n",
            "Moving Average (Training): 1632.52, Success: 1\n",
            "Episode: 39745, Total Reward: 2168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3549523\n",
            "Moving Average (Training): 1641.85, Success: 1\n",
            "Episode: 39746, Total Reward: 166.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 29, Step Count: 3549552\n",
            "Moving Average (Training): 1623.76, Success: 0\n",
            "Episode: 39747, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3549745\n",
            "Moving Average (Training): 1623.24, Success: 0\n",
            "Episode: 39748, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3549858\n",
            "Moving Average (Training): 1614.42, Success: 0\n",
            "Episode: 39749, Total Reward: 166.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3549886\n",
            "Moving Average (Training): 1594.77, Success: 0\n",
            "Episode: 39750, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3550076\n",
            "Moving Average (Training): 1594.85, Success: 0\n",
            "Episode: 39751, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3550188\n",
            "Moving Average (Training): 1595.59, Success: 0\n",
            "Episode: 39752, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3550295\n",
            "Moving Average (Training): 1588.3, Success: 0\n",
            "Episode: 39753, Total Reward: 2174.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 207, Step Count: 3550502\n",
            "Moving Average (Training): 1588.22, Success: 1\n",
            "Episode: 39754, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3550695\n",
            "Moving Average (Training): 1587.88, Success: 0\n",
            "Episode: 39755, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3550803\n",
            "Moving Average (Training): 1589.92, Success: 0\n",
            "Episode: 39756, Total Reward: 2095.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3551004\n",
            "Moving Average (Training): 1598.67, Success: 0\n",
            "Episode: 39757, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3551205\n",
            "Moving Average (Training): 1598.67, Success: 1\n",
            "Episode: 39758, Total Reward: 2073.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 769, Step Count: 3551974\n",
            "Moving Average (Training): 1598.08, Success: 1\n",
            "Episode: 39759, Total Reward: 1162.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3552086\n",
            "Moving Average (Training): 1587.83, Success: 0\n",
            "Episode: 39760, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3552197\n",
            "Moving Average (Training): 1588.6, Success: 0\n",
            "Episode: 39761, Total Reward: 1980.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 180, Step Count: 3552377\n",
            "Moving Average (Training): 1593.37, Success: 0\n",
            "Episode: 39762, Total Reward: 1221.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3552488\n",
            "Moving Average (Training): 1593.23, Success: 0\n",
            "Episode: 39763, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3552679\n",
            "Moving Average (Training): 1603.09, Success: 0\n",
            "Episode: 39764, Total Reward: 1129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3552793\n",
            "Moving Average (Training): 1593.6, Success: 0\n",
            "Episode: 39765, Total Reward: 1106.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 121, Step Count: 3552914\n",
            "Moving Average (Training): 1593.32, Success: 0\n",
            "Episode: 39766, Total Reward: 2102.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 194, Step Count: 3553108\n",
            "Moving Average (Training): 1593.01, Success: 0\n",
            "Episode: 39767, Total Reward: 1154.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3553214\n",
            "Moving Average (Training): 1583.29, Success: 0\n",
            "Episode: 39768, Total Reward: 1500.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 136, Step Count: 3553350\n",
            "Moving Average (Training): 1591.59, Success: 0\n",
            "Episode: 39769, Total Reward: 2113.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3553547\n",
            "Moving Average (Training): 1591.44, Success: 0\n",
            "Episode: 39770, Total Reward: 481.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 64, Step Count: 3553611\n",
            "Moving Average (Training): 1574.93, Success: 0\n",
            "Episode: 39771, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 187, Step Count: 3553798\n",
            "Moving Average (Training): 1584.98, Success: 0\n",
            "Episode: 39772, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3553999\n",
            "Moving Average (Training): 1595.16, Success: 1\n",
            "Episode: 39773, Total Reward: 1170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3554106\n",
            "Moving Average (Training): 1585.67, Success: 0\n",
            "Episode: 39774, Total Reward: 985.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 90, Step Count: 3554196\n",
            "Moving Average (Training): 1585.68, Success: 0\n",
            "Episode: 39775, Total Reward: 2103.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3554397\n",
            "Moving Average (Training): 1595.28, Success: 0\n",
            "Episode: 39776, Total Reward: 1128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3554511\n",
            "Moving Average (Training): 1594.86, Success: 0\n",
            "Episode: 39777, Total Reward: 2167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3554713\n",
            "Moving Average (Training): 1598.97, Success: 1\n",
            "Episode: 39778, Total Reward: 1506.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 147, Step Count: 3554860\n",
            "Moving Average (Training): 1602.61, Success: 0\n",
            "Episode: 39779, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3555051\n",
            "Moving Average (Training): 1602.63, Success: 0\n",
            "Episode: 39780, Total Reward: 2157.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 258, Step Count: 3555309\n",
            "Moving Average (Training): 1612.75, Success: 1\n",
            "Episode: 39781, Total Reward: 2125.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 236, Step Count: 3555545\n",
            "Moving Average (Training): 1627.18, Success: 0\n",
            "Episode: 39782, Total Reward: 1170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3555651\n",
            "Moving Average (Training): 1617.02, Success: 0\n",
            "Episode: 39783, Total Reward: 2170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3555855\n",
            "Moving Average (Training): 1631.86, Success: 1\n",
            "Episode: 39784, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3555967\n",
            "Moving Average (Training): 1632.79, Success: 0\n",
            "Episode: 39785, Total Reward: 2178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 216, Step Count: 3556183\n",
            "Moving Average (Training): 1632.82, Success: 1\n",
            "Episode: 39786, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3556371\n",
            "Moving Average (Training): 1632.21, Success: 0\n",
            "Episode: 39787, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3556561\n",
            "Moving Average (Training): 1649.67, Success: 0\n",
            "Episode: 39788, Total Reward: 1216.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3556677\n",
            "Moving Average (Training): 1640.04, Success: 0\n",
            "Episode: 39789, Total Reward: 390.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 48, Step Count: 3556725\n",
            "Moving Average (Training): 1622.24, Success: 0\n",
            "Episode: 39790, Total Reward: 2166.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3556926\n",
            "Moving Average (Training): 1642.2, Success: 1\n",
            "Episode: 39791, Total Reward: 171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3556954\n",
            "Moving Average (Training): 1622.06, Success: 0\n",
            "Episode: 39792, Total Reward: 1137.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3557066\n",
            "Moving Average (Training): 1612.23, Success: 0\n",
            "Episode: 39793, Total Reward: 2189.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 196, Step Count: 3557262\n",
            "Moving Average (Training): 1621.25, Success: 1\n",
            "Episode: 39794, Total Reward: 2170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 209, Step Count: 3557471\n",
            "Moving Average (Training): 1621.74, Success: 1\n",
            "Episode: 39795, Total Reward: 671.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 66, Step Count: 3557537\n",
            "Moving Average (Training): 1616.23, Success: 0\n",
            "Episode: 39796, Total Reward: 1135.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3557651\n",
            "Moving Average (Training): 1616.13, Success: 0\n",
            "Episode: 39797, Total Reward: 982.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 94, Step Count: 3557745\n",
            "Moving Average (Training): 1613.49, Success: 0\n",
            "Episode: 39798, Total Reward: 2185.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3557945\n",
            "Moving Average (Training): 1623.88, Success: 1\n",
            "Episode: 39799, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 235, Step Count: 3558180\n",
            "Moving Average (Training): 1634.21, Success: 1\n",
            "Episode: 39800, Total Reward: 1168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3558289\n",
            "Moving Average (Training): 1644.15, Success: 0\n",
            "Episode: 39801, Total Reward: 2117.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3558480\n",
            "Moving Average (Training): 1644.08, Success: 0\n",
            "Episode: 39802, Total Reward: 2134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3558679\n",
            "Moving Average (Training): 1660.56, Success: 0\n",
            "Episode: 39803, Total Reward: 165.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 32, Step Count: 3558711\n",
            "Moving Average (Training): 1640.52, Success: 0\n",
            "Episode: 39804, Total Reward: 666.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 73, Step Count: 3558784\n",
            "Moving Average (Training): 1635.73, Success: 0\n",
            "Episode: 39805, Total Reward: 2177.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 215, Step Count: 3558999\n",
            "Moving Average (Training): 1637.01, Success: 1\n",
            "Episode: 39806, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3559106\n",
            "Moving Average (Training): 1626.58, Success: 0\n",
            "Episode: 39807, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3559214\n",
            "Moving Average (Training): 1616.64, Success: 0\n",
            "Episode: 39808, Total Reward: 2136.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3559404\n",
            "Moving Average (Training): 1616.71, Success: 0\n",
            "Episode: 39809, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3559510\n",
            "Moving Average (Training): 1616.73, Success: 0\n",
            "Episode: 39810, Total Reward: 2135.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3559699\n",
            "Moving Average (Training): 1616.21, Success: 0\n",
            "Episode: 39811, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3559811\n",
            "Moving Average (Training): 1607.16, Success: 0\n",
            "Episode: 39812, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3559923\n",
            "Moving Average (Training): 1598.14, Success: 0\n",
            "Episode: 39813, Total Reward: 1125.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3560037\n",
            "Moving Average (Training): 1588.51, Success: 0\n",
            "Episode: 39814, Total Reward: 2116.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3560228\n",
            "Moving Average (Training): 1588.31, Success: 0\n",
            "Episode: 39815, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3560418\n",
            "Moving Average (Training): 1587.74, Success: 0\n",
            "Episode: 39816, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3560522\n",
            "Moving Average (Training): 1587.84, Success: 0\n",
            "Episode: 39817, Total Reward: 2126.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3560723\n",
            "Moving Average (Training): 1587.81, Success: 0\n",
            "Episode: 39818, Total Reward: 699.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 70, Step Count: 3560793\n",
            "Moving Average (Training): 1583.48, Success: 0\n",
            "Episode: 39819, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 57, Step Count: 3560850\n",
            "Moving Average (Training): 1567.0, Success: 0\n",
            "Episode: 39820, Total Reward: 2126.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3561052\n",
            "Moving Average (Training): 1566.58, Success: 0\n",
            "Episode: 39821, Total Reward: 2135.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3561240\n",
            "Moving Average (Training): 1583.09, Success: 0\n",
            "Episode: 39822, Total Reward: 2057.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 258, Step Count: 3561498\n",
            "Moving Average (Training): 1592.13, Success: 0\n",
            "Episode: 39823, Total Reward: 173.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3561526\n",
            "Moving Average (Training): 1572.29, Success: 0\n",
            "Episode: 39824, Total Reward: 1131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3561638\n",
            "Moving Average (Training): 1578.68, Success: 0\n",
            "Episode: 39825, Total Reward: 489.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 53, Step Count: 3561691\n",
            "Moving Average (Training): 1562.29, Success: 0\n",
            "Episode: 39826, Total Reward: 2084.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3561890\n",
            "Moving Average (Training): 1561.81, Success: 0\n",
            "Episode: 39827, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 103, Step Count: 3561993\n",
            "Moving Average (Training): 1552.24, Success: 0\n",
            "Episode: 39828, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3562098\n",
            "Moving Average (Training): 1541.92, Success: 0\n",
            "Episode: 39829, Total Reward: 2123.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3562291\n",
            "Moving Average (Training): 1541.35, Success: 0\n",
            "Episode: 39830, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3562489\n",
            "Moving Average (Training): 1544.57, Success: 1\n",
            "Episode: 39831, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3562678\n",
            "Moving Average (Training): 1554.2, Success: 0\n",
            "Episode: 39832, Total Reward: 2167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3562877\n",
            "Moving Average (Training): 1554.69, Success: 1\n",
            "Episode: 39833, Total Reward: 2163.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 220, Step Count: 3563097\n",
            "Moving Average (Training): 1566.57, Success: 1\n",
            "Episode: 39834, Total Reward: 487.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3563151\n",
            "Moving Average (Training): 1549.84, Success: 0\n",
            "Episode: 39835, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3563264\n",
            "Moving Average (Training): 1552.27, Success: 0\n",
            "Episode: 39836, Total Reward: 2165.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 209, Step Count: 3563473\n",
            "Moving Average (Training): 1567.16, Success: 1\n",
            "Episode: 39837, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 117, Step Count: 3563590\n",
            "Moving Average (Training): 1566.99, Success: 0\n",
            "Episode: 39838, Total Reward: 2126.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3563780\n",
            "Moving Average (Training): 1577.01, Success: 0\n",
            "Episode: 39839, Total Reward: 387.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 45, Step Count: 3563825\n",
            "Moving Average (Training): 1559.89, Success: 0\n",
            "Episode: 39840, Total Reward: 1135.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3563936\n",
            "Moving Average (Training): 1559.08, Success: 0\n",
            "Episode: 39841, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 118, Step Count: 3564054\n",
            "Moving Average (Training): 1549.96, Success: 0\n",
            "Episode: 39842, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3564167\n",
            "Moving Average (Training): 1540.8, Success: 0\n",
            "Episode: 39843, Total Reward: 2165.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3564368\n",
            "Moving Average (Training): 1540.66, Success: 1\n",
            "Episode: 39844, Total Reward: 989.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 93, Step Count: 3564461\n",
            "Moving Average (Training): 1528.79, Success: 0\n",
            "Episode: 39845, Total Reward: 1134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 118, Step Count: 3564579\n",
            "Moving Average (Training): 1518.45, Success: 0\n",
            "Episode: 39846, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3564684\n",
            "Moving Average (Training): 1528.24, Success: 0\n",
            "Episode: 39847, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3564874\n",
            "Moving Average (Training): 1528.28, Success: 0\n",
            "Episode: 39848, Total Reward: 2169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3565077\n",
            "Moving Average (Training): 1537.78, Success: 1\n",
            "Episode: 39849, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3565266\n",
            "Moving Average (Training): 1557.43, Success: 0\n",
            "Episode: 39850, Total Reward: 484.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 56, Step Count: 3565322\n",
            "Moving Average (Training): 1540.98, Success: 0\n",
            "Episode: 39851, Total Reward: 2113.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3565511\n",
            "Moving Average (Training): 1549.93, Success: 0\n",
            "Episode: 39852, Total Reward: 1173.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3565619\n",
            "Moving Average (Training): 1549.95, Success: 0\n",
            "Episode: 39853, Total Reward: 1157.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3565724\n",
            "Moving Average (Training): 1539.78, Success: 0\n",
            "Episode: 39854, Total Reward: 1222.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3565838\n",
            "Moving Average (Training): 1530.68, Success: 0\n",
            "Episode: 39855, Total Reward: 1170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3565946\n",
            "Moving Average (Training): 1530.67, Success: 0\n",
            "Episode: 39856, Total Reward: 1241.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 150, Step Count: 3566096\n",
            "Moving Average (Training): 1522.13, Success: 0\n",
            "Episode: 39857, Total Reward: 2118.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3566286\n",
            "Moving Average (Training): 1521.51, Success: 0\n",
            "Episode: 39858, Total Reward: 2168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 215, Step Count: 3566501\n",
            "Moving Average (Training): 1522.46, Success: 1\n",
            "Episode: 39859, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3566698\n",
            "Moving Average (Training): 1532.72, Success: 1\n",
            "Episode: 39860, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3566900\n",
            "Moving Average (Training): 1542.37, Success: 1\n",
            "Episode: 39861, Total Reward: 176.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 26, Step Count: 3566926\n",
            "Moving Average (Training): 1524.33, Success: 0\n",
            "Episode: 39862, Total Reward: 1140.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3567036\n",
            "Moving Average (Training): 1523.52, Success: 0\n",
            "Episode: 39863, Total Reward: 1150.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3567151\n",
            "Moving Average (Training): 1513.7, Success: 0\n",
            "Episode: 39864, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 117, Step Count: 3567268\n",
            "Moving Average (Training): 1514.59, Success: 0\n",
            "Episode: 39865, Total Reward: 671.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 67, Step Count: 3567335\n",
            "Moving Average (Training): 1510.24, Success: 0\n",
            "Episode: 39866, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3567536\n",
            "Moving Average (Training): 1511.01, Success: 1\n",
            "Episode: 39867, Total Reward: 2167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3567727\n",
            "Moving Average (Training): 1521.14, Success: 1\n",
            "Episode: 39868, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3567918\n",
            "Moving Average (Training): 1527.43, Success: 0\n",
            "Episode: 39869, Total Reward: 2126.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3568109\n",
            "Moving Average (Training): 1527.56, Success: 0\n",
            "Episode: 39870, Total Reward: 2183.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3568312\n",
            "Moving Average (Training): 1544.58, Success: 1\n",
            "Episode: 39871, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3568512\n",
            "Moving Average (Training): 1544.52, Success: 0\n",
            "Episode: 39872, Total Reward: 2113.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3568702\n",
            "Moving Average (Training): 1543.77, Success: 0\n",
            "Episode: 39873, Total Reward: 1147.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3568806\n",
            "Moving Average (Training): 1543.54, Success: 0\n",
            "Episode: 39874, Total Reward: 1915.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 1505, Step Count: 3570311\n",
            "Moving Average (Training): 1552.84, Success: 0\n",
            "Episode: 39875, Total Reward: 2186.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 196, Step Count: 3570507\n",
            "Moving Average (Training): 1553.67, Success: 1\n",
            "Episode: 39876, Total Reward: 2186.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 215, Step Count: 3570722\n",
            "Moving Average (Training): 1564.25, Success: 1\n",
            "Episode: 39877, Total Reward: 2166.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 192, Step Count: 3570914\n",
            "Moving Average (Training): 1564.24, Success: 1\n",
            "Episode: 39878, Total Reward: 1147.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3571018\n",
            "Moving Average (Training): 1560.65, Success: 0\n",
            "Episode: 39879, Total Reward: 2185.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3571219\n",
            "Moving Average (Training): 1561.2, Success: 1\n",
            "Episode: 39880, Total Reward: 2168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 209, Step Count: 3571428\n",
            "Moving Average (Training): 1561.31, Success: 1\n",
            "Episode: 39881, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3571631\n",
            "Moving Average (Training): 1561.86, Success: 1\n",
            "Episode: 39882, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3571824\n",
            "Moving Average (Training): 1571.46, Success: 0\n",
            "Episode: 39883, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3571930\n",
            "Moving Average (Training): 1561.47, Success: 0\n",
            "Episode: 39884, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3572119\n",
            "Moving Average (Training): 1570.61, Success: 0\n",
            "Episode: 39885, Total Reward: 1865.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 178, Step Count: 3572297\n",
            "Moving Average (Training): 1567.48, Success: 0\n",
            "Episode: 39886, Total Reward: 2110.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3572490\n",
            "Moving Average (Training): 1567.31, Success: 0\n",
            "Episode: 39887, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3572680\n",
            "Moving Average (Training): 1567.31, Success: 0\n",
            "Episode: 39888, Total Reward: 468.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3572735\n",
            "Moving Average (Training): 1559.83, Success: 0\n",
            "Episode: 39889, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 103, Step Count: 3572838\n",
            "Moving Average (Training): 1567.38, Success: 0\n",
            "Episode: 39890, Total Reward: 2178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3573040\n",
            "Moving Average (Training): 1567.5, Success: 1\n",
            "Episode: 39891, Total Reward: 2186.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 196, Step Count: 3573236\n",
            "Moving Average (Training): 1587.65, Success: 1\n",
            "Episode: 39892, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3573427\n",
            "Moving Average (Training): 1597.61, Success: 0\n",
            "Episode: 39893, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3573541\n",
            "Moving Average (Training): 1587.91, Success: 0\n",
            "Episode: 39894, Total Reward: 1245.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 119, Step Count: 3573660\n",
            "Moving Average (Training): 1578.66, Success: 0\n",
            "Episode: 39895, Total Reward: 1170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3573767\n",
            "Moving Average (Training): 1583.65, Success: 0\n",
            "Episode: 39896, Total Reward: 2124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 254, Step Count: 3574021\n",
            "Moving Average (Training): 1593.54, Success: 0\n",
            "Episode: 39897, Total Reward: 1221.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3574132\n",
            "Moving Average (Training): 1595.93, Success: 0\n",
            "Episode: 39898, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3574333\n",
            "Moving Average (Training): 1595.89, Success: 1\n",
            "Episode: 39899, Total Reward: 1169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3574441\n",
            "Moving Average (Training): 1585.79, Success: 0\n",
            "Episode: 39900, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3574644\n",
            "Moving Average (Training): 1595.98, Success: 1\n",
            "Episode: 39901, Total Reward: 1137.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3574757\n",
            "Moving Average (Training): 1586.18, Success: 0\n",
            "Episode: 39902, Total Reward: 2113.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3574948\n",
            "Moving Average (Training): 1585.97, Success: 0\n",
            "Episode: 39903, Total Reward: 370.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 40, Step Count: 3574988\n",
            "Moving Average (Training): 1588.02, Success: 0\n",
            "Episode: 39904, Total Reward: 1971.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 182, Step Count: 3575170\n",
            "Moving Average (Training): 1601.07, Success: 0\n",
            "Episode: 39905, Total Reward: 671.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 65, Step Count: 3575235\n",
            "Moving Average (Training): 1586.01, Success: 0\n",
            "Episode: 39906, Total Reward: 2160.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 221, Step Count: 3575456\n",
            "Moving Average (Training): 1596.16, Success: 1\n",
            "Episode: 39907, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3575660\n",
            "Moving Average (Training): 1606.25, Success: 1\n",
            "Episode: 39908, Total Reward: 2124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 206, Step Count: 3575866\n",
            "Moving Average (Training): 1606.13, Success: 0\n",
            "Episode: 39909, Total Reward: 172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3575894\n",
            "Moving Average (Training): 1596.39, Success: 0\n",
            "Episode: 39910, Total Reward: 176.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 26, Step Count: 3575920\n",
            "Moving Average (Training): 1576.8, Success: 0\n",
            "Episode: 39911, Total Reward: 2184.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3576120\n",
            "Moving Average (Training): 1586.45, Success: 1\n",
            "Episode: 39912, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3576310\n",
            "Moving Average (Training): 1595.51, Success: 0\n",
            "Episode: 39913, Total Reward: 1225.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3576422\n",
            "Moving Average (Training): 1596.51, Success: 0\n",
            "Episode: 39914, Total Reward: 694.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 65, Step Count: 3576487\n",
            "Moving Average (Training): 1582.29, Success: 0\n",
            "Episode: 39915, Total Reward: 1135.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3576599\n",
            "Moving Average (Training): 1572.32, Success: 0\n",
            "Episode: 39916, Total Reward: 679.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 70, Step Count: 3576669\n",
            "Moving Average (Training): 1567.65, Success: 0\n",
            "Episode: 39917, Total Reward: 2067.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 187, Step Count: 3576856\n",
            "Moving Average (Training): 1567.06, Success: 0\n",
            "Episode: 39918, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 187, Step Count: 3577043\n",
            "Moving Average (Training): 1581.39, Success: 0\n",
            "Episode: 39919, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3577234\n",
            "Moving Average (Training): 1597.86, Success: 0\n",
            "Episode: 39920, Total Reward: 2136.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3577424\n",
            "Moving Average (Training): 1597.96, Success: 0\n",
            "Episode: 39921, Total Reward: 1503.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 144, Step Count: 3577568\n",
            "Moving Average (Training): 1591.64, Success: 0\n",
            "Episode: 39922, Total Reward: 1974.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 179, Step Count: 3577747\n",
            "Moving Average (Training): 1590.81, Success: 0\n",
            "Episode: 39923, Total Reward: 2173.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 195, Step Count: 3577942\n",
            "Moving Average (Training): 1610.81, Success: 1\n",
            "Episode: 39924, Total Reward: 2136.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3578132\n",
            "Moving Average (Training): 1620.86, Success: 0\n",
            "Episode: 39925, Total Reward: 2136.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3578325\n",
            "Moving Average (Training): 1637.33, Success: 0\n",
            "Episode: 39926, Total Reward: 1877.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 178, Step Count: 3578503\n",
            "Moving Average (Training): 1635.26, Success: 0\n",
            "Episode: 39927, Total Reward: 1139.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3578616\n",
            "Moving Average (Training): 1635.2, Success: 0\n",
            "Episode: 39928, Total Reward: 977.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 89, Step Count: 3578705\n",
            "Moving Average (Training): 1633.52, Success: 0\n",
            "Episode: 39929, Total Reward: 2173.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 222, Step Count: 3578927\n",
            "Moving Average (Training): 1634.02, Success: 1\n",
            "Episode: 39930, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3579118\n",
            "Moving Average (Training): 1633.47, Success: 0\n",
            "Episode: 39931, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3579224\n",
            "Moving Average (Training): 1623.9, Success: 0\n",
            "Episode: 39932, Total Reward: 673.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 65, Step Count: 3579289\n",
            "Moving Average (Training): 1608.96, Success: 0\n",
            "Episode: 39933, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3579482\n",
            "Moving Average (Training): 1608.66, Success: 0\n",
            "Episode: 39934, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3579675\n",
            "Moving Average (Training): 1625.07, Success: 0\n",
            "Episode: 39935, Total Reward: 1239.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 117, Step Count: 3579792\n",
            "Moving Average (Training): 1625.28, Success: 0\n",
            "Episode: 39936, Total Reward: 2174.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 218, Step Count: 3580010\n",
            "Moving Average (Training): 1625.37, Success: 1\n",
            "Episode: 39937, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3580123\n",
            "Moving Average (Training): 1625.38, Success: 0\n",
            "Episode: 39938, Total Reward: 2126.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3580314\n",
            "Moving Average (Training): 1625.38, Success: 0\n",
            "Episode: 39939, Total Reward: 486.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3580369\n",
            "Moving Average (Training): 1626.37, Success: 0\n",
            "Episode: 39940, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3580475\n",
            "Moving Average (Training): 1626.74, Success: 0\n",
            "Episode: 39941, Total Reward: 1124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 119, Step Count: 3580594\n",
            "Moving Average (Training): 1625.81, Success: 0\n",
            "Episode: 39942, Total Reward: 2118.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3580797\n",
            "Moving Average (Training): 1634.81, Success: 0\n",
            "Episode: 39943, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3580998\n",
            "Moving Average (Training): 1634.95, Success: 1\n",
            "Episode: 39944, Total Reward: 391.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 60, Step Count: 3581058\n",
            "Moving Average (Training): 1628.97, Success: 0\n",
            "Episode: 39945, Total Reward: 167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 34, Step Count: 3581092\n",
            "Moving Average (Training): 1619.3, Success: 0\n",
            "Episode: 39946, Total Reward: 2182.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3581290\n",
            "Moving Average (Training): 1629.67, Success: 1\n",
            "Episode: 39947, Total Reward: 170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 27, Step Count: 3581317\n",
            "Moving Average (Training): 1610.04, Success: 0\n",
            "Episode: 39948, Total Reward: 975.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 100, Step Count: 3581417\n",
            "Moving Average (Training): 1598.1, Success: 0\n",
            "Episode: 39949, Total Reward: 2183.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3581618\n",
            "Moving Average (Training): 1598.62, Success: 1\n",
            "Episode: 39950, Total Reward: 2183.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3581822\n",
            "Moving Average (Training): 1615.61, Success: 1\n",
            "Episode: 39951, Total Reward: 2169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 232, Step Count: 3582054\n",
            "Moving Average (Training): 1616.17, Success: 1\n",
            "Episode: 39952, Total Reward: 490.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 57, Step Count: 3582111\n",
            "Moving Average (Training): 1609.34, Success: 0\n",
            "Episode: 39953, Total Reward: 1138.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3582223\n",
            "Moving Average (Training): 1609.15, Success: 0\n",
            "Episode: 39954, Total Reward: 1500.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 141, Step Count: 3582364\n",
            "Moving Average (Training): 1611.93, Success: 0\n",
            "Episode: 39955, Total Reward: 677.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 65, Step Count: 3582429\n",
            "Moving Average (Training): 1607.0, Success: 0\n",
            "Episode: 39956, Total Reward: 1138.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3582540\n",
            "Moving Average (Training): 1605.97, Success: 0\n",
            "Episode: 39957, Total Reward: 492.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 56, Step Count: 3582596\n",
            "Moving Average (Training): 1589.71, Success: 0\n",
            "Episode: 39958, Total Reward: 1158.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3582702\n",
            "Moving Average (Training): 1579.61, Success: 0\n",
            "Episode: 39959, Total Reward: 2134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3582892\n",
            "Moving Average (Training): 1579.07, Success: 0\n",
            "Episode: 39960, Total Reward: 1129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3583006\n",
            "Moving Average (Training): 1568.48, Success: 0\n",
            "Episode: 39961, Total Reward: 1220.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3583118\n",
            "Moving Average (Training): 1578.92, Success: 0\n",
            "Episode: 39962, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3583308\n",
            "Moving Average (Training): 1588.83, Success: 0\n",
            "Episode: 39963, Total Reward: 2157.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 248, Step Count: 3583556\n",
            "Moving Average (Training): 1598.9, Success: 1\n",
            "Episode: 39964, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3583670\n",
            "Moving Average (Training): 1598.91, Success: 0\n",
            "Episode: 39965, Total Reward: 2036.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 960, Step Count: 3584630\n",
            "Moving Average (Training): 1612.56, Success: 1\n",
            "Episode: 39966, Total Reward: 693.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 65, Step Count: 3584695\n",
            "Moving Average (Training): 1597.7, Success: 0\n",
            "Episode: 39967, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 187, Step Count: 3584882\n",
            "Moving Average (Training): 1597.32, Success: 0\n",
            "Episode: 39968, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 209, Step Count: 3585091\n",
            "Moving Average (Training): 1597.82, Success: 1\n",
            "Episode: 39969, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3585205\n",
            "Moving Average (Training): 1588.75, Success: 0\n",
            "Episode: 39970, Total Reward: 1147.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3585309\n",
            "Moving Average (Training): 1578.39, Success: 0\n",
            "Episode: 39971, Total Reward: 671.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 68, Step Count: 3585377\n",
            "Moving Average (Training): 1563.83, Success: 0\n",
            "Episode: 39972, Total Reward: 976.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 92, Step Count: 3585469\n",
            "Moving Average (Training): 1552.46, Success: 0\n",
            "Episode: 39973, Total Reward: 2168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3585671\n",
            "Moving Average (Training): 1562.67, Success: 1\n",
            "Episode: 39974, Total Reward: 2116.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3585860\n",
            "Moving Average (Training): 1564.68, Success: 0\n",
            "Episode: 39975, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3586053\n",
            "Moving Average (Training): 1564.14, Success: 0\n",
            "Episode: 39976, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3586256\n",
            "Moving Average (Training): 1563.58, Success: 0\n",
            "Episode: 39977, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 118, Step Count: 3586374\n",
            "Moving Average (Training): 1554.1, Success: 0\n",
            "Episode: 39978, Total Reward: 1169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3586482\n",
            "Moving Average (Training): 1554.32, Success: 0\n",
            "Episode: 39979, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3586590\n",
            "Moving Average (Training): 1544.19, Success: 0\n",
            "Episode: 39980, Total Reward: 2134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3586779\n",
            "Moving Average (Training): 1543.85, Success: 0\n",
            "Episode: 39981, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3586967\n",
            "Moving Average (Training): 1543.33, Success: 0\n",
            "Episode: 39982, Total Reward: 1167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3587075\n",
            "Moving Average (Training): 1533.7, Success: 0\n",
            "Episode: 39983, Total Reward: 1141.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3587190\n",
            "Moving Average (Training): 1533.4, Success: 0\n",
            "Episode: 39984, Total Reward: 2163.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 214, Step Count: 3587404\n",
            "Moving Average (Training): 1533.72, Success: 1\n",
            "Episode: 39985, Total Reward: 170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3587432\n",
            "Moving Average (Training): 1516.77, Success: 0\n",
            "Episode: 39986, Total Reward: 2174.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 259, Step Count: 3587691\n",
            "Moving Average (Training): 1517.41, Success: 1\n",
            "Episode: 39987, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3587795\n",
            "Moving Average (Training): 1507.57, Success: 0\n",
            "Episode: 39988, Total Reward: 2183.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3587994\n",
            "Moving Average (Training): 1524.72, Success: 1\n",
            "Episode: 39989, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3588099\n",
            "Moving Average (Training): 1524.73, Success: 0\n",
            "Episode: 39990, Total Reward: 179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3588127\n",
            "Moving Average (Training): 1504.74, Success: 0\n",
            "Episode: 39991, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3588330\n",
            "Moving Average (Training): 1504.68, Success: 1\n",
            "Episode: 39992, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3588441\n",
            "Moving Average (Training): 1495.53, Success: 0\n",
            "Episode: 39993, Total Reward: 2125.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3588641\n",
            "Moving Average (Training): 1504.59, Success: 0\n",
            "Episode: 39994, Total Reward: 158.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3588669\n",
            "Moving Average (Training): 1493.72, Success: 0\n",
            "Episode: 39995, Total Reward: 1128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3588783\n",
            "Moving Average (Training): 1493.3, Success: 0\n",
            "Episode: 39996, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3588972\n",
            "Moving Average (Training): 1493.37, Success: 0\n",
            "Episode: 39997, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3589078\n",
            "Moving Average (Training): 1492.87, Success: 0\n",
            "Episode: 39998, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3589282\n",
            "Moving Average (Training): 1492.87, Success: 1\n",
            "Episode: 39999, Total Reward: 2186.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3589483\n",
            "Moving Average (Training): 1503.04, Success: 1\n",
            "Episode: 40000, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 210, Step Count: 3589693\n",
            "Moving Average (Training): 1502.47, Success: 0\n",
            "Episode: 40001, Total Reward: 491.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 57, Step Count: 3589750\n",
            "Moving Average (Training): 1496.01, Success: 0\n",
            "Episode: 40002, Total Reward: 981.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 91, Step Count: 3589841\n",
            "Moving Average (Training): 1484.69, Success: 0\n",
            "Episode: 40003, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3590043\n",
            "Moving Average (Training): 1502.87, Success: 1\n",
            "Episode: 40004, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 196, Step Count: 3590239\n",
            "Moving Average (Training): 1504.96, Success: 1\n",
            "Episode: 40005, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 206, Step Count: 3590445\n",
            "Moving Average (Training): 1519.52, Success: 0\n",
            "Episode: 40006, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3590559\n",
            "Moving Average (Training): 1510.1, Success: 0\n",
            "Episode: 40007, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3590752\n",
            "Moving Average (Training): 1509.59, Success: 0\n",
            "Episode: 40008, Total Reward: 2134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3590943\n",
            "Moving Average (Training): 1509.69, Success: 0\n",
            "Episode: 40009, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3591049\n",
            "Moving Average (Training): 1519.42, Success: 0\n",
            "Episode: 40010, Total Reward: 968.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 88, Step Count: 3591137\n",
            "Moving Average (Training): 1527.34, Success: 0\n",
            "Episode: 40011, Total Reward: 1360.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 127, Step Count: 3591264\n",
            "Moving Average (Training): 1519.1, Success: 0\n",
            "Episode: 40012, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3591375\n",
            "Moving Average (Training): 1510.0, Success: 0\n",
            "Episode: 40013, Total Reward: 2146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 412, Step Count: 3591787\n",
            "Moving Average (Training): 1519.21, Success: 1\n",
            "Episode: 40014, Total Reward: 957.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 91, Step Count: 3591878\n",
            "Moving Average (Training): 1521.84, Success: 0\n",
            "Episode: 40015, Total Reward: 969.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 90, Step Count: 3591968\n",
            "Moving Average (Training): 1520.18, Success: 0\n",
            "Episode: 40016, Total Reward: 1168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3592078\n",
            "Moving Average (Training): 1525.07, Success: 0\n",
            "Episode: 40017, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3592269\n",
            "Moving Average (Training): 1525.69, Success: 0\n",
            "Episode: 40018, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3592460\n",
            "Moving Average (Training): 1525.65, Success: 0\n",
            "Episode: 40019, Total Reward: 1167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3592573\n",
            "Moving Average (Training): 1516.0, Success: 0\n",
            "Episode: 40020, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3592770\n",
            "Moving Average (Training): 1516.52, Success: 1\n",
            "Episode: 40021, Total Reward: 1169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3592877\n",
            "Moving Average (Training): 1513.18, Success: 0\n",
            "Episode: 40022, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3593082\n",
            "Moving Average (Training): 1515.25, Success: 1\n",
            "Episode: 40023, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3593189\n",
            "Moving Average (Training): 1505.24, Success: 0\n",
            "Episode: 40024, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3593303\n",
            "Moving Average (Training): 1496.06, Success: 0\n",
            "Episode: 40025, Total Reward: 2118.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 210, Step Count: 3593513\n",
            "Moving Average (Training): 1495.88, Success: 0\n",
            "Episode: 40026, Total Reward: 2174.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3593715\n",
            "Moving Average (Training): 1498.85, Success: 1\n",
            "Episode: 40027, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3593918\n",
            "Moving Average (Training): 1509.34, Success: 1\n",
            "Episode: 40028, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3594109\n",
            "Moving Average (Training): 1520.86, Success: 0\n",
            "Episode: 40029, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3594300\n",
            "Moving Average (Training): 1520.41, Success: 0\n",
            "Episode: 40030, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3594488\n",
            "Moving Average (Training): 1520.38, Success: 0\n",
            "Episode: 40031, Total Reward: 1131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3594602\n",
            "Moving Average (Training): 1519.97, Success: 0\n",
            "Episode: 40032, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3594713\n",
            "Moving Average (Training): 1525.43, Success: 0\n",
            "Episode: 40033, Total Reward: 683.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 67, Step Count: 3594780\n",
            "Moving Average (Training): 1510.93, Success: 0\n",
            "Episode: 40034, Total Reward: 1235.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3594892\n",
            "Moving Average (Training): 1502.0, Success: 0\n",
            "Episode: 40035, Total Reward: 179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3594920\n",
            "Moving Average (Training): 1491.4, Success: 0\n",
            "Episode: 40036, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3595030\n",
            "Moving Average (Training): 1481.84, Success: 0\n",
            "Episode: 40037, Total Reward: 169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 29, Step Count: 3595059\n",
            "Moving Average (Training): 1471.35, Success: 0\n",
            "Episode: 40038, Total Reward: 2185.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 206, Step Count: 3595265\n",
            "Moving Average (Training): 1471.94, Success: 1\n",
            "Episode: 40039, Total Reward: 375.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 46, Step Count: 3595311\n",
            "Moving Average (Training): 1470.83, Success: 0\n",
            "Episode: 40040, Total Reward: 1506.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 138, Step Count: 3595449\n",
            "Moving Average (Training): 1474.17, Success: 0\n",
            "Episode: 40041, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3595650\n",
            "Moving Average (Training): 1484.8, Success: 1\n",
            "Episode: 40042, Total Reward: 1865.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 176, Step Count: 3595826\n",
            "Moving Average (Training): 1482.27, Success: 0\n",
            "Episode: 40043, Total Reward: 484.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 58, Step Count: 3595884\n",
            "Moving Average (Training): 1465.32, Success: 0\n",
            "Episode: 40044, Total Reward: 1137.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3595996\n",
            "Moving Average (Training): 1472.78, Success: 0\n",
            "Episode: 40045, Total Reward: 1245.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 152, Step Count: 3596148\n",
            "Moving Average (Training): 1483.56, Success: 0\n",
            "Episode: 40046, Total Reward: 2164.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3596351\n",
            "Moving Average (Training): 1483.38, Success: 1\n",
            "Episode: 40047, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3596466\n",
            "Moving Average (Training): 1493.86, Success: 0\n",
            "Episode: 40048, Total Reward: 2182.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3596657\n",
            "Moving Average (Training): 1505.93, Success: 1\n",
            "Episode: 40049, Total Reward: 2168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3596848\n",
            "Moving Average (Training): 1505.78, Success: 1\n",
            "Episode: 40050, Total Reward: 2178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 211, Step Count: 3597059\n",
            "Moving Average (Training): 1505.73, Success: 1\n",
            "Episode: 40051, Total Reward: 2012.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 1064, Step Count: 3598123\n",
            "Moving Average (Training): 1504.16, Success: 1\n",
            "Episode: 40052, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3598323\n",
            "Moving Average (Training): 1521.06, Success: 1\n",
            "Episode: 40053, Total Reward: 1505.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 140, Step Count: 3598463\n",
            "Moving Average (Training): 1524.73, Success: 0\n",
            "Episode: 40054, Total Reward: 2182.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 209, Step Count: 3598672\n",
            "Moving Average (Training): 1531.55, Success: 1\n",
            "Episode: 40055, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3598875\n",
            "Moving Average (Training): 1546.11, Success: 0\n",
            "Episode: 40056, Total Reward: 1981.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 175, Step Count: 3599050\n",
            "Moving Average (Training): 1554.54, Success: 0\n",
            "Episode: 40057, Total Reward: 2124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3599247\n",
            "Moving Average (Training): 1570.86, Success: 0\n",
            "Episode: 40058, Total Reward: 1903.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 175, Step Count: 3599422\n",
            "Moving Average (Training): 1578.31, Success: 0\n",
            "Episode: 40059, Total Reward: 1164.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3599534\n",
            "Moving Average (Training): 1568.61, Success: 0\n",
            "Episode: 40060, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3599724\n",
            "Moving Average (Training): 1578.63, Success: 0\n",
            "Episode: 40061, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3599837\n",
            "Moving Average (Training): 1578.61, Success: 0\n",
            "Episode: 40062, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3599950\n",
            "Moving Average (Training): 1569.47, Success: 0\n",
            "Episode: 40063, Total Reward: 981.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 92, Step Count: 3600042\n",
            "Moving Average (Training): 1557.71, Success: 0\n",
            "Episode: 40064, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3600242\n",
            "Moving Average (Training): 1567.4, Success: 1\n",
            "Episode: 40065, Total Reward: 706.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 68, Step Count: 3600310\n",
            "Moving Average (Training): 1554.1, Success: 0\n",
            "Episode: 40066, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3600501\n",
            "Moving Average (Training): 1568.44, Success: 0\n",
            "Episode: 40067, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3600691\n",
            "Moving Average (Training): 1568.43, Success: 0\n",
            "Episode: 40068, Total Reward: 2167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 214, Step Count: 3600905\n",
            "Moving Average (Training): 1568.31, Success: 1\n",
            "Episode: 40069, Total Reward: 493.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 52, Step Count: 3600957\n",
            "Moving Average (Training): 1561.05, Success: 0\n",
            "Episode: 40070, Total Reward: 2074.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 241, Step Count: 3601198\n",
            "Moving Average (Training): 1570.32, Success: 0\n",
            "Episode: 40071, Total Reward: 1168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3601306\n",
            "Moving Average (Training): 1575.29, Success: 0\n",
            "Episode: 40072, Total Reward: 2097.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 196, Step Count: 3601502\n",
            "Moving Average (Training): 1586.5, Success: 0\n",
            "Episode: 40073, Total Reward: 1138.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 118, Step Count: 3601620\n",
            "Moving Average (Training): 1576.2, Success: 0\n",
            "Episode: 40074, Total Reward: 974.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 97, Step Count: 3601717\n",
            "Moving Average (Training): 1564.78, Success: 0\n",
            "Episode: 40075, Total Reward: 1222.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3601830\n",
            "Moving Average (Training): 1555.68, Success: 0\n",
            "Episode: 40076, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3602034\n",
            "Moving Average (Training): 1556.18, Success: 1\n",
            "Episode: 40077, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3602224\n",
            "Moving Average (Training): 1565.31, Success: 0\n",
            "Episode: 40078, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3602417\n",
            "Moving Average (Training): 1574.91, Success: 0\n",
            "Episode: 40079, Total Reward: 1137.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3602528\n",
            "Moving Average (Training): 1574.56, Success: 0\n",
            "Episode: 40080, Total Reward: 481.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3602583\n",
            "Moving Average (Training): 1558.03, Success: 0\n",
            "Episode: 40081, Total Reward: 2169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3602773\n",
            "Moving Average (Training): 1558.44, Success: 1\n",
            "Episode: 40082, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 245, Step Count: 3603018\n",
            "Moving Average (Training): 1568.56, Success: 1\n",
            "Episode: 40083, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3603125\n",
            "Moving Average (Training): 1568.61, Success: 0\n",
            "Episode: 40084, Total Reward: 479.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 63, Step Count: 3603188\n",
            "Moving Average (Training): 1551.77, Success: 0\n",
            "Episode: 40085, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3603379\n",
            "Moving Average (Training): 1571.34, Success: 0\n",
            "Episode: 40086, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3603572\n",
            "Moving Average (Training): 1570.9, Success: 0\n",
            "Episode: 40087, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 210, Step Count: 3603782\n",
            "Moving Average (Training): 1581.23, Success: 1\n",
            "Episode: 40088, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3603972\n",
            "Moving Average (Training): 1580.69, Success: 0\n",
            "Episode: 40089, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3604079\n",
            "Moving Average (Training): 1580.94, Success: 0\n",
            "Episode: 40090, Total Reward: 2165.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3604277\n",
            "Moving Average (Training): 1600.8, Success: 1\n",
            "Episode: 40091, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3604389\n",
            "Moving Average (Training): 1591.18, Success: 0\n",
            "Episode: 40092, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3604577\n",
            "Moving Average (Training): 1600.33, Success: 0\n",
            "Episode: 40093, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3604780\n",
            "Moving Average (Training): 1600.88, Success: 1\n",
            "Episode: 40094, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3604982\n",
            "Moving Average (Training): 1621.09, Success: 1\n",
            "Episode: 40095, Total Reward: 702.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 68, Step Count: 3605050\n",
            "Moving Average (Training): 1616.83, Success: 0\n",
            "Episode: 40096, Total Reward: 1237.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3605161\n",
            "Moving Average (Training): 1607.89, Success: 0\n",
            "Episode: 40097, Total Reward: 2115.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3605351\n",
            "Moving Average (Training): 1617.33, Success: 0\n",
            "Episode: 40098, Total Reward: 2178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 223, Step Count: 3605574\n",
            "Moving Average (Training): 1617.3, Success: 1\n",
            "Episode: 40099, Total Reward: 2125.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3605767\n",
            "Moving Average (Training): 1616.69, Success: 0\n",
            "Episode: 40100, Total Reward: 687.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 69, Step Count: 3605836\n",
            "Moving Average (Training): 1602.26, Success: 0\n",
            "Episode: 40101, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3606037\n",
            "Moving Average (Training): 1619.23, Success: 1\n",
            "Episode: 40102, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3606151\n",
            "Moving Average (Training): 1621.59, Success: 0\n",
            "Episode: 40103, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3606257\n",
            "Moving Average (Training): 1611.43, Success: 0\n",
            "Episode: 40104, Total Reward: 2185.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 208, Step Count: 3606465\n",
            "Moving Average (Training): 1611.48, Success: 1\n",
            "Episode: 40105, Total Reward: 1278.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 137, Step Count: 3606602\n",
            "Moving Average (Training): 1602.99, Success: 0\n",
            "Episode: 40106, Total Reward: 672.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 69, Step Count: 3606671\n",
            "Moving Average (Training): 1597.53, Success: 0\n",
            "Episode: 40107, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 207, Step Count: 3606878\n",
            "Moving Average (Training): 1598.04, Success: 1\n",
            "Episode: 40108, Total Reward: 2097.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 298, Step Count: 3607176\n",
            "Moving Average (Training): 1597.67, Success: 0\n",
            "Episode: 40109, Total Reward: 2135.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3607373\n",
            "Moving Average (Training): 1607.57, Success: 0\n",
            "Episode: 40110, Total Reward: 2177.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3607576\n",
            "Moving Average (Training): 1619.66, Success: 1\n",
            "Episode: 40111, Total Reward: 672.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 65, Step Count: 3607641\n",
            "Moving Average (Training): 1612.78, Success: 0\n",
            "Episode: 40112, Total Reward: 1152.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3607757\n",
            "Moving Average (Training): 1612.11, Success: 0\n",
            "Episode: 40113, Total Reward: 483.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 57, Step Count: 3607814\n",
            "Moving Average (Training): 1595.48, Success: 0\n",
            "Episode: 40114, Total Reward: 2104.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 273, Step Count: 3608087\n",
            "Moving Average (Training): 1606.95, Success: 0\n",
            "Episode: 40115, Total Reward: 989.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 95, Step Count: 3608182\n",
            "Moving Average (Training): 1607.15, Success: 0\n",
            "Episode: 40116, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3608290\n",
            "Moving Average (Training): 1607.18, Success: 0\n",
            "Episode: 40117, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3608479\n",
            "Moving Average (Training): 1607.21, Success: 0\n",
            "Episode: 40118, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3608672\n",
            "Moving Average (Training): 1607.26, Success: 0\n",
            "Episode: 40119, Total Reward: 2182.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 231, Step Count: 3608903\n",
            "Moving Average (Training): 1617.41, Success: 1\n",
            "Episode: 40120, Total Reward: 2123.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3609100\n",
            "Moving Average (Training): 1616.76, Success: 0\n",
            "Episode: 40121, Total Reward: 172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 27, Step Count: 3609127\n",
            "Moving Average (Training): 1606.79, Success: 0\n",
            "Episode: 40122, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3609329\n",
            "Moving Average (Training): 1606.85, Success: 1\n",
            "Episode: 40123, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3609440\n",
            "Moving Average (Training): 1607.36, Success: 0\n",
            "Episode: 40124, Total Reward: 2189.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 196, Step Count: 3609636\n",
            "Moving Average (Training): 1617.07, Success: 1\n",
            "Episode: 40125, Total Reward: 696.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 68, Step Count: 3609704\n",
            "Moving Average (Training): 1602.85, Success: 0\n",
            "Episode: 40126, Total Reward: 1111.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 123, Step Count: 3609827\n",
            "Moving Average (Training): 1592.22, Success: 0\n",
            "Episode: 40127, Total Reward: 699.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 66, Step Count: 3609893\n",
            "Moving Average (Training): 1577.33, Success: 0\n",
            "Episode: 40128, Total Reward: 173.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3609921\n",
            "Moving Average (Training): 1557.77, Success: 0\n",
            "Episode: 40129, Total Reward: 1251.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 121, Step Count: 3610042\n",
            "Moving Average (Training): 1549.0, Success: 0\n",
            "Episode: 40130, Total Reward: 1169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3610150\n",
            "Moving Average (Training): 1539.39, Success: 0\n",
            "Episode: 40131, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3610350\n",
            "Moving Average (Training): 1549.96, Success: 1\n",
            "Episode: 40132, Total Reward: 2189.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3610549\n",
            "Moving Average (Training): 1559.66, Success: 1\n",
            "Episode: 40133, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3610750\n",
            "Moving Average (Training): 1574.7, Success: 1\n",
            "Episode: 40134, Total Reward: 1105.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 124, Step Count: 3610874\n",
            "Moving Average (Training): 1573.4, Success: 0\n",
            "Episode: 40135, Total Reward: 2189.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3611073\n",
            "Moving Average (Training): 1593.5, Success: 1\n",
            "Episode: 40136, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3611272\n",
            "Moving Average (Training): 1603.2, Success: 1\n",
            "Episode: 40137, Total Reward: 976.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 99, Step Count: 3611371\n",
            "Moving Average (Training): 1611.27, Success: 0\n",
            "Episode: 40138, Total Reward: 2068.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 186, Step Count: 3611557\n",
            "Moving Average (Training): 1610.1, Success: 0\n",
            "Episode: 40139, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3611754\n",
            "Moving Average (Training): 1627.65, Success: 0\n",
            "Episode: 40140, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3611942\n",
            "Moving Average (Training): 1633.88, Success: 0\n",
            "Episode: 40141, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3612143\n",
            "Moving Average (Training): 1633.82, Success: 1\n",
            "Episode: 40142, Total Reward: 373.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 40, Step Count: 3612183\n",
            "Moving Average (Training): 1618.9, Success: 0\n",
            "Episode: 40143, Total Reward: 2172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3612385\n",
            "Moving Average (Training): 1635.78, Success: 1\n",
            "Episode: 40144, Total Reward: 370.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 50, Step Count: 3612435\n",
            "Moving Average (Training): 1628.11, Success: 0\n",
            "Episode: 40145, Total Reward: 2189.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3612635\n",
            "Moving Average (Training): 1637.55, Success: 1\n",
            "Episode: 40146, Total Reward: 2183.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 206, Step Count: 3612841\n",
            "Moving Average (Training): 1637.74, Success: 1\n",
            "Episode: 40147, Total Reward: 483.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 58, Step Count: 3612899\n",
            "Moving Average (Training): 1630.39, Success: 0\n",
            "Episode: 40148, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3613097\n",
            "Moving Average (Training): 1630.45, Success: 1\n",
            "Episode: 40149, Total Reward: 2175.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 229, Step Count: 3613326\n",
            "Moving Average (Training): 1630.52, Success: 1\n",
            "Episode: 40150, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3613515\n",
            "Moving Average (Training): 1630.03, Success: 0\n",
            "Episode: 40151, Total Reward: 2169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3613715\n",
            "Moving Average (Training): 1631.6, Success: 1\n",
            "Episode: 40152, Total Reward: 2184.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 212, Step Count: 3613927\n",
            "Moving Average (Training): 1631.64, Success: 1\n",
            "Episode: 40153, Total Reward: 1221.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3614040\n",
            "Moving Average (Training): 1628.8, Success: 0\n",
            "Episode: 40154, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3614240\n",
            "Moving Average (Training): 1628.78, Success: 1\n",
            "Episode: 40155, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3614353\n",
            "Moving Average (Training): 1619.63, Success: 0\n",
            "Episode: 40156, Total Reward: 169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3614381\n",
            "Moving Average (Training): 1601.51, Success: 0\n",
            "Episode: 40157, Total Reward: 985.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 93, Step Count: 3614474\n",
            "Moving Average (Training): 1590.12, Success: 0\n",
            "Episode: 40158, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3614677\n",
            "Moving Average (Training): 1592.97, Success: 1\n",
            "Episode: 40159, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3614790\n",
            "Moving Average (Training): 1593.5, Success: 0\n",
            "Episode: 40160, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3614983\n",
            "Moving Average (Training): 1593.52, Success: 0\n",
            "Episode: 40161, Total Reward: 2137.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3615171\n",
            "Moving Average (Training): 1602.71, Success: 0\n",
            "Episode: 40162, Total Reward: 171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 27, Step Count: 3615198\n",
            "Moving Average (Training): 1592.25, Success: 0\n",
            "Episode: 40163, Total Reward: 2178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3615399\n",
            "Moving Average (Training): 1604.22, Success: 1\n",
            "Episode: 40164, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3615514\n",
            "Moving Average (Training): 1594.53, Success: 0\n",
            "Episode: 40165, Total Reward: 492.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 57, Step Count: 3615571\n",
            "Moving Average (Training): 1592.39, Success: 0\n",
            "Episode: 40166, Total Reward: 2106.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3615769\n",
            "Moving Average (Training): 1592.18, Success: 0\n",
            "Episode: 40167, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3615973\n",
            "Moving Average (Training): 1592.69, Success: 1\n",
            "Episode: 40168, Total Reward: 483.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3616028\n",
            "Moving Average (Training): 1575.85, Success: 0\n",
            "Episode: 40169, Total Reward: 1165.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3616136\n",
            "Moving Average (Training): 1582.57, Success: 0\n",
            "Episode: 40170, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3616329\n",
            "Moving Average (Training): 1583.12, Success: 0\n",
            "Episode: 40171, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3616518\n",
            "Moving Average (Training): 1592.74, Success: 0\n",
            "Episode: 40172, Total Reward: 1133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 119, Step Count: 3616637\n",
            "Moving Average (Training): 1583.1, Success: 0\n",
            "Episode: 40173, Total Reward: 1285.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 142, Step Count: 3616779\n",
            "Moving Average (Training): 1584.57, Success: 0\n",
            "Episode: 40174, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3616885\n",
            "Moving Average (Training): 1586.55, Success: 0\n",
            "Episode: 40175, Total Reward: 2183.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 224, Step Count: 3617109\n",
            "Moving Average (Training): 1596.16, Success: 1\n",
            "Episode: 40176, Total Reward: 2124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3617300\n",
            "Moving Average (Training): 1595.6, Success: 0\n",
            "Episode: 40177, Total Reward: 176.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3617328\n",
            "Moving Average (Training): 1576.05, Success: 0\n",
            "Episode: 40178, Total Reward: 2125.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 206, Step Count: 3617534\n",
            "Moving Average (Training): 1576.01, Success: 0\n",
            "Episode: 40179, Total Reward: 1895.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 175, Step Count: 3617709\n",
            "Moving Average (Training): 1583.59, Success: 0\n",
            "Episode: 40180, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3617814\n",
            "Moving Average (Training): 1590.24, Success: 0\n",
            "Episode: 40181, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3618013\n",
            "Moving Average (Training): 1590.36, Success: 1\n",
            "Episode: 40182, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3618125\n",
            "Moving Average (Training): 1580.75, Success: 0\n",
            "Episode: 40183, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3618328\n",
            "Moving Average (Training): 1591.16, Success: 1\n",
            "Episode: 40184, Total Reward: 1127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3618444\n",
            "Moving Average (Training): 1597.64, Success: 0\n",
            "Episode: 40185, Total Reward: 678.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 69, Step Count: 3618513\n",
            "Moving Average (Training): 1583.15, Success: 0\n",
            "Episode: 40186, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 117, Step Count: 3618630\n",
            "Moving Average (Training): 1574.02, Success: 0\n",
            "Episode: 40187, Total Reward: 1742.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3618827\n",
            "Moving Average (Training): 1569.65, Success: 0\n",
            "Episode: 40188, Total Reward: 1221.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3618938\n",
            "Moving Average (Training): 1560.57, Success: 0\n",
            "Episode: 40189, Total Reward: 1144.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3619044\n",
            "Moving Average (Training): 1560.3, Success: 0\n",
            "Episode: 40190, Total Reward: 1904.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 175, Step Count: 3619219\n",
            "Moving Average (Training): 1557.69, Success: 0\n",
            "Episode: 40191, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3619329\n",
            "Moving Average (Training): 1556.97, Success: 0\n",
            "Episode: 40192, Total Reward: 2066.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3619518\n",
            "Moving Average (Training): 1556.3, Success: 0\n",
            "Episode: 40193, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3619634\n",
            "Moving Average (Training): 1546.69, Success: 0\n",
            "Episode: 40194, Total Reward: 975.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 96, Step Count: 3619730\n",
            "Moving Average (Training): 1534.65, Success: 0\n",
            "Episode: 40195, Total Reward: 2163.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 208, Step Count: 3619938\n",
            "Moving Average (Training): 1549.26, Success: 1\n",
            "Episode: 40196, Total Reward: 2115.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3620137\n",
            "Moving Average (Training): 1558.04, Success: 0\n",
            "Episode: 40197, Total Reward: 1905.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 224, Step Count: 3620361\n",
            "Moving Average (Training): 1555.94, Success: 0\n",
            "Episode: 40198, Total Reward: 2059.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 839, Step Count: 3621200\n",
            "Moving Average (Training): 1554.75, Success: 1\n",
            "Episode: 40199, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3621402\n",
            "Moving Average (Training): 1555.38, Success: 1\n",
            "Episode: 40200, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3621516\n",
            "Moving Average (Training): 1560.68, Success: 0\n",
            "Episode: 40201, Total Reward: 1135.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3621628\n",
            "Moving Average (Training): 1550.15, Success: 0\n",
            "Episode: 40202, Total Reward: 1156.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3621738\n",
            "Moving Average (Training): 1549.54, Success: 0\n",
            "Episode: 40203, Total Reward: 1124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3621854\n",
            "Moving Average (Training): 1549.06, Success: 0\n",
            "Episode: 40204, Total Reward: 700.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 68, Step Count: 3621922\n",
            "Moving Average (Training): 1534.21, Success: 0\n",
            "Episode: 40205, Total Reward: 979.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 97, Step Count: 3622019\n",
            "Moving Average (Training): 1531.22, Success: 0\n",
            "Episode: 40206, Total Reward: 1166.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3622128\n",
            "Moving Average (Training): 1536.16, Success: 0\n",
            "Episode: 40207, Total Reward: 706.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 72, Step Count: 3622200\n",
            "Moving Average (Training): 1521.42, Success: 0\n",
            "Episode: 40208, Total Reward: 492.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 58, Step Count: 3622258\n",
            "Moving Average (Training): 1505.37, Success: 0\n",
            "Episode: 40209, Total Reward: 704.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 66, Step Count: 3622324\n",
            "Moving Average (Training): 1491.06, Success: 0\n",
            "Episode: 40210, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3622517\n",
            "Moving Average (Training): 1491.17, Success: 1\n",
            "Episode: 40211, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3622707\n",
            "Moving Average (Training): 1505.74, Success: 0\n",
            "Episode: 40212, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3622813\n",
            "Moving Average (Training): 1505.93, Success: 0\n",
            "Episode: 40213, Total Reward: 1173.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3622922\n",
            "Moving Average (Training): 1512.83, Success: 0\n",
            "Episode: 40214, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3623033\n",
            "Moving Average (Training): 1503.24, Success: 0\n",
            "Episode: 40215, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3623141\n",
            "Moving Average (Training): 1505.07, Success: 0\n",
            "Episode: 40216, Total Reward: 981.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 100, Step Count: 3623241\n",
            "Moving Average (Training): 1503.17, Success: 0\n",
            "Episode: 40217, Total Reward: 2186.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3623442\n",
            "Moving Average (Training): 1503.71, Success: 1\n",
            "Episode: 40218, Total Reward: 1221.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3623553\n",
            "Moving Average (Training): 1494.59, Success: 0\n",
            "Episode: 40219, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3623659\n",
            "Moving Average (Training): 1484.49, Success: 0\n",
            "Episode: 40220, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3623860\n",
            "Moving Average (Training): 1485.14, Success: 1\n",
            "Episode: 40221, Total Reward: 2115.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3624051\n",
            "Moving Average (Training): 1504.57, Success: 0\n",
            "Episode: 40222, Total Reward: 1238.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3624165\n",
            "Moving Average (Training): 1495.08, Success: 0\n",
            "Episode: 40223, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 103, Step Count: 3624268\n",
            "Moving Average (Training): 1494.3, Success: 0\n",
            "Episode: 40224, Total Reward: 2101.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 192, Step Count: 3624460\n",
            "Moving Average (Training): 1493.42, Success: 0\n",
            "Episode: 40225, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3624657\n",
            "Moving Average (Training): 1507.76, Success: 0\n",
            "Episode: 40226, Total Reward: 976.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 100, Step Count: 3624757\n",
            "Moving Average (Training): 1506.41, Success: 0\n",
            "Episode: 40227, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3624946\n",
            "Moving Average (Training): 1520.7, Success: 0\n",
            "Episode: 40228, Total Reward: 703.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 69, Step Count: 3625015\n",
            "Moving Average (Training): 1526.0, Success: 0\n",
            "Episode: 40229, Total Reward: 2112.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3625205\n",
            "Moving Average (Training): 1534.61, Success: 0\n",
            "Episode: 40230, Total Reward: 2122.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 206, Step Count: 3625411\n",
            "Moving Average (Training): 1544.14, Success: 0\n",
            "Episode: 40231, Total Reward: 1147.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3625515\n",
            "Moving Average (Training): 1533.73, Success: 0\n",
            "Episode: 40232, Total Reward: 699.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 67, Step Count: 3625582\n",
            "Moving Average (Training): 1518.83, Success: 0\n",
            "Episode: 40233, Total Reward: 2183.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 215, Step Count: 3625797\n",
            "Moving Average (Training): 1518.79, Success: 1\n",
            "Episode: 40234, Total Reward: 2108.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 196, Step Count: 3625993\n",
            "Moving Average (Training): 1528.82, Success: 0\n",
            "Episode: 40235, Total Reward: 698.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 73, Step Count: 3626066\n",
            "Moving Average (Training): 1513.91, Success: 0\n",
            "Episode: 40236, Total Reward: 967.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 92, Step Count: 3626158\n",
            "Moving Average (Training): 1501.7, Success: 0\n",
            "Episode: 40237, Total Reward: 174.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 26, Step Count: 3626184\n",
            "Moving Average (Training): 1493.68, Success: 0\n",
            "Episode: 40238, Total Reward: 671.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 64, Step Count: 3626248\n",
            "Moving Average (Training): 1479.71, Success: 0\n",
            "Episode: 40239, Total Reward: 2124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3626436\n",
            "Moving Average (Training): 1479.65, Success: 0\n",
            "Episode: 40240, Total Reward: 1127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 117, Step Count: 3626553\n",
            "Moving Average (Training): 1469.63, Success: 0\n",
            "Episode: 40241, Total Reward: 2116.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3626753\n",
            "Moving Average (Training): 1468.98, Success: 0\n",
            "Episode: 40242, Total Reward: 2134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3626954\n",
            "Moving Average (Training): 1486.59, Success: 0\n",
            "Episode: 40243, Total Reward: 1153.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3627062\n",
            "Moving Average (Training): 1476.4, Success: 0\n",
            "Episode: 40244, Total Reward: 1127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3627176\n",
            "Moving Average (Training): 1483.97, Success: 0\n",
            "Episode: 40245, Total Reward: 2185.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 207, Step Count: 3627383\n",
            "Moving Average (Training): 1483.93, Success: 1\n",
            "Episode: 40246, Total Reward: 1251.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 121, Step Count: 3627504\n",
            "Moving Average (Training): 1474.61, Success: 0\n",
            "Episode: 40247, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3627615\n",
            "Moving Average (Training): 1481.96, Success: 0\n",
            "Episode: 40248, Total Reward: 1169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3627723\n",
            "Moving Average (Training): 1471.77, Success: 0\n",
            "Episode: 40249, Total Reward: 1230.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3627837\n",
            "Moving Average (Training): 1462.32, Success: 0\n",
            "Episode: 40250, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3627943\n",
            "Moving Average (Training): 1452.75, Success: 0\n",
            "Episode: 40251, Total Reward: 1131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3628057\n",
            "Moving Average (Training): 1442.37, Success: 0\n",
            "Episode: 40252, Total Reward: 2126.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3628248\n",
            "Moving Average (Training): 1441.79, Success: 0\n",
            "Episode: 40253, Total Reward: 398.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 44, Step Count: 3628292\n",
            "Moving Average (Training): 1433.56, Success: 0\n",
            "Episode: 40254, Total Reward: 2165.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3628494\n",
            "Moving Average (Training): 1433.41, Success: 1\n",
            "Episode: 40255, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3628609\n",
            "Moving Average (Training): 1433.42, Success: 0\n",
            "Episode: 40256, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3628716\n",
            "Moving Average (Training): 1443.44, Success: 0\n",
            "Episode: 40257, Total Reward: 399.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 49, Step Count: 3628765\n",
            "Moving Average (Training): 1437.58, Success: 0\n",
            "Episode: 40258, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3628881\n",
            "Moving Average (Training): 1427.89, Success: 0\n",
            "Episode: 40259, Total Reward: 1780.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 243, Step Count: 3629124\n",
            "Moving Average (Training): 1433.52, Success: 0\n",
            "Episode: 40260, Total Reward: 179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 26, Step Count: 3629150\n",
            "Moving Average (Training): 1413.98, Success: 0\n",
            "Episode: 40261, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 207, Step Count: 3629357\n",
            "Moving Average (Training): 1414.41, Success: 1\n",
            "Episode: 40262, Total Reward: 2116.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 194, Step Count: 3629551\n",
            "Moving Average (Training): 1433.86, Success: 0\n",
            "Episode: 40263, Total Reward: 2178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 208, Step Count: 3629759\n",
            "Moving Average (Training): 1433.86, Success: 1\n",
            "Episode: 40264, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3629866\n",
            "Moving Average (Training): 1433.12, Success: 0\n",
            "Episode: 40265, Total Reward: 1504.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 142, Step Count: 3630008\n",
            "Moving Average (Training): 1443.24, Success: 0\n",
            "Episode: 40266, Total Reward: 1236.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3630121\n",
            "Moving Average (Training): 1434.54, Success: 0\n",
            "Episode: 40267, Total Reward: 968.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 90, Step Count: 3630211\n",
            "Moving Average (Training): 1422.43, Success: 0\n",
            "Episode: 40268, Total Reward: 986.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 91, Step Count: 3630302\n",
            "Moving Average (Training): 1427.46, Success: 0\n",
            "Episode: 40269, Total Reward: 1966.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 177, Step Count: 3630479\n",
            "Moving Average (Training): 1435.47, Success: 0\n",
            "Episode: 40270, Total Reward: 1973.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 184, Step Count: 3630663\n",
            "Moving Average (Training): 1433.91, Success: 0\n",
            "Episode: 40271, Total Reward: 1165.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3630769\n",
            "Moving Average (Training): 1424.26, Success: 0\n",
            "Episode: 40272, Total Reward: 964.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 101, Step Count: 3630870\n",
            "Moving Average (Training): 1422.57, Success: 0\n",
            "Episode: 40273, Total Reward: 1136.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3630981\n",
            "Moving Average (Training): 1421.08, Success: 0\n",
            "Episode: 40274, Total Reward: 2089.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3631169\n",
            "Moving Average (Training): 1430.25, Success: 0\n",
            "Episode: 40275, Total Reward: 1236.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3631282\n",
            "Moving Average (Training): 1420.78, Success: 0\n",
            "Episode: 40276, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3631482\n",
            "Moving Average (Training): 1421.42, Success: 1\n",
            "Episode: 40277, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3631670\n",
            "Moving Average (Training): 1440.94, Success: 0\n",
            "Episode: 40278, Total Reward: 394.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 45, Step Count: 3631715\n",
            "Moving Average (Training): 1423.63, Success: 0\n",
            "Episode: 40279, Total Reward: 1881.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 176, Step Count: 3631891\n",
            "Moving Average (Training): 1423.49, Success: 0\n",
            "Episode: 40280, Total Reward: 684.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 64, Step Count: 3631955\n",
            "Moving Average (Training): 1418.87, Success: 0\n",
            "Episode: 40281, Total Reward: 488.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 53, Step Count: 3632008\n",
            "Moving Average (Training): 1401.94, Success: 0\n",
            "Episode: 40282, Total Reward: 166.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 31, Step Count: 3632039\n",
            "Moving Average (Training): 1391.42, Success: 0\n",
            "Episode: 40283, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 210, Step Count: 3632249\n",
            "Moving Average (Training): 1390.84, Success: 0\n",
            "Episode: 40284, Total Reward: 667.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 71, Step Count: 3632320\n",
            "Moving Average (Training): 1386.24, Success: 0\n",
            "Episode: 40285, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3632426\n",
            "Moving Average (Training): 1390.91, Success: 0\n",
            "Episode: 40286, Total Reward: 953.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 94, Step Count: 3632520\n",
            "Moving Average (Training): 1388.27, Success: 0\n",
            "Episode: 40287, Total Reward: 1221.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3632633\n",
            "Moving Average (Training): 1383.06, Success: 0\n",
            "Episode: 40288, Total Reward: 2118.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3632823\n",
            "Moving Average (Training): 1392.03, Success: 0\n",
            "Episode: 40289, Total Reward: 2169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3633021\n",
            "Moving Average (Training): 1402.28, Success: 1\n",
            "Episode: 40290, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3633211\n",
            "Moving Average (Training): 1404.54, Success: 0\n",
            "Episode: 40291, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3633412\n",
            "Moving Average (Training): 1414.4, Success: 0\n",
            "Episode: 40292, Total Reward: 1267.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 143, Step Count: 3633555\n",
            "Moving Average (Training): 1406.41, Success: 0\n",
            "Episode: 40293, Total Reward: 2078.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 194, Step Count: 3633749\n",
            "Moving Average (Training): 1415.0, Success: 0\n",
            "Episode: 40294, Total Reward: 2124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3633940\n",
            "Moving Average (Training): 1426.49, Success: 0\n",
            "Episode: 40295, Total Reward: 1222.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3634052\n",
            "Moving Average (Training): 1417.08, Success: 0\n",
            "Episode: 40296, Total Reward: 1224.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3634162\n",
            "Moving Average (Training): 1408.17, Success: 0\n",
            "Episode: 40297, Total Reward: 1979.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3634360\n",
            "Moving Average (Training): 1408.91, Success: 0\n",
            "Episode: 40298, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3634549\n",
            "Moving Average (Training): 1409.62, Success: 0\n",
            "Episode: 40299, Total Reward: 1144.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3634656\n",
            "Moving Average (Training): 1399.18, Success: 0\n",
            "Episode: 40300, Total Reward: 1144.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3634766\n",
            "Moving Average (Training): 1398.45, Success: 0\n",
            "Episode: 40301, Total Reward: 988.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 91, Step Count: 3634857\n",
            "Moving Average (Training): 1396.98, Success: 0\n",
            "Episode: 40302, Total Reward: 2122.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3635056\n",
            "Moving Average (Training): 1406.64, Success: 0\n",
            "Episode: 40303, Total Reward: 1170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3635165\n",
            "Moving Average (Training): 1407.1, Success: 0\n",
            "Episode: 40304, Total Reward: 968.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 98, Step Count: 3635263\n",
            "Moving Average (Training): 1409.78, Success: 0\n",
            "Episode: 40305, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3635466\n",
            "Moving Average (Training): 1421.8, Success: 1\n",
            "Episode: 40306, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3635580\n",
            "Moving Average (Training): 1422.32, Success: 0\n",
            "Episode: 40307, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3635769\n",
            "Moving Average (Training): 1436.55, Success: 0\n",
            "Episode: 40308, Total Reward: 384.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 42, Step Count: 3635811\n",
            "Moving Average (Training): 1435.47, Success: 0\n",
            "Episode: 40309, Total Reward: 1135.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3635921\n",
            "Moving Average (Training): 1439.78, Success: 0\n",
            "Episode: 40310, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3636126\n",
            "Moving Average (Training): 1439.71, Success: 1\n",
            "Episode: 40311, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3636319\n",
            "Moving Average (Training): 1439.72, Success: 0\n",
            "Episode: 40312, Total Reward: 2118.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3636508\n",
            "Moving Average (Training): 1449.19, Success: 0\n",
            "Episode: 40313, Total Reward: 488.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3636562\n",
            "Moving Average (Training): 1442.34, Success: 0\n",
            "Episode: 40314, Total Reward: 675.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 68, Step Count: 3636630\n",
            "Moving Average (Training): 1437.64, Success: 0\n",
            "Episode: 40315, Total Reward: 1221.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3636741\n",
            "Moving Average (Training): 1438.13, Success: 0\n",
            "Episode: 40316, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3636853\n",
            "Moving Average (Training): 1440.55, Success: 0\n",
            "Episode: 40317, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3636964\n",
            "Moving Average (Training): 1430.92, Success: 0\n",
            "Episode: 40318, Total Reward: 2100.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3637155\n",
            "Moving Average (Training): 1439.71, Success: 0\n",
            "Episode: 40319, Total Reward: 1220.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3637267\n",
            "Moving Average (Training): 1440.19, Success: 0\n",
            "Episode: 40320, Total Reward: 684.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 64, Step Count: 3637331\n",
            "Moving Average (Training): 1425.15, Success: 0\n",
            "Episode: 40321, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3637532\n",
            "Moving Average (Training): 1425.81, Success: 1\n",
            "Episode: 40322, Total Reward: 973.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 92, Step Count: 3637624\n",
            "Moving Average (Training): 1423.16, Success: 0\n",
            "Episode: 40323, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3637738\n",
            "Moving Average (Training): 1423.9, Success: 0\n",
            "Episode: 40324, Total Reward: 2182.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3637941\n",
            "Moving Average (Training): 1424.71, Success: 1\n",
            "Episode: 40325, Total Reward: 1229.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3638053\n",
            "Moving Average (Training): 1415.7, Success: 0\n",
            "Episode: 40326, Total Reward: 670.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 66, Step Count: 3638119\n",
            "Moving Average (Training): 1412.64, Success: 0\n",
            "Episode: 40327, Total Reward: 672.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 67, Step Count: 3638186\n",
            "Moving Average (Training): 1398.08, Success: 0\n",
            "Episode: 40328, Total Reward: 2164.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 212, Step Count: 3638398\n",
            "Moving Average (Training): 1412.69, Success: 1\n",
            "Episode: 40329, Total Reward: 173.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 26, Step Count: 3638424\n",
            "Moving Average (Training): 1393.3, Success: 0\n",
            "Episode: 40330, Total Reward: 2167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3638617\n",
            "Moving Average (Training): 1393.75, Success: 1\n",
            "Episode: 40331, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3638808\n",
            "Moving Average (Training): 1403.59, Success: 0\n",
            "Episode: 40332, Total Reward: 1246.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 148, Step Count: 3638956\n",
            "Moving Average (Training): 1409.06, Success: 0\n",
            "Episode: 40333, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 220, Step Count: 3639176\n",
            "Moving Average (Training): 1409.04, Success: 1\n",
            "Episode: 40334, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3639376\n",
            "Moving Average (Training): 1409.29, Success: 0\n",
            "Episode: 40335, Total Reward: 2168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3639579\n",
            "Moving Average (Training): 1423.99, Success: 1\n",
            "Episode: 40336, Total Reward: 1833.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 262, Step Count: 3639841\n",
            "Moving Average (Training): 1432.65, Success: 0\n",
            "Episode: 40337, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3640044\n",
            "Moving Average (Training): 1452.71, Success: 1\n",
            "Episode: 40338, Total Reward: 2174.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 209, Step Count: 3640253\n",
            "Moving Average (Training): 1467.74, Success: 1\n",
            "Episode: 40339, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 243, Step Count: 3640496\n",
            "Moving Average (Training): 1468.3, Success: 1\n",
            "Episode: 40340, Total Reward: 1975.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 178, Step Count: 3640674\n",
            "Moving Average (Training): 1476.78, Success: 0\n",
            "Episode: 40341, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3640876\n",
            "Moving Average (Training): 1477.49, Success: 1\n",
            "Episode: 40342, Total Reward: 2093.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3641076\n",
            "Moving Average (Training): 1477.08, Success: 0\n",
            "Episode: 40343, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3641181\n",
            "Moving Average (Training): 1477.01, Success: 0\n",
            "Episode: 40344, Total Reward: 673.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 65, Step Count: 3641246\n",
            "Moving Average (Training): 1472.47, Success: 0\n",
            "Episode: 40345, Total Reward: 967.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 93, Step Count: 3641339\n",
            "Moving Average (Training): 1460.29, Success: 0\n",
            "Episode: 40346, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3641528\n",
            "Moving Average (Training): 1469.11, Success: 0\n",
            "Episode: 40347, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3641733\n",
            "Moving Average (Training): 1478.23, Success: 0\n",
            "Episode: 40348, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3641926\n",
            "Moving Average (Training): 1487.82, Success: 0\n",
            "Episode: 40349, Total Reward: 1135.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3642037\n",
            "Moving Average (Training): 1486.87, Success: 0\n",
            "Episode: 40350, Total Reward: 1155.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3642148\n",
            "Moving Average (Training): 1486.7, Success: 0\n",
            "Episode: 40351, Total Reward: 2124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3642336\n",
            "Moving Average (Training): 1496.63, Success: 0\n",
            "Episode: 40352, Total Reward: 2166.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3642535\n",
            "Moving Average (Training): 1497.03, Success: 1\n",
            "Episode: 40353, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3642650\n",
            "Moving Average (Training): 1505.23, Success: 0\n",
            "Episode: 40354, Total Reward: 1236.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3642765\n",
            "Moving Average (Training): 1495.94, Success: 0\n",
            "Episode: 40355, Total Reward: 1220.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3642878\n",
            "Moving Average (Training): 1495.95, Success: 0\n",
            "Episode: 40356, Total Reward: 2091.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 252, Step Count: 3643130\n",
            "Moving Average (Training): 1505.15, Success: 0\n",
            "Episode: 40357, Total Reward: 165.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 32, Step Count: 3643162\n",
            "Moving Average (Training): 1502.81, Success: 0\n",
            "Episode: 40358, Total Reward: 976.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 93, Step Count: 3643255\n",
            "Moving Average (Training): 1500.38, Success: 0\n",
            "Episode: 40359, Total Reward: 1135.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3643367\n",
            "Moving Average (Training): 1493.93, Success: 0\n",
            "Episode: 40360, Total Reward: 2080.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 245, Step Count: 3643612\n",
            "Moving Average (Training): 1512.94, Success: 0\n",
            "Episode: 40361, Total Reward: 2120.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3643802\n",
            "Moving Average (Training): 1512.34, Success: 0\n",
            "Episode: 40362, Total Reward: 971.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 98, Step Count: 3643900\n",
            "Moving Average (Training): 1500.89, Success: 0\n",
            "Episode: 40363, Total Reward: 486.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3643955\n",
            "Moving Average (Training): 1483.97, Success: 0\n",
            "Episode: 40364, Total Reward: 384.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 43, Step Count: 3643998\n",
            "Moving Average (Training): 1476.36, Success: 0\n",
            "Episode: 40365, Total Reward: 493.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3644053\n",
            "Moving Average (Training): 1466.25, Success: 0\n",
            "Episode: 40366, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3644164\n",
            "Moving Average (Training): 1466.08, Success: 0\n",
            "Episode: 40367, Total Reward: 2126.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3644366\n",
            "Moving Average (Training): 1477.66, Success: 0\n",
            "Episode: 40368, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 229, Step Count: 3644595\n",
            "Moving Average (Training): 1489.61, Success: 1\n",
            "Episode: 40369, Total Reward: 2119.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3644792\n",
            "Moving Average (Training): 1491.14, Success: 0\n",
            "Episode: 40370, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3644907\n",
            "Moving Average (Training): 1483.59, Success: 0\n",
            "Episode: 40371, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3645014\n",
            "Moving Average (Training): 1483.65, Success: 0\n",
            "Episode: 40372, Total Reward: 1150.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3645122\n",
            "Moving Average (Training): 1485.51, Success: 0\n",
            "Episode: 40373, Total Reward: 1168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3645230\n",
            "Moving Average (Training): 1485.83, Success: 0\n",
            "Episode: 40374, Total Reward: 1170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3645337\n",
            "Moving Average (Training): 1476.64, Success: 0\n",
            "Episode: 40375, Total Reward: 2125.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3645528\n",
            "Moving Average (Training): 1485.53, Success: 0\n",
            "Episode: 40376, Total Reward: 386.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 47, Step Count: 3645575\n",
            "Moving Average (Training): 1467.51, Success: 0\n",
            "Episode: 40377, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3645772\n",
            "Moving Average (Training): 1468.04, Success: 1\n",
            "Episode: 40378, Total Reward: 170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 31, Step Count: 3645803\n",
            "Moving Average (Training): 1465.8, Success: 0\n",
            "Episode: 40379, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3645911\n",
            "Moving Average (Training): 1458.7, Success: 0\n",
            "Episode: 40380, Total Reward: 1156.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3646020\n",
            "Moving Average (Training): 1463.42, Success: 0\n",
            "Episode: 40381, Total Reward: 2178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 212, Step Count: 3646232\n",
            "Moving Average (Training): 1480.32, Success: 1\n",
            "Episode: 40382, Total Reward: 975.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 91, Step Count: 3646323\n",
            "Moving Average (Training): 1488.41, Success: 0\n",
            "Episode: 40383, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3646377\n",
            "Moving Average (Training): 1471.97, Success: 0\n",
            "Episode: 40384, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 187, Step Count: 3646564\n",
            "Moving Average (Training): 1486.58, Success: 0\n",
            "Episode: 40385, Total Reward: 1169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3646671\n",
            "Moving Average (Training): 1486.82, Success: 0\n",
            "Episode: 40386, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3646787\n",
            "Moving Average (Training): 1489.52, Success: 0\n",
            "Episode: 40387, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3646902\n",
            "Moving Average (Training): 1489.5, Success: 0\n",
            "Episode: 40388, Total Reward: 702.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 69, Step Count: 3646971\n",
            "Moving Average (Training): 1475.34, Success: 0\n",
            "Episode: 40389, Total Reward: 704.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 67, Step Count: 3647038\n",
            "Moving Average (Training): 1460.69, Success: 0\n",
            "Episode: 40390, Total Reward: 171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 29, Step Count: 3647067\n",
            "Moving Average (Training): 1441.1, Success: 0\n",
            "Episode: 40391, Total Reward: 2170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3647271\n",
            "Moving Average (Training): 1441.48, Success: 1\n",
            "Episode: 40392, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3647475\n",
            "Moving Average (Training): 1450.61, Success: 1\n",
            "Episode: 40393, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3647676\n",
            "Moving Average (Training): 1451.14, Success: 0\n",
            "Episode: 40394, Total Reward: 1221.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3647788\n",
            "Moving Average (Training): 1442.11, Success: 0\n",
            "Episode: 40395, Total Reward: 1222.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3647902\n",
            "Moving Average (Training): 1442.11, Success: 0\n",
            "Episode: 40396, Total Reward: 706.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 67, Step Count: 3647969\n",
            "Moving Average (Training): 1436.93, Success: 0\n",
            "Episode: 40397, Total Reward: 487.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3648024\n",
            "Moving Average (Training): 1422.01, Success: 0\n",
            "Episode: 40398, Total Reward: 172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3648052\n",
            "Moving Average (Training): 1402.43, Success: 0\n",
            "Episode: 40399, Total Reward: 2098.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3648256\n",
            "Moving Average (Training): 1411.97, Success: 0\n",
            "Episode: 40400, Total Reward: 486.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 60, Step Count: 3648316\n",
            "Moving Average (Training): 1405.39, Success: 0\n",
            "Episode: 40401, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3648428\n",
            "Moving Average (Training): 1407.69, Success: 0\n",
            "Episode: 40402, Total Reward: 2174.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3648629\n",
            "Moving Average (Training): 1408.21, Success: 1\n",
            "Episode: 40403, Total Reward: 2099.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3648827\n",
            "Moving Average (Training): 1417.5, Success: 0\n",
            "Episode: 40404, Total Reward: 1221.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3648938\n",
            "Moving Average (Training): 1420.03, Success: 0\n",
            "Episode: 40405, Total Reward: 1220.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3649051\n",
            "Moving Average (Training): 1410.42, Success: 0\n",
            "Episode: 40406, Total Reward: 2049.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 258, Step Count: 3649309\n",
            "Moving Average (Training): 1418.73, Success: 0\n",
            "Episode: 40407, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3649506\n",
            "Moving Average (Training): 1418.76, Success: 0\n",
            "Episode: 40408, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3649614\n",
            "Moving Average (Training): 1426.37, Success: 0\n",
            "Episode: 40409, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3649668\n",
            "Moving Average (Training): 1419.87, Success: 0\n",
            "Episode: 40410, Total Reward: 2100.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 194, Step Count: 3649862\n",
            "Moving Average (Training): 1419.06, Success: 0\n",
            "Episode: 40411, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3650053\n",
            "Moving Average (Training): 1419.05, Success: 0\n",
            "Episode: 40412, Total Reward: 1236.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3650166\n",
            "Moving Average (Training): 1410.23, Success: 0\n",
            "Episode: 40413, Total Reward: 1151.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3650275\n",
            "Moving Average (Training): 1416.86, Success: 0\n",
            "Episode: 40414, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3650388\n",
            "Moving Average (Training): 1422.28, Success: 0\n",
            "Episode: 40415, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3650492\n",
            "Moving Average (Training): 1421.53, Success: 0\n",
            "Episode: 40416, Total Reward: 373.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 39, Step Count: 3650531\n",
            "Moving Average (Training): 1413.03, Success: 0\n",
            "Episode: 40417, Total Reward: 1511.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 136, Step Count: 3650667\n",
            "Moving Average (Training): 1415.91, Success: 0\n",
            "Episode: 40418, Total Reward: 1501.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 140, Step Count: 3650807\n",
            "Moving Average (Training): 1409.92, Success: 0\n",
            "Episode: 40419, Total Reward: 1220.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3650918\n",
            "Moving Average (Training): 1409.92, Success: 0\n",
            "Episode: 40420, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3651122\n",
            "Moving Average (Training): 1424.89, Success: 1\n",
            "Episode: 40421, Total Reward: 2113.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 218, Step Count: 3651340\n",
            "Moving Average (Training): 1424.21, Success: 0\n",
            "Episode: 40422, Total Reward: 1220.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3651453\n",
            "Moving Average (Training): 1426.68, Success: 0\n",
            "Episode: 40423, Total Reward: 1246.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 147, Step Count: 3651600\n",
            "Moving Average (Training): 1426.95, Success: 0\n",
            "Episode: 40424, Total Reward: 2120.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3651790\n",
            "Moving Average (Training): 1426.33, Success: 0\n",
            "Episode: 40425, Total Reward: 2170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3651990\n",
            "Moving Average (Training): 1435.74, Success: 1\n",
            "Episode: 40426, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3652180\n",
            "Moving Average (Training): 1450.35, Success: 0\n",
            "Episode: 40427, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 208, Step Count: 3652388\n",
            "Moving Average (Training): 1465.5, Success: 1\n",
            "Episode: 40428, Total Reward: 707.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 68, Step Count: 3652456\n",
            "Moving Average (Training): 1450.93, Success: 0\n",
            "Episode: 40429, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3652661\n",
            "Moving Average (Training): 1470.99, Success: 1\n",
            "Episode: 40430, Total Reward: 1137.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3652774\n",
            "Moving Average (Training): 1460.69, Success: 0\n",
            "Episode: 40431, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3652977\n",
            "Moving Average (Training): 1461.17, Success: 1\n",
            "Episode: 40432, Total Reward: 172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3653005\n",
            "Moving Average (Training): 1450.43, Success: 0\n",
            "Episode: 40433, Total Reward: 2123.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3653194\n",
            "Moving Average (Training): 1449.85, Success: 0\n",
            "Episode: 40434, Total Reward: 976.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 92, Step Count: 3653286\n",
            "Moving Average (Training): 1438.28, Success: 0\n",
            "Episode: 40435, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3653393\n",
            "Moving Average (Training): 1428.31, Success: 0\n",
            "Episode: 40436, Total Reward: 2173.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 222, Step Count: 3653615\n",
            "Moving Average (Training): 1431.71, Success: 1\n",
            "Episode: 40437, Total Reward: 1136.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3653721\n",
            "Moving Average (Training): 1421.27, Success: 0\n",
            "Episode: 40438, Total Reward: 1893.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 185, Step Count: 3653906\n",
            "Moving Average (Training): 1418.46, Success: 0\n",
            "Episode: 40439, Total Reward: 172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3653934\n",
            "Moving Average (Training): 1398.38, Success: 0\n",
            "Episode: 40440, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3653962\n",
            "Moving Average (Training): 1380.41, Success: 0\n",
            "Episode: 40441, Total Reward: 2107.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3654161\n",
            "Moving Average (Training): 1379.61, Success: 0\n",
            "Episode: 40442, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 215, Step Count: 3654376\n",
            "Moving Average (Training): 1380.48, Success: 1\n",
            "Episode: 40443, Total Reward: 1169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3654483\n",
            "Moving Average (Training): 1380.71, Success: 0\n",
            "Episode: 40444, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3654681\n",
            "Moving Average (Training): 1395.85, Success: 1\n",
            "Episode: 40445, Total Reward: 2177.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 251, Step Count: 3654932\n",
            "Moving Average (Training): 1407.95, Success: 1\n",
            "Episode: 40446, Total Reward: 2116.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3655121\n",
            "Moving Average (Training): 1407.78, Success: 0\n",
            "Episode: 40447, Total Reward: 2176.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 212, Step Count: 3655333\n",
            "Moving Average (Training): 1408.24, Success: 1\n",
            "Episode: 40448, Total Reward: 2101.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3655531\n",
            "Moving Average (Training): 1407.97, Success: 0\n",
            "Episode: 40449, Total Reward: 1969.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 178, Step Count: 3655709\n",
            "Moving Average (Training): 1416.31, Success: 0\n",
            "Episode: 40450, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3655822\n",
            "Moving Average (Training): 1416.94, Success: 0\n",
            "Episode: 40451, Total Reward: 2111.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3656015\n",
            "Moving Average (Training): 1416.81, Success: 0\n",
            "Episode: 40452, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3656119\n",
            "Moving Average (Training): 1406.61, Success: 0\n",
            "Episode: 40453, Total Reward: 2088.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3656308\n",
            "Moving Average (Training): 1415.31, Success: 0\n",
            "Episode: 40454, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 211, Step Count: 3656519\n",
            "Moving Average (Training): 1424.24, Success: 0\n",
            "Episode: 40455, Total Reward: 489.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 52, Step Count: 3656571\n",
            "Moving Average (Training): 1416.93, Success: 0\n",
            "Episode: 40456, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3656761\n",
            "Moving Average (Training): 1417.31, Success: 0\n",
            "Episode: 40457, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3656962\n",
            "Moving Average (Training): 1437.46, Success: 1\n",
            "Episode: 40458, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 212, Step Count: 3657174\n",
            "Moving Average (Training): 1448.97, Success: 0\n",
            "Episode: 40459, Total Reward: 1298.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 135, Step Count: 3657309\n",
            "Moving Average (Training): 1450.6, Success: 0\n",
            "Episode: 40460, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3657417\n",
            "Moving Average (Training): 1441.52, Success: 0\n",
            "Episode: 40461, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3657525\n",
            "Moving Average (Training): 1432.03, Success: 0\n",
            "Episode: 40462, Total Reward: 2108.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3657723\n",
            "Moving Average (Training): 1443.4, Success: 0\n",
            "Episode: 40463, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3657925\n",
            "Moving Average (Training): 1460.34, Success: 1\n",
            "Episode: 40464, Total Reward: 168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 31, Step Count: 3657956\n",
            "Moving Average (Training): 1458.18, Success: 0\n",
            "Episode: 40465, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3658011\n",
            "Moving Average (Training): 1458.1, Success: 0\n",
            "Episode: 40466, Total Reward: 669.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 64, Step Count: 3658075\n",
            "Moving Average (Training): 1452.6, Success: 0\n",
            "Episode: 40467, Total Reward: 1097.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 121, Step Count: 3658196\n",
            "Moving Average (Training): 1442.31, Success: 0\n",
            "Episode: 40468, Total Reward: 967.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 100, Step Count: 3658296\n",
            "Moving Average (Training): 1430.17, Success: 0\n",
            "Episode: 40469, Total Reward: 1163.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3658406\n",
            "Moving Average (Training): 1420.61, Success: 0\n",
            "Episode: 40470, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3658607\n",
            "Moving Average (Training): 1430.24, Success: 1\n",
            "Episode: 40471, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3658804\n",
            "Moving Average (Training): 1439.84, Success: 0\n",
            "Episode: 40472, Total Reward: 1246.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 148, Step Count: 3658952\n",
            "Moving Average (Training): 1440.8, Success: 0\n",
            "Episode: 40473, Total Reward: 487.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 58, Step Count: 3659010\n",
            "Moving Average (Training): 1433.99, Success: 0\n",
            "Episode: 40474, Total Reward: 1165.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3659120\n",
            "Moving Average (Training): 1433.94, Success: 0\n",
            "Episode: 40475, Total Reward: 2186.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3659320\n",
            "Moving Average (Training): 1434.55, Success: 1\n",
            "Episode: 40476, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3659509\n",
            "Moving Average (Training): 1451.99, Success: 0\n",
            "Episode: 40477, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3659700\n",
            "Moving Average (Training): 1451.51, Success: 0\n",
            "Episode: 40478, Total Reward: 2184.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 215, Step Count: 3659915\n",
            "Moving Average (Training): 1471.65, Success: 1\n",
            "Episode: 40479, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3660020\n",
            "Moving Average (Training): 1471.39, Success: 0\n",
            "Episode: 40480, Total Reward: 1314.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 138, Step Count: 3660158\n",
            "Moving Average (Training): 1472.97, Success: 0\n",
            "Episode: 40481, Total Reward: 1359.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 135, Step Count: 3660293\n",
            "Moving Average (Training): 1464.78, Success: 0\n",
            "Episode: 40482, Total Reward: 487.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3660347\n",
            "Moving Average (Training): 1459.9, Success: 0\n",
            "Episode: 40483, Total Reward: 2178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 207, Step Count: 3660554\n",
            "Moving Average (Training): 1476.83, Success: 1\n",
            "Episode: 40484, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3660745\n",
            "Moving Average (Training): 1476.83, Success: 0\n",
            "Episode: 40485, Total Reward: 671.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 66, Step Count: 3660811\n",
            "Moving Average (Training): 1471.85, Success: 0\n",
            "Episode: 40486, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3661016\n",
            "Moving Average (Training): 1480.9, Success: 0\n",
            "Episode: 40487, Total Reward: 2164.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3661218\n",
            "Moving Average (Training): 1490.35, Success: 1\n",
            "Episode: 40488, Total Reward: 1904.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 175, Step Count: 3661393\n",
            "Moving Average (Training): 1502.37, Success: 0\n",
            "Episode: 40489, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3661499\n",
            "Moving Average (Training): 1506.78, Success: 0\n",
            "Episode: 40490, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3661612\n",
            "Moving Average (Training): 1517.26, Success: 0\n",
            "Episode: 40491, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3661718\n",
            "Moving Average (Training): 1507.01, Success: 0\n",
            "Episode: 40492, Total Reward: 1168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3661828\n",
            "Moving Average (Training): 1496.89, Success: 0\n",
            "Episode: 40493, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3661940\n",
            "Moving Average (Training): 1487.81, Success: 0\n",
            "Episode: 40494, Total Reward: 1345.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 133, Step Count: 3662073\n",
            "Moving Average (Training): 1489.05, Success: 0\n",
            "Episode: 40495, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3662264\n",
            "Moving Average (Training): 1498.15, Success: 0\n",
            "Episode: 40496, Total Reward: 1509.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 135, Step Count: 3662399\n",
            "Moving Average (Training): 1506.18, Success: 0\n",
            "Episode: 40497, Total Reward: 667.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 65, Step Count: 3662464\n",
            "Moving Average (Training): 1507.98, Success: 0\n",
            "Episode: 40498, Total Reward: 170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 29, Step Count: 3662493\n",
            "Moving Average (Training): 1507.96, Success: 0\n",
            "Episode: 40499, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3662684\n",
            "Moving Average (Training): 1508.31, Success: 0\n",
            "Episode: 40500, Total Reward: 671.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 74, Step Count: 3662758\n",
            "Moving Average (Training): 1510.16, Success: 0\n",
            "Episode: 40501, Total Reward: 2115.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3662947\n",
            "Moving Average (Training): 1519.13, Success: 0\n",
            "Episode: 40502, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3662975\n",
            "Moving Average (Training): 1499.17, Success: 0\n",
            "Episode: 40503, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3663082\n",
            "Moving Average (Training): 1489.89, Success: 0\n",
            "Episode: 40504, Total Reward: 1169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3663190\n",
            "Moving Average (Training): 1489.37, Success: 0\n",
            "Episode: 40505, Total Reward: 488.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3663245\n",
            "Moving Average (Training): 1482.05, Success: 0\n",
            "Episode: 40506, Total Reward: 1237.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3663357\n",
            "Moving Average (Training): 1473.93, Success: 0\n",
            "Episode: 40507, Total Reward: 1220.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3663471\n",
            "Moving Average (Training): 1464.81, Success: 0\n",
            "Episode: 40508, Total Reward: 703.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 77, Step Count: 3663548\n",
            "Moving Average (Training): 1460.39, Success: 0\n",
            "Episode: 40509, Total Reward: 2178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3663750\n",
            "Moving Average (Training): 1477.32, Success: 1\n",
            "Episode: 40510, Total Reward: 2117.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3663941\n",
            "Moving Average (Training): 1477.49, Success: 0\n",
            "Episode: 40511, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3664052\n",
            "Moving Average (Training): 1467.91, Success: 0\n",
            "Episode: 40512, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 196, Step Count: 3664248\n",
            "Moving Average (Training): 1477.43, Success: 1\n",
            "Episode: 40513, Total Reward: 2166.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3664451\n",
            "Moving Average (Training): 1487.58, Success: 1\n",
            "Episode: 40514, Total Reward: 2166.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3664649\n",
            "Moving Average (Training): 1497.07, Success: 1\n",
            "Episode: 40515, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3664852\n",
            "Moving Average (Training): 1507.49, Success: 1\n",
            "Episode: 40516, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3665041\n",
            "Moving Average (Training): 1525.05, Success: 0\n",
            "Episode: 40517, Total Reward: 1125.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3665155\n",
            "Moving Average (Training): 1521.19, Success: 0\n",
            "Episode: 40518, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 117, Step Count: 3665272\n",
            "Moving Average (Training): 1518.37, Success: 0\n",
            "Episode: 40519, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3665465\n",
            "Moving Average (Training): 1527.47, Success: 0\n",
            "Episode: 40520, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3665574\n",
            "Moving Average (Training): 1517.38, Success: 0\n",
            "Episode: 40521, Total Reward: 2103.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 245, Step Count: 3665819\n",
            "Moving Average (Training): 1517.28, Success: 0\n",
            "Episode: 40522, Total Reward: 2166.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3666021\n",
            "Moving Average (Training): 1526.74, Success: 1\n",
            "Episode: 40523, Total Reward: 2164.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3666226\n",
            "Moving Average (Training): 1535.92, Success: 1\n",
            "Episode: 40524, Total Reward: 492.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 53, Step Count: 3666279\n",
            "Moving Average (Training): 1519.64, Success: 0\n",
            "Episode: 40525, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3666480\n",
            "Moving Average (Training): 1519.81, Success: 1\n",
            "Episode: 40526, Total Reward: 2100.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3666680\n",
            "Moving Average (Training): 1519.5, Success: 0\n",
            "Episode: 40527, Total Reward: 2168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 210, Step Count: 3666890\n",
            "Moving Average (Training): 1519.31, Success: 1\n",
            "Episode: 40528, Total Reward: 2089.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 195, Step Count: 3667085\n",
            "Moving Average (Training): 1533.13, Success: 0\n",
            "Episode: 40529, Total Reward: 2124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3667275\n",
            "Moving Average (Training): 1532.58, Success: 0\n",
            "Episode: 40530, Total Reward: 1229.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3667389\n",
            "Moving Average (Training): 1533.5, Success: 0\n",
            "Episode: 40531, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3667579\n",
            "Moving Average (Training): 1533.04, Success: 0\n",
            "Episode: 40532, Total Reward: 1899.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 180, Step Count: 3667759\n",
            "Moving Average (Training): 1550.31, Success: 0\n",
            "Episode: 40533, Total Reward: 1237.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3667872\n",
            "Moving Average (Training): 1541.45, Success: 0\n",
            "Episode: 40534, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3668062\n",
            "Moving Average (Training): 1552.98, Success: 0\n",
            "Episode: 40535, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3668178\n",
            "Moving Average (Training): 1553.45, Success: 0\n",
            "Episode: 40536, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3668369\n",
            "Moving Average (Training): 1553.05, Success: 0\n",
            "Episode: 40537, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3668483\n",
            "Moving Average (Training): 1553.88, Success: 0\n",
            "Episode: 40538, Total Reward: 1874.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 178, Step Count: 3668661\n",
            "Moving Average (Training): 1553.69, Success: 0\n",
            "Episode: 40539, Total Reward: 1268.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 137, Step Count: 3668798\n",
            "Moving Average (Training): 1564.65, Success: 0\n",
            "Episode: 40540, Total Reward: 987.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 91, Step Count: 3668889\n",
            "Moving Average (Training): 1572.74, Success: 0\n",
            "Episode: 40541, Total Reward: 177.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3668917\n",
            "Moving Average (Training): 1553.44, Success: 0\n",
            "Episode: 40542, Total Reward: 1503.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 134, Step Count: 3669051\n",
            "Moving Average (Training): 1546.67, Success: 0\n",
            "Episode: 40543, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3669166\n",
            "Moving Average (Training): 1547.16, Success: 0\n",
            "Episode: 40544, Total Reward: 2125.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 214, Step Count: 3669380\n",
            "Moving Average (Training): 1546.54, Success: 0\n",
            "Episode: 40545, Total Reward: 2097.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3669582\n",
            "Moving Average (Training): 1545.74, Success: 0\n",
            "Episode: 40546, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3669771\n",
            "Moving Average (Training): 1545.87, Success: 0\n",
            "Episode: 40547, Total Reward: 173.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3669799\n",
            "Moving Average (Training): 1525.84, Success: 0\n",
            "Episode: 40548, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 482, Step Count: 3670281\n",
            "Moving Average (Training): 1526.14, Success: 1\n",
            "Episode: 40549, Total Reward: 1882.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 178, Step Count: 3670459\n",
            "Moving Average (Training): 1525.27, Success: 0\n",
            "Episode: 40550, Total Reward: 1164.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3670564\n",
            "Moving Average (Training): 1524.73, Success: 0\n",
            "Episode: 40551, Total Reward: 1143.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3670679\n",
            "Moving Average (Training): 1515.05, Success: 0\n",
            "Episode: 40552, Total Reward: 486.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 59, Step Count: 3670738\n",
            "Moving Average (Training): 1508.45, Success: 0\n",
            "Episode: 40553, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3670843\n",
            "Moving Average (Training): 1499.02, Success: 0\n",
            "Episode: 40554, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3671032\n",
            "Moving Average (Training): 1499.03, Success: 0\n",
            "Episode: 40555, Total Reward: 1136.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3671143\n",
            "Moving Average (Training): 1505.5, Success: 0\n",
            "Episode: 40556, Total Reward: 2121.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3671340\n",
            "Moving Average (Training): 1505.42, Success: 0\n",
            "Episode: 40557, Total Reward: 2167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 209, Step Count: 3671549\n",
            "Moving Average (Training): 1505.29, Success: 1\n",
            "Episode: 40558, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3671752\n",
            "Moving Average (Training): 1505.9, Success: 1\n",
            "Episode: 40559, Total Reward: 1221.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3671865\n",
            "Moving Average (Training): 1505.13, Success: 0\n",
            "Episode: 40560, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 53, Step Count: 3671918\n",
            "Moving Average (Training): 1498.26, Success: 0\n",
            "Episode: 40561, Total Reward: 2166.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3672123\n",
            "Moving Average (Training): 1508.21, Success: 1\n",
            "Episode: 40562, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3672234\n",
            "Moving Average (Training): 1499.32, Success: 0\n",
            "Episode: 40563, Total Reward: 2167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3672439\n",
            "Moving Average (Training): 1499.19, Success: 1\n",
            "Episode: 40564, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 206, Step Count: 3672645\n",
            "Moving Average (Training): 1519.32, Success: 1\n",
            "Episode: 40565, Total Reward: 2182.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3672843\n",
            "Moving Average (Training): 1536.29, Success: 1\n",
            "Episode: 40566, Total Reward: 2115.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3673034\n",
            "Moving Average (Training): 1550.75, Success: 0\n",
            "Episode: 40567, Total Reward: 1907.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 175, Step Count: 3673209\n",
            "Moving Average (Training): 1558.85, Success: 0\n",
            "Episode: 40568, Total Reward: 1221.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3673320\n",
            "Moving Average (Training): 1561.39, Success: 0\n",
            "Episode: 40569, Total Reward: 2134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3673509\n",
            "Moving Average (Training): 1571.1, Success: 0\n",
            "Episode: 40570, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3673615\n",
            "Moving Average (Training): 1560.75, Success: 0\n",
            "Episode: 40571, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3673643\n",
            "Moving Average (Training): 1541.22, Success: 0\n",
            "Episode: 40572, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3673747\n",
            "Moving Average (Training): 1540.22, Success: 0\n",
            "Episode: 40573, Total Reward: 671.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 64, Step Count: 3673811\n",
            "Moving Average (Training): 1542.06, Success: 0\n",
            "Episode: 40574, Total Reward: 2186.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 196, Step Count: 3674007\n",
            "Moving Average (Training): 1552.27, Success: 1\n",
            "Episode: 40575, Total Reward: 2124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 435, Step Count: 3674442\n",
            "Moving Average (Training): 1551.65, Success: 1\n",
            "Episode: 40576, Total Reward: 2170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3674644\n",
            "Moving Average (Training): 1552.05, Success: 1\n",
            "Episode: 40577, Total Reward: 2178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 207, Step Count: 3674851\n",
            "Moving Average (Training): 1552.5, Success: 1\n",
            "Episode: 40578, Total Reward: 2167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3675054\n",
            "Moving Average (Training): 1552.33, Success: 1\n",
            "Episode: 40579, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 118, Step Count: 3675172\n",
            "Moving Average (Training): 1553.06, Success: 0\n",
            "Episode: 40580, Total Reward: 2113.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 187, Step Count: 3675359\n",
            "Moving Average (Training): 1561.05, Success: 0\n",
            "Episode: 40581, Total Reward: 1905.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 174, Step Count: 3675533\n",
            "Moving Average (Training): 1566.51, Success: 0\n",
            "Episode: 40582, Total Reward: 1503.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 136, Step Count: 3675669\n",
            "Moving Average (Training): 1576.67, Success: 0\n",
            "Episode: 40583, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3675778\n",
            "Moving Average (Training): 1566.61, Success: 0\n",
            "Episode: 40584, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3675983\n",
            "Moving Average (Training): 1566.64, Success: 0\n",
            "Episode: 40585, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 117, Step Count: 3676100\n",
            "Moving Average (Training): 1572.12, Success: 0\n",
            "Episode: 40586, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3676205\n",
            "Moving Average (Training): 1562.3, Success: 0\n",
            "Episode: 40587, Total Reward: 1222.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3676316\n",
            "Moving Average (Training): 1552.88, Success: 0\n",
            "Episode: 40588, Total Reward: 2178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 250, Step Count: 3676566\n",
            "Moving Average (Training): 1555.62, Success: 1\n",
            "Episode: 40589, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3676681\n",
            "Moving Average (Training): 1556.35, Success: 0\n",
            "Episode: 40590, Total Reward: 1134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3676790\n",
            "Moving Average (Training): 1555.5, Success: 0\n",
            "Episode: 40591, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3676978\n",
            "Moving Average (Training): 1565.33, Success: 0\n",
            "Episode: 40592, Total Reward: 1903.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 180, Step Count: 3677158\n",
            "Moving Average (Training): 1572.68, Success: 0\n",
            "Episode: 40593, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3677347\n",
            "Moving Average (Training): 1581.75, Success: 0\n",
            "Episode: 40594, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3677535\n",
            "Moving Average (Training): 1589.63, Success: 0\n",
            "Episode: 40595, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3677740\n",
            "Moving Average (Training): 1589.58, Success: 0\n",
            "Episode: 40596, Total Reward: 903.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 83, Step Count: 3677823\n",
            "Moving Average (Training): 1583.52, Success: 0\n",
            "Episode: 40597, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3678025\n",
            "Moving Average (Training): 1598.72, Success: 1\n",
            "Episode: 40598, Total Reward: 1144.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3678132\n",
            "Moving Average (Training): 1608.46, Success: 0\n",
            "Episode: 40599, Total Reward: 2134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3678329\n",
            "Moving Average (Training): 1608.47, Success: 0\n",
            "Episode: 40600, Total Reward: 1243.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3678445\n",
            "Moving Average (Training): 1614.19, Success: 0\n",
            "Episode: 40601, Total Reward: 1225.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3678558\n",
            "Moving Average (Training): 1605.29, Success: 0\n",
            "Episode: 40602, Total Reward: 1250.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 150, Step Count: 3678708\n",
            "Moving Average (Training): 1616.01, Success: 0\n",
            "Episode: 40603, Total Reward: 2126.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3678908\n",
            "Moving Average (Training): 1625.56, Success: 0\n",
            "Episode: 40604, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 209, Step Count: 3679117\n",
            "Moving Average (Training): 1635.66, Success: 1\n",
            "Episode: 40605, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3679320\n",
            "Moving Average (Training): 1652.66, Success: 1\n",
            "Episode: 40606, Total Reward: 2167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 212, Step Count: 3679532\n",
            "Moving Average (Training): 1661.96, Success: 1\n",
            "Episode: 40607, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3679644\n",
            "Moving Average (Training): 1661.93, Success: 0\n",
            "Episode: 40608, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3679756\n",
            "Moving Average (Training): 1667.13, Success: 0\n",
            "Episode: 40609, Total Reward: 2162.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 212, Step Count: 3679968\n",
            "Moving Average (Training): 1666.97, Success: 1\n",
            "Episode: 40610, Total Reward: 1124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3680084\n",
            "Moving Average (Training): 1657.04, Success: 0\n",
            "Episode: 40611, Total Reward: 1162.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3680195\n",
            "Moving Average (Training): 1656.95, Success: 0\n",
            "Episode: 40612, Total Reward: 2117.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 214, Step Count: 3680409\n",
            "Moving Average (Training): 1656.24, Success: 0\n",
            "Episode: 40613, Total Reward: 2168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 207, Step Count: 3680616\n",
            "Moving Average (Training): 1656.26, Success: 1\n",
            "Episode: 40614, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3680731\n",
            "Moving Average (Training): 1646.79, Success: 0\n",
            "Episode: 40615, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3680845\n",
            "Moving Average (Training): 1637.08, Success: 0\n",
            "Episode: 40616, Total Reward: 2123.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 206, Step Count: 3681051\n",
            "Moving Average (Training): 1637.02, Success: 0\n",
            "Episode: 40617, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3681079\n",
            "Moving Average (Training): 1627.55, Success: 0\n",
            "Episode: 40618, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3681186\n",
            "Moving Average (Training): 1626.82, Success: 0\n",
            "Episode: 40619, Total Reward: 1233.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3681299\n",
            "Moving Average (Training): 1617.85, Success: 0\n",
            "Episode: 40620, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3681415\n",
            "Moving Average (Training): 1618.31, Success: 0\n",
            "Episode: 40621, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3681529\n",
            "Moving Average (Training): 1609.45, Success: 0\n",
            "Episode: 40622, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3681637\n",
            "Moving Average (Training): 1599.5, Success: 0\n",
            "Episode: 40623, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3681841\n",
            "Moving Average (Training): 1599.73, Success: 1\n",
            "Episode: 40624, Total Reward: 1221.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 117, Step Count: 3681958\n",
            "Moving Average (Training): 1607.02, Success: 0\n",
            "Episode: 40625, Total Reward: 1261.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 141, Step Count: 3682099\n",
            "Moving Average (Training): 1597.76, Success: 0\n",
            "Episode: 40626, Total Reward: 174.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3682127\n",
            "Moving Average (Training): 1578.5, Success: 0\n",
            "Episode: 40627, Total Reward: 1115.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 164, Step Count: 3682291\n",
            "Moving Average (Training): 1567.97, Success: 0\n",
            "Episode: 40628, Total Reward: 670.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 66, Step Count: 3682357\n",
            "Moving Average (Training): 1553.78, Success: 0\n",
            "Episode: 40629, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3682412\n",
            "Moving Average (Training): 1537.39, Success: 0\n",
            "Episode: 40630, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3682615\n",
            "Moving Average (Training): 1546.97, Success: 1\n",
            "Episode: 40631, Total Reward: 2136.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3682812\n",
            "Moving Average (Training): 1547.0, Success: 0\n",
            "Episode: 40632, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3682918\n",
            "Moving Average (Training): 1539.46, Success: 0\n",
            "Episode: 40633, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3683109\n",
            "Moving Average (Training): 1548.37, Success: 0\n",
            "Episode: 40634, Total Reward: 2134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3683297\n",
            "Moving Average (Training): 1548.42, Success: 0\n",
            "Episode: 40635, Total Reward: 1970.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 1291, Step Count: 3684588\n",
            "Moving Average (Training): 1555.94, Success: 1\n",
            "Episode: 40636, Total Reward: 2134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3684777\n",
            "Moving Average (Training): 1555.95, Success: 0\n",
            "Episode: 40637, Total Reward: 1163.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3684890\n",
            "Moving Average (Training): 1555.39, Success: 0\n",
            "Episode: 40638, Total Reward: 1235.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3685003\n",
            "Moving Average (Training): 1549.0, Success: 0\n",
            "Episode: 40639, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 215, Step Count: 3685218\n",
            "Moving Average (Training): 1557.59, Success: 0\n",
            "Episode: 40640, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3685329\n",
            "Moving Average (Training): 1559.91, Success: 0\n",
            "Episode: 40641, Total Reward: 1222.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3685440\n",
            "Moving Average (Training): 1570.36, Success: 0\n",
            "Episode: 40642, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3685629\n",
            "Moving Average (Training): 1576.63, Success: 0\n",
            "Episode: 40643, Total Reward: 673.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 65, Step Count: 3685694\n",
            "Moving Average (Training): 1571.18, Success: 0\n",
            "Episode: 40644, Total Reward: 2182.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 217, Step Count: 3685911\n",
            "Moving Average (Training): 1571.75, Success: 1\n",
            "Episode: 40645, Total Reward: 1503.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 146, Step Count: 3686057\n",
            "Moving Average (Training): 1565.81, Success: 0\n",
            "Episode: 40646, Total Reward: 2174.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 242, Step Count: 3686299\n",
            "Moving Average (Training): 1566.26, Success: 1\n",
            "Episode: 40647, Total Reward: 2184.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3686499\n",
            "Moving Average (Training): 1586.37, Success: 1\n",
            "Episode: 40648, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3686615\n",
            "Moving Average (Training): 1577.23, Success: 0\n",
            "Episode: 40649, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3686729\n",
            "Moving Average (Training): 1570.6, Success: 0\n",
            "Episode: 40650, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3686919\n",
            "Moving Average (Training): 1580.24, Success: 0\n",
            "Episode: 40651, Total Reward: 2178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 211, Step Count: 3687130\n",
            "Moving Average (Training): 1590.59, Success: 1\n",
            "Episode: 40652, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3687332\n",
            "Moving Average (Training): 1607.02, Success: 0\n",
            "Episode: 40653, Total Reward: 1245.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3687448\n",
            "Moving Average (Training): 1608.02, Success: 0\n",
            "Episode: 40654, Total Reward: 1237.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3687560\n",
            "Moving Average (Training): 1599.09, Success: 0\n",
            "Episode: 40655, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3687665\n",
            "Moving Average (Training): 1599.18, Success: 0\n",
            "Episode: 40656, Total Reward: 488.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 56, Step Count: 3687721\n",
            "Moving Average (Training): 1582.85, Success: 0\n",
            "Episode: 40657, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3687835\n",
            "Moving Average (Training): 1573.37, Success: 0\n",
            "Episode: 40658, Total Reward: 369.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 39, Step Count: 3687874\n",
            "Moving Average (Training): 1555.18, Success: 0\n",
            "Episode: 40659, Total Reward: 487.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3687929\n",
            "Moving Average (Training): 1547.84, Success: 0\n",
            "Episode: 40660, Total Reward: 174.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3687957\n",
            "Moving Average (Training): 1544.73, Success: 0\n",
            "Episode: 40661, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3688065\n",
            "Moving Average (Training): 1534.78, Success: 0\n",
            "Episode: 40662, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3688262\n",
            "Moving Average (Training): 1544.47, Success: 1\n",
            "Episode: 40663, Total Reward: 2166.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3688464\n",
            "Moving Average (Training): 1544.46, Success: 1\n",
            "Episode: 40664, Total Reward: 2169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3688668\n",
            "Moving Average (Training): 1544.34, Success: 1\n",
            "Episode: 40665, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3688722\n",
            "Moving Average (Training): 1527.37, Success: 0\n",
            "Episode: 40666, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 209, Step Count: 3688931\n",
            "Moving Average (Training): 1527.55, Success: 0\n",
            "Episode: 40667, Total Reward: 2125.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 215, Step Count: 3689146\n",
            "Moving Average (Training): 1529.73, Success: 0\n",
            "Episode: 40668, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3689337\n",
            "Moving Average (Training): 1538.83, Success: 0\n",
            "Episode: 40669, Total Reward: 2172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 237, Step Count: 3689574\n",
            "Moving Average (Training): 1539.21, Success: 1\n",
            "Episode: 40670, Total Reward: 486.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 56, Step Count: 3689630\n",
            "Moving Average (Training): 1532.61, Success: 0\n",
            "Episode: 40671, Total Reward: 2086.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3689819\n",
            "Moving Average (Training): 1551.69, Success: 0\n",
            "Episode: 40672, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3689931\n",
            "Moving Average (Training): 1552.41, Success: 0\n",
            "Episode: 40673, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3690121\n",
            "Moving Average (Training): 1566.99, Success: 0\n",
            "Episode: 40674, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3690322\n",
            "Moving Average (Training): 1566.93, Success: 1\n",
            "Episode: 40675, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3690429\n",
            "Moving Average (Training): 1557.14, Success: 0\n",
            "Episode: 40676, Total Reward: 2134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3690618\n",
            "Moving Average (Training): 1556.78, Success: 0\n",
            "Episode: 40677, Total Reward: 486.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3690673\n",
            "Moving Average (Training): 1539.86, Success: 0\n",
            "Episode: 40678, Total Reward: 492.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 52, Step Count: 3690725\n",
            "Moving Average (Training): 1523.11, Success: 0\n",
            "Episode: 40679, Total Reward: 492.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 57, Step Count: 3690782\n",
            "Moving Average (Training): 1515.85, Success: 0\n",
            "Episode: 40680, Total Reward: 686.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 66, Step Count: 3690848\n",
            "Moving Average (Training): 1501.58, Success: 0\n",
            "Episode: 40681, Total Reward: 379.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 40, Step Count: 3690888\n",
            "Moving Average (Training): 1486.32, Success: 0\n",
            "Episode: 40682, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3690996\n",
            "Moving Average (Training): 1483.0, Success: 0\n",
            "Episode: 40683, Total Reward: 372.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 41, Step Count: 3691037\n",
            "Moving Average (Training): 1475.0, Success: 0\n",
            "Episode: 40684, Total Reward: 1961.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 1330, Step Count: 3692367\n",
            "Moving Average (Training): 1473.3, Success: 1\n",
            "Episode: 40685, Total Reward: 2106.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3692569\n",
            "Moving Average (Training): 1482.17, Success: 0\n",
            "Episode: 40686, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 207, Step Count: 3692776\n",
            "Moving Average (Training): 1492.51, Success: 1\n",
            "Episode: 40687, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3692967\n",
            "Moving Average (Training): 1501.61, Success: 0\n",
            "Episode: 40688, Total Reward: 1125.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3693080\n",
            "Moving Average (Training): 1491.08, Success: 0\n",
            "Episode: 40689, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3693187\n",
            "Moving Average (Training): 1490.36, Success: 0\n",
            "Episode: 40690, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3693378\n",
            "Moving Average (Training): 1500.3, Success: 0\n",
            "Episode: 40691, Total Reward: 2182.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3693579\n",
            "Moving Average (Training): 1500.84, Success: 1\n",
            "Episode: 40692, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3693684\n",
            "Moving Average (Training): 1493.27, Success: 0\n",
            "Episode: 40693, Total Reward: 2184.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3693886\n",
            "Moving Average (Training): 1493.81, Success: 1\n",
            "Episode: 40694, Total Reward: 170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3693914\n",
            "Moving Average (Training): 1474.18, Success: 0\n",
            "Episode: 40695, Total Reward: 1166.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3694027\n",
            "Moving Average (Training): 1464.57, Success: 0\n",
            "Episode: 40696, Total Reward: 2183.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 229, Step Count: 3694256\n",
            "Moving Average (Training): 1477.37, Success: 1\n",
            "Episode: 40697, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3694458\n",
            "Moving Average (Training): 1477.37, Success: 1\n",
            "Episode: 40698, Total Reward: 2175.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3694661\n",
            "Moving Average (Training): 1487.68, Success: 1\n",
            "Episode: 40699, Total Reward: 494.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3694715\n",
            "Moving Average (Training): 1471.28, Success: 0\n",
            "Episode: 40700, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3694908\n",
            "Moving Average (Training): 1480.15, Success: 0\n",
            "Episode: 40701, Total Reward: 2114.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3695098\n",
            "Moving Average (Training): 1489.04, Success: 0\n",
            "Episode: 40702, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 195, Step Count: 3695293\n",
            "Moving Average (Training): 1498.41, Success: 1\n",
            "Episode: 40703, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3695484\n",
            "Moving Average (Training): 1498.42, Success: 0\n",
            "Episode: 40704, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3695672\n",
            "Moving Average (Training): 1497.92, Success: 0\n",
            "Episode: 40705, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3695865\n",
            "Moving Average (Training): 1497.33, Success: 0\n",
            "Episode: 40706, Total Reward: 1288.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 133, Step Count: 3695998\n",
            "Moving Average (Training): 1488.54, Success: 0\n",
            "Episode: 40707, Total Reward: 488.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3696053\n",
            "Moving Average (Training): 1481.25, Success: 0\n",
            "Episode: 40708, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 53, Step Count: 3696106\n",
            "Moving Average (Training): 1473.87, Success: 0\n",
            "Episode: 40709, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3696161\n",
            "Moving Average (Training): 1457.1, Success: 0\n",
            "Episode: 40710, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3696266\n",
            "Moving Average (Training): 1457.31, Success: 0\n",
            "Episode: 40711, Total Reward: 2185.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 219, Step Count: 3696485\n",
            "Moving Average (Training): 1467.54, Success: 1\n",
            "Episode: 40712, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 213, Step Count: 3696698\n",
            "Moving Average (Training): 1468.16, Success: 1\n",
            "Episode: 40713, Total Reward: 2116.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3696898\n",
            "Moving Average (Training): 1467.64, Success: 0\n",
            "Episode: 40714, Total Reward: 1765.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 195, Step Count: 3697093\n",
            "Moving Average (Training): 1473.1, Success: 0\n",
            "Episode: 40715, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3697294\n",
            "Moving Average (Training): 1482.81, Success: 1\n",
            "Episode: 40716, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3697407\n",
            "Moving Average (Training): 1473.75, Success: 0\n",
            "Episode: 40717, Total Reward: 1222.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3697519\n",
            "Moving Average (Training): 1484.19, Success: 0\n",
            "Episode: 40718, Total Reward: 2125.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3697708\n",
            "Moving Average (Training): 1493.98, Success: 0\n",
            "Episode: 40719, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3697899\n",
            "Moving Average (Training): 1502.95, Success: 0\n",
            "Episode: 40720, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3698006\n",
            "Moving Average (Training): 1502.23, Success: 0\n",
            "Episode: 40721, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3698210\n",
            "Moving Average (Training): 1511.93, Success: 1\n",
            "Episode: 40722, Total Reward: 1144.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3698319\n",
            "Moving Average (Training): 1511.66, Success: 0\n",
            "Episode: 40723, Total Reward: 2185.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 196, Step Count: 3698515\n",
            "Moving Average (Training): 1511.64, Success: 1\n",
            "Episode: 40724, Total Reward: 2167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 216, Step Count: 3698731\n",
            "Moving Average (Training): 1521.1, Success: 1\n",
            "Episode: 40725, Total Reward: 1169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3698840\n",
            "Moving Average (Training): 1520.18, Success: 0\n",
            "Episode: 40726, Total Reward: 1147.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3698945\n",
            "Moving Average (Training): 1529.91, Success: 0\n",
            "Episode: 40727, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3698973\n",
            "Moving Average (Training): 1520.54, Success: 0\n",
            "Episode: 40728, Total Reward: 1882.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 175, Step Count: 3699148\n",
            "Moving Average (Training): 1532.66, Success: 0\n",
            "Episode: 40729, Total Reward: 670.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 71, Step Count: 3699219\n",
            "Moving Average (Training): 1534.51, Success: 0\n",
            "Episode: 40730, Total Reward: 2121.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 250, Step Count: 3699469\n",
            "Moving Average (Training): 1533.85, Success: 0\n",
            "Episode: 40731, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3699581\n",
            "Moving Average (Training): 1524.67, Success: 0\n",
            "Episode: 40732, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3699694\n",
            "Moving Average (Training): 1525.45, Success: 0\n",
            "Episode: 40733, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3699883\n",
            "Moving Average (Training): 1525.46, Success: 0\n",
            "Episode: 40734, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3699996\n",
            "Moving Average (Training): 1516.29, Success: 0\n",
            "Episode: 40735, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3700186\n",
            "Moving Average (Training): 1517.92, Success: 0\n",
            "Episode: 40736, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3700301\n",
            "Moving Average (Training): 1508.75, Success: 0\n",
            "Episode: 40737, Total Reward: 2086.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 215, Step Count: 3700516\n",
            "Moving Average (Training): 1517.98, Success: 0\n",
            "Episode: 40738, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3700630\n",
            "Moving Average (Training): 1517.86, Success: 0\n",
            "Episode: 40739, Total Reward: 974.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 89, Step Count: 3700719\n",
            "Moving Average (Training): 1506.33, Success: 0\n",
            "Episode: 40740, Total Reward: 483.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 56, Step Count: 3700775\n",
            "Moving Average (Training): 1498.97, Success: 0\n",
            "Episode: 40741, Total Reward: 2101.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3700976\n",
            "Moving Average (Training): 1507.76, Success: 0\n",
            "Episode: 40742, Total Reward: 1236.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3701090\n",
            "Moving Average (Training): 1498.82, Success: 0\n",
            "Episode: 40743, Total Reward: 173.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 29, Step Count: 3701119\n",
            "Moving Average (Training): 1493.82, Success: 0\n",
            "Episode: 40744, Total Reward: 1144.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3701225\n",
            "Moving Average (Training): 1483.44, Success: 0\n",
            "Episode: 40745, Total Reward: 2094.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3701413\n",
            "Moving Average (Training): 1489.35, Success: 0\n",
            "Episode: 40746, Total Reward: 1142.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3701527\n",
            "Moving Average (Training): 1479.03, Success: 0\n",
            "Episode: 40747, Total Reward: 670.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 65, Step Count: 3701592\n",
            "Moving Average (Training): 1463.89, Success: 0\n",
            "Episode: 40748, Total Reward: 2178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3701793\n",
            "Moving Average (Training): 1473.5, Success: 1\n",
            "Episode: 40749, Total Reward: 2164.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3701996\n",
            "Moving Average (Training): 1482.95, Success: 1\n",
            "Episode: 40750, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3702185\n",
            "Moving Average (Training): 1482.95, Success: 0\n",
            "Episode: 40751, Total Reward: 1168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3702297\n",
            "Moving Average (Training): 1472.85, Success: 0\n",
            "Episode: 40752, Total Reward: 2171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3702495\n",
            "Moving Average (Training): 1473.27, Success: 1\n",
            "Episode: 40753, Total Reward: 484.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 59, Step Count: 3702554\n",
            "Moving Average (Training): 1465.66, Success: 0\n",
            "Episode: 40754, Total Reward: 2185.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 196, Step Count: 3702750\n",
            "Moving Average (Training): 1475.14, Success: 1\n",
            "Episode: 40755, Total Reward: 1139.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 117, Step Count: 3702867\n",
            "Moving Average (Training): 1475.08, Success: 0\n",
            "Episode: 40756, Total Reward: 1266.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 142, Step Count: 3703009\n",
            "Moving Average (Training): 1482.86, Success: 0\n",
            "Episode: 40757, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3703212\n",
            "Moving Average (Training): 1492.54, Success: 1\n",
            "Episode: 40758, Total Reward: 2120.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3703411\n",
            "Moving Average (Training): 1510.05, Success: 0\n",
            "Episode: 40759, Total Reward: 177.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3703439\n",
            "Moving Average (Training): 1506.95, Success: 0\n",
            "Episode: 40760, Total Reward: 2134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3703630\n",
            "Moving Average (Training): 1526.55, Success: 0\n",
            "Episode: 40761, Total Reward: 1170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3703738\n",
            "Moving Average (Training): 1526.54, Success: 0\n",
            "Episode: 40762, Total Reward: 1246.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 148, Step Count: 3703886\n",
            "Moving Average (Training): 1517.12, Success: 0\n",
            "Episode: 40763, Total Reward: 2111.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3704075\n",
            "Moving Average (Training): 1516.57, Success: 0\n",
            "Episode: 40764, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3704183\n",
            "Moving Average (Training): 1506.59, Success: 0\n",
            "Episode: 40765, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3704237\n",
            "Moving Average (Training): 1506.59, Success: 0\n",
            "Episode: 40766, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3704427\n",
            "Moving Average (Training): 1506.54, Success: 0\n",
            "Episode: 40767, Total Reward: 2098.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 206, Step Count: 3704633\n",
            "Moving Average (Training): 1506.27, Success: 0\n",
            "Episode: 40768, Total Reward: 954.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 88, Step Count: 3704721\n",
            "Moving Average (Training): 1494.5, Success: 0\n",
            "Episode: 40769, Total Reward: 2182.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3704925\n",
            "Moving Average (Training): 1494.6, Success: 1\n",
            "Episode: 40770, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3705037\n",
            "Moving Average (Training): 1501.92, Success: 0\n",
            "Episode: 40771, Total Reward: 685.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 67, Step Count: 3705104\n",
            "Moving Average (Training): 1487.91, Success: 0\n",
            "Episode: 40772, Total Reward: 673.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 64, Step Count: 3705168\n",
            "Moving Average (Training): 1482.46, Success: 0\n",
            "Episode: 40773, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3705359\n",
            "Moving Average (Training): 1482.48, Success: 0\n",
            "Episode: 40774, Total Reward: 489.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3705414\n",
            "Moving Average (Training): 1465.57, Success: 0\n",
            "Episode: 40775, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3705527\n",
            "Moving Average (Training): 1466.35, Success: 0\n",
            "Episode: 40776, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3705635\n",
            "Moving Average (Training): 1456.47, Success: 0\n",
            "Episode: 40777, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3705840\n",
            "Moving Average (Training): 1473.41, Success: 1\n",
            "Episode: 40778, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3705956\n",
            "Moving Average (Training): 1480.66, Success: 0\n",
            "Episode: 40779, Total Reward: 2125.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 217, Step Count: 3706173\n",
            "Moving Average (Training): 1496.99, Success: 0\n",
            "Episode: 40780, Total Reward: 2185.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3706373\n",
            "Moving Average (Training): 1511.98, Success: 1\n",
            "Episode: 40781, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3706485\n",
            "Moving Average (Training): 1520.42, Success: 0\n",
            "Episode: 40782, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3706590\n",
            "Moving Average (Training): 1520.17, Success: 0\n",
            "Episode: 40783, Total Reward: 671.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 67, Step Count: 3706657\n",
            "Moving Average (Training): 1523.16, Success: 0\n",
            "Episode: 40784, Total Reward: 2117.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3706862\n",
            "Moving Average (Training): 1524.72, Success: 0\n",
            "Episode: 40785, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 206, Step Count: 3707068\n",
            "Moving Average (Training): 1525.46, Success: 1\n",
            "Episode: 40786, Total Reward: 952.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 94, Step Count: 3707162\n",
            "Moving Average (Training): 1513.18, Success: 0\n",
            "Episode: 40787, Total Reward: 2167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3707363\n",
            "Moving Average (Training): 1513.53, Success: 1\n",
            "Episode: 40788, Total Reward: 1901.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 175, Step Count: 3707538\n",
            "Moving Average (Training): 1521.29, Success: 0\n",
            "Episode: 40789, Total Reward: 987.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 95, Step Count: 3707633\n",
            "Moving Average (Training): 1519.7, Success: 0\n",
            "Episode: 40790, Total Reward: 2167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3707834\n",
            "Moving Average (Training): 1520.09, Success: 1\n",
            "Episode: 40791, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3707889\n",
            "Moving Average (Training): 1503.12, Success: 0\n",
            "Episode: 40792, Total Reward: 2121.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3708089\n",
            "Moving Average (Training): 1512.87, Success: 0\n",
            "Episode: 40793, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3708195\n",
            "Moving Average (Training): 1502.49, Success: 0\n",
            "Episode: 40794, Total Reward: 1222.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3708308\n",
            "Moving Average (Training): 1513.01, Success: 0\n",
            "Episode: 40795, Total Reward: 979.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 92, Step Count: 3708400\n",
            "Moving Average (Training): 1511.14, Success: 0\n",
            "Episode: 40796, Total Reward: 1147.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3708504\n",
            "Moving Average (Training): 1500.78, Success: 0\n",
            "Episode: 40797, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3708708\n",
            "Moving Average (Training): 1500.7, Success: 1\n",
            "Episode: 40798, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3708909\n",
            "Moving Average (Training): 1500.22, Success: 0\n",
            "Episode: 40799, Total Reward: 1164.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3709017\n",
            "Moving Average (Training): 1506.92, Success: 0\n",
            "Episode: 40800, Total Reward: 2080.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 736, Step Count: 3709753\n",
            "Moving Average (Training): 1506.42, Success: 1\n",
            "Episode: 40801, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3709950\n",
            "Moving Average (Training): 1506.55, Success: 0\n",
            "Episode: 40802, Total Reward: 1162.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3710060\n",
            "Moving Average (Training): 1496.3, Success: 0\n",
            "Episode: 40803, Total Reward: 170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3710088\n",
            "Moving Average (Training): 1476.73, Success: 0\n",
            "Episode: 40804, Total Reward: 1899.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 182, Step Count: 3710270\n",
            "Moving Average (Training): 1474.43, Success: 0\n",
            "Episode: 40805, Total Reward: 1506.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 137, Step Count: 3710407\n",
            "Moving Average (Training): 1468.2, Success: 0\n",
            "Episode: 40806, Total Reward: 2144.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 219, Step Count: 3710626\n",
            "Moving Average (Training): 1476.76, Success: 0\n",
            "Episode: 40807, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3710738\n",
            "Moving Average (Training): 1484.05, Success: 0\n",
            "Episode: 40808, Total Reward: 1170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3710846\n",
            "Moving Average (Training): 1490.9, Success: 0\n",
            "Episode: 40809, Total Reward: 1144.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3710956\n",
            "Moving Average (Training): 1497.49, Success: 0\n",
            "Episode: 40810, Total Reward: 373.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 40, Step Count: 3710996\n",
            "Moving Average (Training): 1489.77, Success: 0\n",
            "Episode: 40811, Total Reward: 483.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 60, Step Count: 3711056\n",
            "Moving Average (Training): 1472.75, Success: 0\n",
            "Episode: 40812, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3711163\n",
            "Moving Average (Training): 1462.41, Success: 0\n",
            "Episode: 40813, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3711271\n",
            "Moving Average (Training): 1452.7, Success: 0\n",
            "Episode: 40814, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3711385\n",
            "Moving Average (Training): 1447.24, Success: 0\n",
            "Episode: 40815, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3711491\n",
            "Moving Average (Training): 1436.81, Success: 0\n",
            "Episode: 40816, Total Reward: 489.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3711546\n",
            "Moving Average (Training): 1429.53, Success: 0\n",
            "Episode: 40817, Total Reward: 1143.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3711651\n",
            "Moving Average (Training): 1428.74, Success: 0\n",
            "Episode: 40818, Total Reward: 2164.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3711855\n",
            "Moving Average (Training): 1429.13, Success: 1\n",
            "Episode: 40819, Total Reward: 488.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 59, Step Count: 3711914\n",
            "Moving Average (Training): 1412.71, Success: 0\n",
            "Episode: 40820, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3712027\n",
            "Moving Average (Training): 1413.44, Success: 0\n",
            "Episode: 40821, Total Reward: 2174.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3712231\n",
            "Moving Average (Training): 1413.31, Success: 1\n",
            "Episode: 40822, Total Reward: 1236.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3712342\n",
            "Moving Average (Training): 1414.23, Success: 0\n",
            "Episode: 40823, Total Reward: 1170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3712449\n",
            "Moving Average (Training): 1404.08, Success: 0\n",
            "Episode: 40824, Total Reward: 2182.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3712650\n",
            "Moving Average (Training): 1404.23, Success: 1\n",
            "Episode: 40825, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3712840\n",
            "Moving Average (Training): 1413.85, Success: 0\n",
            "Episode: 40826, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3712868\n",
            "Moving Average (Training): 1404.16, Success: 0\n",
            "Episode: 40827, Total Reward: 2166.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3713072\n",
            "Moving Average (Training): 1424.04, Success: 1\n",
            "Episode: 40828, Total Reward: 1234.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3713188\n",
            "Moving Average (Training): 1417.56, Success: 0\n",
            "Episode: 40829, Total Reward: 1505.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 143, Step Count: 3713331\n",
            "Moving Average (Training): 1425.91, Success: 0\n",
            "Episode: 40830, Total Reward: 1163.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3713438\n",
            "Moving Average (Training): 1416.33, Success: 0\n",
            "Episode: 40831, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3713550\n",
            "Moving Average (Training): 1416.38, Success: 0\n",
            "Episode: 40832, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3713578\n",
            "Moving Average (Training): 1405.93, Success: 0\n",
            "Episode: 40833, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3713606\n",
            "Moving Average (Training): 1386.42, Success: 0\n",
            "Episode: 40834, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3713634\n",
            "Moving Average (Training): 1376.03, Success: 0\n",
            "Episode: 40835, Total Reward: 177.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3713662\n",
            "Moving Average (Training): 1356.47, Success: 0\n",
            "Episode: 40836, Total Reward: 1143.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3713769\n",
            "Moving Average (Training): 1355.73, Success: 0\n",
            "Episode: 40837, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3713875\n",
            "Moving Average (Training): 1346.32, Success: 0\n",
            "Episode: 40838, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 117, Step Count: 3713992\n",
            "Moving Average (Training): 1345.55, Success: 0\n",
            "Episode: 40839, Total Reward: 1117.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 119, Step Count: 3714111\n",
            "Moving Average (Training): 1346.98, Success: 0\n",
            "Episode: 40840, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3714217\n",
            "Moving Average (Training): 1353.6, Success: 0\n",
            "Episode: 40841, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3714326\n",
            "Moving Average (Training): 1344.3, Success: 0\n",
            "Episode: 40842, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3714525\n",
            "Moving Average (Training): 1353.82, Success: 1\n",
            "Episode: 40843, Total Reward: 1227.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3714636\n",
            "Moving Average (Training): 1364.36, Success: 0\n",
            "Episode: 40844, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3714690\n",
            "Moving Average (Training): 1357.77, Success: 0\n",
            "Episode: 40845, Total Reward: 487.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 52, Step Count: 3714742\n",
            "Moving Average (Training): 1341.7, Success: 0\n",
            "Episode: 40846, Total Reward: 489.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3714797\n",
            "Moving Average (Training): 1335.17, Success: 0\n",
            "Episode: 40847, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3714901\n",
            "Moving Average (Training): 1339.93, Success: 0\n",
            "Episode: 40848, Total Reward: 2103.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 276, Step Count: 3715177\n",
            "Moving Average (Training): 1339.18, Success: 0\n",
            "Episode: 40849, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3715366\n",
            "Moving Average (Training): 1338.86, Success: 0\n",
            "Episode: 40850, Total Reward: 491.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 53, Step Count: 3715419\n",
            "Moving Average (Training): 1322.49, Success: 0\n",
            "Episode: 40851, Total Reward: 1170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3715527\n",
            "Moving Average (Training): 1322.51, Success: 0\n",
            "Episode: 40852, Total Reward: 1147.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3715632\n",
            "Moving Average (Training): 1312.27, Success: 0\n",
            "Episode: 40853, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3715823\n",
            "Moving Average (Training): 1328.74, Success: 0\n",
            "Episode: 40854, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3715932\n",
            "Moving Average (Training): 1318.6, Success: 0\n",
            "Episode: 40855, Total Reward: 2114.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 206, Step Count: 3716138\n",
            "Moving Average (Training): 1328.35, Success: 0\n",
            "Episode: 40856, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3716248\n",
            "Moving Average (Training): 1327.4, Success: 0\n",
            "Episode: 40857, Total Reward: 1144.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3716355\n",
            "Moving Average (Training): 1316.97, Success: 0\n",
            "Episode: 40858, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3716553\n",
            "Moving Average (Training): 1317.64, Success: 1\n",
            "Episode: 40859, Total Reward: 1222.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3716665\n",
            "Moving Average (Training): 1328.09, Success: 0\n",
            "Episode: 40860, Total Reward: 1144.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3716770\n",
            "Moving Average (Training): 1318.19, Success: 0\n",
            "Episode: 40861, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3716882\n",
            "Moving Average (Training): 1318.72, Success: 0\n",
            "Episode: 40862, Total Reward: 167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 33, Step Count: 3716915\n",
            "Moving Average (Training): 1307.93, Success: 0\n",
            "Episode: 40863, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3717023\n",
            "Moving Average (Training): 1298.54, Success: 0\n",
            "Episode: 40864, Total Reward: 172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 29, Step Count: 3717052\n",
            "Moving Average (Training): 1288.55, Success: 0\n",
            "Episode: 40865, Total Reward: 1503.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 147, Step Count: 3717199\n",
            "Moving Average (Training): 1298.73, Success: 0\n",
            "Episode: 40866, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3717401\n",
            "Moving Average (Training): 1299.26, Success: 1\n",
            "Episode: 40867, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3717600\n",
            "Moving Average (Training): 1300.08, Success: 1\n",
            "Episode: 40868, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3717791\n",
            "Moving Average (Training): 1311.82, Success: 0\n",
            "Episode: 40869, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3717981\n",
            "Moving Average (Training): 1311.29, Success: 0\n",
            "Episode: 40870, Total Reward: 2118.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3718170\n",
            "Moving Average (Training): 1320.29, Success: 0\n",
            "Episode: 40871, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3718278\n",
            "Moving Average (Training): 1324.89, Success: 0\n",
            "Episode: 40872, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3718306\n",
            "Moving Average (Training): 1319.94, Success: 0\n",
            "Episode: 40873, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 187, Step Count: 3718493\n",
            "Moving Average (Training): 1319.96, Success: 0\n",
            "Episode: 40874, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3718683\n",
            "Moving Average (Training): 1336.38, Success: 0\n",
            "Episode: 40875, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 192, Step Count: 3718875\n",
            "Moving Average (Training): 1345.96, Success: 1\n",
            "Episode: 40876, Total Reward: 1147.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3718980\n",
            "Moving Average (Training): 1345.97, Success: 0\n",
            "Episode: 40877, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3719183\n",
            "Moving Average (Training): 1345.97, Success: 1\n",
            "Episode: 40878, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3719374\n",
            "Moving Average (Training): 1355.07, Success: 0\n",
            "Episode: 40879, Total Reward: 2167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3719576\n",
            "Moving Average (Training): 1355.49, Success: 1\n",
            "Episode: 40880, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3719780\n",
            "Moving Average (Training): 1355.45, Success: 1\n",
            "Episode: 40881, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3719834\n",
            "Moving Average (Training): 1348.07, Success: 0\n",
            "Episode: 40882, Total Reward: 487.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3719889\n",
            "Moving Average (Training): 1341.48, Success: 0\n",
            "Episode: 40883, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3720078\n",
            "Moving Average (Training): 1356.08, Success: 0\n",
            "Episode: 40884, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3720191\n",
            "Moving Average (Training): 1347.1, Success: 0\n",
            "Episode: 40885, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3720396\n",
            "Moving Average (Training): 1347.18, Success: 1\n",
            "Episode: 40886, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3720501\n",
            "Moving Average (Training): 1349.12, Success: 0\n",
            "Episode: 40887, Total Reward: 2122.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 214, Step Count: 3720715\n",
            "Moving Average (Training): 1348.67, Success: 0\n",
            "Episode: 40888, Total Reward: 1892.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 176, Step Count: 3720891\n",
            "Moving Average (Training): 1348.58, Success: 0\n",
            "Episode: 40889, Total Reward: 2126.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3721082\n",
            "Moving Average (Training): 1359.97, Success: 0\n",
            "Episode: 40890, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3721286\n",
            "Moving Average (Training): 1360.18, Success: 1\n",
            "Episode: 40891, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3721479\n",
            "Moving Average (Training): 1376.65, Success: 0\n",
            "Episode: 40892, Total Reward: 985.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 92, Step Count: 3721571\n",
            "Moving Average (Training): 1365.29, Success: 0\n",
            "Episode: 40893, Total Reward: 2169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 210, Step Count: 3721781\n",
            "Moving Average (Training): 1375.52, Success: 1\n",
            "Episode: 40894, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3721893\n",
            "Moving Average (Training): 1375.49, Success: 0\n",
            "Episode: 40895, Total Reward: 687.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 66, Step Count: 3721959\n",
            "Moving Average (Training): 1372.57, Success: 0\n",
            "Episode: 40896, Total Reward: 1896.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 176, Step Count: 3722135\n",
            "Moving Average (Training): 1380.06, Success: 0\n",
            "Episode: 40897, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3722249\n",
            "Moving Average (Training): 1370.45, Success: 0\n",
            "Episode: 40898, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3722449\n",
            "Moving Average (Training): 1370.49, Success: 0\n",
            "Episode: 40899, Total Reward: 674.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 65, Step Count: 3722514\n",
            "Moving Average (Training): 1365.59, Success: 0\n",
            "Episode: 40900, Total Reward: 1164.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3722626\n",
            "Moving Average (Training): 1356.43, Success: 0\n",
            "Episode: 40901, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3722828\n",
            "Moving Average (Training): 1357.03, Success: 1\n",
            "Episode: 40902, Total Reward: 2189.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3723027\n",
            "Moving Average (Training): 1367.3, Success: 1\n",
            "Episode: 40903, Total Reward: 1143.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3723139\n",
            "Moving Average (Training): 1377.03, Success: 0\n",
            "Episode: 40904, Total Reward: 2062.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3723341\n",
            "Moving Average (Training): 1378.66, Success: 0\n",
            "Episode: 40905, Total Reward: 2185.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 215, Step Count: 3723556\n",
            "Moving Average (Training): 1385.45, Success: 1\n",
            "Episode: 40906, Total Reward: 1132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3723669\n",
            "Moving Average (Training): 1375.33, Success: 0\n",
            "Episode: 40907, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3723860\n",
            "Moving Average (Training): 1384.44, Success: 0\n",
            "Episode: 40908, Total Reward: 2147.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3724062\n",
            "Moving Average (Training): 1394.21, Success: 0\n",
            "Episode: 40909, Total Reward: 1134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3724173\n",
            "Moving Average (Training): 1394.11, Success: 0\n",
            "Episode: 40910, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3724374\n",
            "Moving Average (Training): 1412.18, Success: 1\n",
            "Episode: 40911, Total Reward: 377.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 39, Step Count: 3724413\n",
            "Moving Average (Training): 1411.12, Success: 0\n",
            "Episode: 40912, Total Reward: 2114.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 187, Step Count: 3724600\n",
            "Moving Average (Training): 1420.81, Success: 0\n",
            "Episode: 40913, Total Reward: 1748.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3724797\n",
            "Moving Average (Training): 1426.84, Success: 0\n",
            "Episode: 40914, Total Reward: 2120.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3724994\n",
            "Moving Average (Training): 1435.85, Success: 0\n",
            "Episode: 40915, Total Reward: 1232.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3725105\n",
            "Moving Average (Training): 1436.72, Success: 0\n",
            "Episode: 40916, Total Reward: 2166.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 194, Step Count: 3725299\n",
            "Moving Average (Training): 1453.49, Success: 1\n",
            "Episode: 40917, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3725414\n",
            "Moving Average (Training): 1454.25, Success: 0\n",
            "Episode: 40918, Total Reward: 169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 29, Step Count: 3725443\n",
            "Moving Average (Training): 1434.3, Success: 0\n",
            "Episode: 40919, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3725551\n",
            "Moving Average (Training): 1441.14, Success: 0\n",
            "Episode: 40920, Total Reward: 2170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3725753\n",
            "Moving Average (Training): 1450.65, Success: 1\n",
            "Episode: 40921, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3725956\n",
            "Moving Average (Training): 1450.72, Success: 1\n",
            "Episode: 40922, Total Reward: 1935.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 192, Step Count: 3726148\n",
            "Moving Average (Training): 1457.71, Success: 0\n",
            "Episode: 40923, Total Reward: 170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3726176\n",
            "Moving Average (Training): 1447.71, Success: 0\n",
            "Episode: 40924, Total Reward: 1151.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3726283\n",
            "Moving Average (Training): 1437.4, Success: 0\n",
            "Episode: 40925, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3726474\n",
            "Moving Average (Training): 1437.41, Success: 0\n",
            "Episode: 40926, Total Reward: 1968.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 184, Step Count: 3726658\n",
            "Moving Average (Training): 1455.31, Success: 0\n",
            "Episode: 40927, Total Reward: 2167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3726851\n",
            "Moving Average (Training): 1455.32, Success: 1\n",
            "Episode: 40928, Total Reward: 1247.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 118, Step Count: 3726969\n",
            "Moving Average (Training): 1455.45, Success: 0\n",
            "Episode: 40929, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3727172\n",
            "Moving Average (Training): 1462.2, Success: 1\n",
            "Episode: 40930, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3727370\n",
            "Moving Average (Training): 1472.38, Success: 1\n",
            "Episode: 40931, Total Reward: 2088.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3727558\n",
            "Moving Average (Training): 1481.03, Success: 0\n",
            "Episode: 40932, Total Reward: 1894.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 186, Step Count: 3727744\n",
            "Moving Average (Training): 1498.19, Success: 0\n",
            "Episode: 40933, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3727772\n",
            "Moving Average (Training): 1498.19, Success: 0\n",
            "Episode: 40934, Total Reward: 1854.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 235, Step Count: 3728007\n",
            "Moving Average (Training): 1514.95, Success: 0\n",
            "Episode: 40935, Total Reward: 1120.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 118, Step Count: 3728125\n",
            "Moving Average (Training): 1524.38, Success: 0\n",
            "Episode: 40936, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3728238\n",
            "Moving Average (Training): 1525.14, Success: 0\n",
            "Episode: 40937, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3728342\n",
            "Moving Average (Training): 1525.15, Success: 0\n",
            "Episode: 40938, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3728453\n",
            "Moving Average (Training): 1525.88, Success: 0\n",
            "Episode: 40939, Total Reward: 171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 31, Step Count: 3728484\n",
            "Moving Average (Training): 1516.42, Success: 0\n",
            "Episode: 40940, Total Reward: 1813.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3728689\n",
            "Moving Average (Training): 1523.1, Success: 0\n",
            "Episode: 40941, Total Reward: 384.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 41, Step Count: 3728730\n",
            "Moving Average (Training): 1515.23, Success: 0\n",
            "Episode: 40942, Total Reward: 986.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 93, Step Count: 3728823\n",
            "Moving Average (Training): 1503.21, Success: 0\n",
            "Episode: 40943, Total Reward: 2125.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3729013\n",
            "Moving Average (Training): 1512.19, Success: 0\n",
            "Episode: 40944, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3729203\n",
            "Moving Average (Training): 1528.64, Success: 0\n",
            "Episode: 40945, Total Reward: 2177.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 212, Step Count: 3729415\n",
            "Moving Average (Training): 1545.54, Success: 1\n",
            "Episode: 40946, Total Reward: 1142.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3729529\n",
            "Moving Average (Training): 1552.07, Success: 0\n",
            "Episode: 40947, Total Reward: 1131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3729644\n",
            "Moving Average (Training): 1551.92, Success: 0\n",
            "Episode: 40948, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3729758\n",
            "Moving Average (Training): 1543.08, Success: 0\n",
            "Episode: 40949, Total Reward: 1973.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 181, Step Count: 3729939\n",
            "Moving Average (Training): 1541.49, Success: 0\n",
            "Episode: 40950, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3730141\n",
            "Moving Average (Training): 1557.85, Success: 0\n",
            "Episode: 40951, Total Reward: 1148.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3730247\n",
            "Moving Average (Training): 1557.63, Success: 0\n",
            "Episode: 40952, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 187, Step Count: 3730434\n",
            "Moving Average (Training): 1567.46, Success: 0\n",
            "Episode: 40953, Total Reward: 483.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3730489\n",
            "Moving Average (Training): 1550.98, Success: 0\n",
            "Episode: 40954, Total Reward: 398.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 47, Step Count: 3730536\n",
            "Moving Average (Training): 1543.25, Success: 0\n",
            "Episode: 40955, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3730736\n",
            "Moving Average (Training): 1543.42, Success: 0\n",
            "Episode: 40956, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3730850\n",
            "Moving Average (Training): 1543.94, Success: 0\n",
            "Episode: 40957, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 215, Step Count: 3731065\n",
            "Moving Average (Training): 1553.78, Success: 0\n",
            "Episode: 40958, Total Reward: 2112.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3731263\n",
            "Moving Average (Training): 1553.03, Success: 0\n",
            "Episode: 40959, Total Reward: 1220.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3731378\n",
            "Moving Average (Training): 1553.01, Success: 0\n",
            "Episode: 40960, Total Reward: 174.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3731406\n",
            "Moving Average (Training): 1543.31, Success: 0\n",
            "Episode: 40961, Total Reward: 1220.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3731519\n",
            "Moving Average (Training): 1543.28, Success: 0\n",
            "Episode: 40962, Total Reward: 2177.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3731724\n",
            "Moving Average (Training): 1563.38, Success: 1\n",
            "Episode: 40963, Total Reward: 1225.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3731838\n",
            "Moving Average (Training): 1563.91, Success: 0\n",
            "Episode: 40964, Total Reward: 2089.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3732026\n",
            "Moving Average (Training): 1583.08, Success: 0\n",
            "Episode: 40965, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3732215\n",
            "Moving Average (Training): 1589.32, Success: 0\n",
            "Episode: 40966, Total Reward: 1162.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3732327\n",
            "Moving Average (Training): 1579.13, Success: 0\n",
            "Episode: 40967, Total Reward: 484.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 63, Step Count: 3732390\n",
            "Moving Average (Training): 1562.17, Success: 0\n",
            "Episode: 40968, Total Reward: 2108.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3732594\n",
            "Moving Average (Training): 1561.97, Success: 0\n",
            "Episode: 40969, Total Reward: 487.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3732649\n",
            "Moving Average (Training): 1545.55, Success: 0\n",
            "Episode: 40970, Total Reward: 1939.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 213, Step Count: 3732862\n",
            "Moving Average (Training): 1543.76, Success: 0\n",
            "Episode: 40971, Total Reward: 2173.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3733062\n",
            "Moving Average (Training): 1554.04, Success: 1\n",
            "Episode: 40972, Total Reward: 2170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 220, Step Count: 3733282\n",
            "Moving Average (Training): 1573.96, Success: 1\n",
            "Episode: 40973, Total Reward: 1901.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 175, Step Count: 3733457\n",
            "Moving Average (Training): 1571.64, Success: 0\n",
            "Episode: 40974, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3733511\n",
            "Moving Average (Training): 1555.18, Success: 0\n",
            "Episode: 40975, Total Reward: 687.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 67, Step Count: 3733578\n",
            "Moving Average (Training): 1540.24, Success: 0\n",
            "Episode: 40976, Total Reward: 905.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 86, Step Count: 3733664\n",
            "Moving Average (Training): 1537.82, Success: 0\n",
            "Episode: 40977, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3733770\n",
            "Moving Average (Training): 1527.47, Success: 0\n",
            "Episode: 40978, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3733876\n",
            "Moving Average (Training): 1517.66, Success: 0\n",
            "Episode: 40979, Total Reward: 1979.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 179, Step Count: 3734055\n",
            "Moving Average (Training): 1515.78, Success: 0\n",
            "Episode: 40980, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3734162\n",
            "Moving Average (Training): 1505.43, Success: 0\n",
            "Episode: 40981, Total Reward: 2114.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3734355\n",
            "Moving Average (Training): 1521.72, Success: 0\n",
            "Episode: 40982, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 118, Step Count: 3734473\n",
            "Moving Average (Training): 1529.02, Success: 0\n",
            "Episode: 40983, Total Reward: 1170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3734582\n",
            "Moving Average (Training): 1519.41, Success: 0\n",
            "Episode: 40984, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3734782\n",
            "Moving Average (Training): 1529.03, Success: 1\n",
            "Episode: 40985, Total Reward: 2097.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 186, Step Count: 3734968\n",
            "Moving Average (Training): 1528.12, Success: 0\n",
            "Episode: 40986, Total Reward: 2126.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3735156\n",
            "Moving Average (Training): 1537.92, Success: 0\n",
            "Episode: 40987, Total Reward: 1147.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3735260\n",
            "Moving Average (Training): 1528.17, Success: 0\n",
            "Episode: 40988, Total Reward: 1147.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3735364\n",
            "Moving Average (Training): 1520.72, Success: 0\n",
            "Episode: 40989, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3735555\n",
            "Moving Average (Training): 1520.74, Success: 0\n",
            "Episode: 40990, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3735610\n",
            "Moving Average (Training): 1503.71, Success: 0\n",
            "Episode: 40991, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3735800\n",
            "Moving Average (Training): 1503.66, Success: 0\n",
            "Episode: 40992, Total Reward: 986.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 90, Step Count: 3735890\n",
            "Moving Average (Training): 1503.67, Success: 0\n",
            "Episode: 40993, Total Reward: 2178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 209, Step Count: 3736099\n",
            "Moving Average (Training): 1503.76, Success: 1\n",
            "Episode: 40994, Total Reward: 2118.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3736290\n",
            "Moving Average (Training): 1512.75, Success: 0\n",
            "Episode: 40995, Total Reward: 1156.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3736400\n",
            "Moving Average (Training): 1517.44, Success: 0\n",
            "Episode: 40996, Total Reward: 2167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3736602\n",
            "Moving Average (Training): 1520.15, Success: 1\n",
            "Episode: 40997, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3736710\n",
            "Moving Average (Training): 1519.68, Success: 0\n",
            "Episode: 40998, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3736913\n",
            "Moving Average (Training): 1520.24, Success: 1\n",
            "Episode: 40999, Total Reward: 2125.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3737116\n",
            "Moving Average (Training): 1534.75, Success: 0\n",
            "Episode: 41000, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3737228\n",
            "Moving Average (Training): 1535.28, Success: 0\n",
            "Episode: 41001, Total Reward: 2164.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3737429\n",
            "Moving Average (Training): 1535.05, Success: 1\n",
            "Episode: 41002, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 196, Step Count: 3737625\n",
            "Moving Average (Training): 1535.04, Success: 1\n",
            "Episode: 41003, Total Reward: 1847.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 219, Step Count: 3737844\n",
            "Moving Average (Training): 1542.08, Success: 0\n",
            "Episode: 41004, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3738034\n",
            "Moving Average (Training): 1542.76, Success: 0\n",
            "Episode: 41005, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3738231\n",
            "Moving Average (Training): 1542.18, Success: 0\n",
            "Episode: 41006, Total Reward: 2186.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 214, Step Count: 3738445\n",
            "Moving Average (Training): 1552.72, Success: 1\n",
            "Episode: 41007, Total Reward: 1753.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 207, Step Count: 3738652\n",
            "Moving Average (Training): 1548.97, Success: 0\n",
            "Episode: 41008, Total Reward: 670.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 69, Step Count: 3738721\n",
            "Moving Average (Training): 1534.2, Success: 0\n",
            "Episode: 41009, Total Reward: 1845.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 182, Step Count: 3738903\n",
            "Moving Average (Training): 1541.31, Success: 0\n",
            "Episode: 41010, Total Reward: 487.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 51, Step Count: 3738954\n",
            "Moving Average (Training): 1524.38, Success: 0\n",
            "Episode: 41011, Total Reward: 487.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3739009\n",
            "Moving Average (Training): 1525.48, Success: 0\n",
            "Episode: 41012, Total Reward: 2099.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 195, Step Count: 3739204\n",
            "Moving Average (Training): 1525.33, Success: 0\n",
            "Episode: 41013, Total Reward: 491.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3739258\n",
            "Moving Average (Training): 1512.76, Success: 0\n",
            "Episode: 41014, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3739373\n",
            "Moving Average (Training): 1503.74, Success: 0\n",
            "Episode: 41015, Total Reward: 2119.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3739563\n",
            "Moving Average (Training): 1512.61, Success: 0\n",
            "Episode: 41016, Total Reward: 2134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3739751\n",
            "Moving Average (Training): 1512.29, Success: 0\n",
            "Episode: 41017, Total Reward: 1220.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3739864\n",
            "Moving Average (Training): 1512.3, Success: 0\n",
            "Episode: 41018, Total Reward: 1972.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 178, Step Count: 3740042\n",
            "Moving Average (Training): 1530.33, Success: 0\n",
            "Episode: 41019, Total Reward: 1134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3740153\n",
            "Moving Average (Training): 1529.95, Success: 0\n",
            "Episode: 41020, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3740358\n",
            "Moving Average (Training): 1529.54, Success: 0\n",
            "Episode: 41021, Total Reward: 174.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3740386\n",
            "Moving Average (Training): 1509.47, Success: 0\n",
            "Episode: 41022, Total Reward: 173.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3740414\n",
            "Moving Average (Training): 1491.85, Success: 0\n",
            "Episode: 41023, Total Reward: 1889.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 175, Step Count: 3740589\n",
            "Moving Average (Training): 1509.04, Success: 0\n",
            "Episode: 41024, Total Reward: 1883.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 175, Step Count: 3740764\n",
            "Moving Average (Training): 1516.36, Success: 0\n",
            "Episode: 41025, Total Reward: 2168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 195, Step Count: 3740959\n",
            "Moving Average (Training): 1516.72, Success: 1\n",
            "Episode: 41026, Total Reward: 179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 30, Step Count: 3740989\n",
            "Moving Average (Training): 1498.83, Success: 0\n",
            "Episode: 41027, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3741179\n",
            "Moving Average (Training): 1498.44, Success: 0\n",
            "Episode: 41028, Total Reward: 1991.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3741377\n",
            "Moving Average (Training): 1505.88, Success: 0\n",
            "Episode: 41029, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3741581\n",
            "Moving Average (Training): 1505.88, Success: 1\n",
            "Episode: 41030, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3741769\n",
            "Moving Average (Training): 1505.39, Success: 0\n",
            "Episode: 41031, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3741960\n",
            "Moving Average (Training): 1505.79, Success: 0\n",
            "Episode: 41032, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3742151\n",
            "Moving Average (Training): 1508.13, Success: 0\n",
            "Episode: 41033, Total Reward: 1170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3742260\n",
            "Moving Average (Training): 1518.05, Success: 0\n",
            "Episode: 41034, Total Reward: 170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 26, Step Count: 3742286\n",
            "Moving Average (Training): 1501.21, Success: 0\n",
            "Episode: 41035, Total Reward: 695.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 65, Step Count: 3742351\n",
            "Moving Average (Training): 1496.96, Success: 0\n",
            "Episode: 41036, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3742465\n",
            "Moving Average (Training): 1496.96, Success: 0\n",
            "Episode: 41037, Total Reward: 1908.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 230, Step Count: 3742695\n",
            "Moving Average (Training): 1504.58, Success: 0\n",
            "Episode: 41038, Total Reward: 1147.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3742800\n",
            "Moving Average (Training): 1503.86, Success: 0\n",
            "Episode: 41039, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3743001\n",
            "Moving Average (Training): 1523.94, Success: 1\n",
            "Episode: 41040, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3743117\n",
            "Moving Average (Training): 1518.0, Success: 0\n",
            "Episode: 41041, Total Reward: 1147.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3743221\n",
            "Moving Average (Training): 1525.63, Success: 0\n",
            "Episode: 41042, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3743332\n",
            "Moving Average (Training): 1527.94, Success: 0\n",
            "Episode: 41043, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3743535\n",
            "Moving Average (Training): 1528.48, Success: 1\n",
            "Episode: 41044, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3743643\n",
            "Moving Average (Training): 1518.63, Success: 0\n",
            "Episode: 41045, Total Reward: 387.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 44, Step Count: 3743687\n",
            "Moving Average (Training): 1500.73, Success: 0\n",
            "Episode: 41046, Total Reward: 1883.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 181, Step Count: 3743868\n",
            "Moving Average (Training): 1508.14, Success: 0\n",
            "Episode: 41047, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3743973\n",
            "Moving Average (Training): 1508.29, Success: 0\n",
            "Episode: 41048, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3744170\n",
            "Moving Average (Training): 1517.4, Success: 0\n",
            "Episode: 41049, Total Reward: 985.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 94, Step Count: 3744264\n",
            "Moving Average (Training): 1507.52, Success: 0\n",
            "Episode: 41050, Total Reward: 2114.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3744454\n",
            "Moving Average (Training): 1507.39, Success: 0\n",
            "Episode: 41051, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3744645\n",
            "Moving Average (Training): 1517.19, Success: 0\n",
            "Episode: 41052, Total Reward: 1236.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3744758\n",
            "Moving Average (Training): 1508.25, Success: 0\n",
            "Episode: 41053, Total Reward: 1144.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3744865\n",
            "Moving Average (Training): 1514.86, Success: 0\n",
            "Episode: 41054, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3745068\n",
            "Moving Average (Training): 1532.76, Success: 1\n",
            "Episode: 41055, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3745269\n",
            "Moving Average (Training): 1533.32, Success: 1\n",
            "Episode: 41056, Total Reward: 2126.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3745471\n",
            "Moving Average (Training): 1542.35, Success: 0\n",
            "Episode: 41057, Total Reward: 483.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 61, Step Count: 3745532\n",
            "Moving Average (Training): 1525.9, Success: 0\n",
            "Episode: 41058, Total Reward: 1217.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3745644\n",
            "Moving Average (Training): 1516.95, Success: 0\n",
            "Episode: 41059, Total Reward: 492.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3745699\n",
            "Moving Average (Training): 1509.67, Success: 0\n",
            "Episode: 41060, Total Reward: 474.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 62, Step Count: 3745761\n",
            "Moving Average (Training): 1512.67, Success: 0\n",
            "Episode: 41061, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3745816\n",
            "Moving Average (Training): 1505.32, Success: 0\n",
            "Episode: 41062, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3745922\n",
            "Moving Average (Training): 1495.0, Success: 0\n",
            "Episode: 41063, Total Reward: 685.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 67, Step Count: 3745989\n",
            "Moving Average (Training): 1489.6, Success: 0\n",
            "Episode: 41064, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3746105\n",
            "Moving Average (Training): 1480.89, Success: 0\n",
            "Episode: 41065, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3746296\n",
            "Moving Average (Training): 1480.94, Success: 0\n",
            "Episode: 41066, Total Reward: 2077.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 195, Step Count: 3746491\n",
            "Moving Average (Training): 1490.09, Success: 0\n",
            "Episode: 41067, Total Reward: 2099.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 195, Step Count: 3746686\n",
            "Moving Average (Training): 1506.24, Success: 0\n",
            "Episode: 41068, Total Reward: 1857.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 182, Step Count: 3746868\n",
            "Moving Average (Training): 1503.73, Success: 0\n",
            "Episode: 41069, Total Reward: 2099.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3747057\n",
            "Moving Average (Training): 1519.85, Success: 0\n",
            "Episode: 41070, Total Reward: 2078.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3747260\n",
            "Moving Average (Training): 1521.24, Success: 0\n",
            "Episode: 41071, Total Reward: 2178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 210, Step Count: 3747470\n",
            "Moving Average (Training): 1521.29, Success: 1\n",
            "Episode: 41072, Total Reward: 1220.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3747581\n",
            "Moving Average (Training): 1511.79, Success: 0\n",
            "Episode: 41073, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 206, Step Count: 3747787\n",
            "Moving Average (Training): 1514.57, Success: 1\n",
            "Episode: 41074, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3747989\n",
            "Moving Average (Training): 1531.6, Success: 1\n",
            "Episode: 41075, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3748178\n",
            "Moving Average (Training): 1546.02, Success: 0\n",
            "Episode: 41076, Total Reward: 486.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3748232\n",
            "Moving Average (Training): 1541.83, Success: 0\n",
            "Episode: 41077, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3748346\n",
            "Moving Average (Training): 1542.57, Success: 0\n",
            "Episode: 41078, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3748456\n",
            "Moving Average (Training): 1542.83, Success: 0\n",
            "Episode: 41079, Total Reward: 1876.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3748659\n",
            "Moving Average (Training): 1541.8, Success: 0\n",
            "Episode: 41080, Total Reward: 1175.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3748771\n",
            "Moving Average (Training): 1542.09, Success: 0\n",
            "Episode: 41081, Total Reward: 2185.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3748969\n",
            "Moving Average (Training): 1542.8, Success: 1\n",
            "Episode: 41082, Total Reward: 1135.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3749082\n",
            "Moving Average (Training): 1541.98, Success: 0\n",
            "Episode: 41083, Total Reward: 1503.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 146, Step Count: 3749228\n",
            "Moving Average (Training): 1545.31, Success: 0\n",
            "Episode: 41084, Total Reward: 970.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 97, Step Count: 3749325\n",
            "Moving Average (Training): 1533.2, Success: 0\n",
            "Episode: 41085, Total Reward: 2185.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3749523\n",
            "Moving Average (Training): 1534.08, Success: 1\n",
            "Episode: 41086, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3749637\n",
            "Moving Average (Training): 1525.01, Success: 0\n",
            "Episode: 41087, Total Reward: 2125.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3749830\n",
            "Moving Average (Training): 1534.79, Success: 0\n",
            "Episode: 41088, Total Reward: 1169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3749940\n",
            "Moving Average (Training): 1535.01, Success: 0\n",
            "Episode: 41089, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3750047\n",
            "Moving Average (Training): 1525.44, Success: 0\n",
            "Episode: 41090, Total Reward: 1144.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3750155\n",
            "Moving Average (Training): 1532.03, Success: 0\n",
            "Episode: 41091, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3750259\n",
            "Moving Average (Training): 1522.22, Success: 0\n",
            "Episode: 41092, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3750449\n",
            "Moving Average (Training): 1533.68, Success: 0\n",
            "Episode: 41093, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3750640\n",
            "Moving Average (Training): 1533.18, Success: 0\n",
            "Episode: 41094, Total Reward: 2134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 187, Step Count: 3750827\n",
            "Moving Average (Training): 1533.34, Success: 0\n",
            "Episode: 41095, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3750933\n",
            "Moving Average (Training): 1533.23, Success: 0\n",
            "Episode: 41096, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3751134\n",
            "Moving Average (Training): 1533.35, Success: 1\n",
            "Episode: 41097, Total Reward: 2182.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3751327\n",
            "Moving Average (Training): 1543.46, Success: 1\n",
            "Episode: 41098, Total Reward: 179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3751355\n",
            "Moving Average (Training): 1523.38, Success: 0\n",
            "Episode: 41099, Total Reward: 1160.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3751464\n",
            "Moving Average (Training): 1513.73, Success: 0\n",
            "Episode: 41100, Total Reward: 2124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 233, Step Count: 3751697\n",
            "Moving Average (Training): 1522.8, Success: 0\n",
            "Episode: 41101, Total Reward: 2183.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 196, Step Count: 3751893\n",
            "Moving Average (Training): 1522.99, Success: 1\n",
            "Episode: 41102, Total Reward: 967.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 89, Step Count: 3751982\n",
            "Moving Average (Training): 1510.78, Success: 0\n",
            "Episode: 41103, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3752089\n",
            "Moving Average (Training): 1503.77, Success: 0\n",
            "Episode: 41104, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3752291\n",
            "Moving Average (Training): 1504.35, Success: 1\n",
            "Episode: 41105, Total Reward: 482.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 58, Step Count: 3752349\n",
            "Moving Average (Training): 1487.9, Success: 0\n",
            "Episode: 41106, Total Reward: 1983.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3752548\n",
            "Moving Average (Training): 1485.87, Success: 0\n",
            "Episode: 41107, Total Reward: 486.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 57, Step Count: 3752605\n",
            "Moving Average (Training): 1473.2, Success: 0\n",
            "Episode: 41108, Total Reward: 1235.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3752717\n",
            "Moving Average (Training): 1478.85, Success: 0\n",
            "Episode: 41109, Total Reward: 1144.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3752830\n",
            "Moving Average (Training): 1471.84, Success: 0\n",
            "Episode: 41110, Total Reward: 2097.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 659, Step Count: 3753489\n",
            "Moving Average (Training): 1487.94, Success: 1\n",
            "Episode: 41111, Total Reward: 1235.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3753605\n",
            "Moving Average (Training): 1495.42, Success: 0\n",
            "Episode: 41112, Total Reward: 973.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 102, Step Count: 3753707\n",
            "Moving Average (Training): 1484.16, Success: 0\n",
            "Episode: 41113, Total Reward: 2170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3753905\n",
            "Moving Average (Training): 1500.95, Success: 1\n",
            "Episode: 41114, Total Reward: 1850.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 335, Step Count: 3754240\n",
            "Moving Average (Training): 1507.27, Success: 0\n",
            "Episode: 41115, Total Reward: 488.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3754295\n",
            "Moving Average (Training): 1490.96, Success: 0\n",
            "Episode: 41116, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3754496\n",
            "Moving Average (Training): 1490.89, Success: 0\n",
            "Episode: 41117, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3754696\n",
            "Moving Average (Training): 1500.48, Success: 1\n",
            "Episode: 41118, Total Reward: 961.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 93, Step Count: 3754789\n",
            "Moving Average (Training): 1490.37, Success: 0\n",
            "Episode: 41119, Total Reward: 173.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3754817\n",
            "Moving Average (Training): 1480.76, Success: 0\n",
            "Episode: 41120, Total Reward: 2085.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 195, Step Count: 3755012\n",
            "Moving Average (Training): 1480.32, Success: 0\n",
            "Episode: 41121, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3755215\n",
            "Moving Average (Training): 1500.38, Success: 1\n",
            "Episode: 41122, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3755327\n",
            "Moving Average (Training): 1510.84, Success: 0\n",
            "Episode: 41123, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3755520\n",
            "Moving Average (Training): 1513.27, Success: 0\n",
            "Episode: 41124, Total Reward: 2120.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3755717\n",
            "Moving Average (Training): 1515.64, Success: 0\n",
            "Episode: 41125, Total Reward: 1222.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3755831\n",
            "Moving Average (Training): 1506.18, Success: 0\n",
            "Episode: 41126, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3755939\n",
            "Moving Average (Training): 1515.85, Success: 0\n",
            "Episode: 41127, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3756052\n",
            "Moving Average (Training): 1506.76, Success: 0\n",
            "Episode: 41128, Total Reward: 971.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 89, Step Count: 3756141\n",
            "Moving Average (Training): 1496.56, Success: 0\n",
            "Episode: 41129, Total Reward: 488.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3756196\n",
            "Moving Average (Training): 1479.64, Success: 0\n",
            "Episode: 41130, Total Reward: 172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 29, Step Count: 3756225\n",
            "Moving Average (Training): 1460.04, Success: 0\n",
            "Episode: 41131, Total Reward: 1151.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3756334\n",
            "Moving Average (Training): 1450.27, Success: 0\n",
            "Episode: 41132, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3756449\n",
            "Moving Average (Training): 1441.18, Success: 0\n",
            "Episode: 41133, Total Reward: 2116.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3756654\n",
            "Moving Average (Training): 1450.64, Success: 0\n",
            "Episode: 41134, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3756844\n",
            "Moving Average (Training): 1470.25, Success: 0\n",
            "Episode: 41135, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 208, Step Count: 3757052\n",
            "Moving Average (Training): 1485.17, Success: 1\n",
            "Episode: 41136, Total Reward: 1970.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 183, Step Count: 3757235\n",
            "Moving Average (Training): 1492.68, Success: 0\n",
            "Episode: 41137, Total Reward: 1135.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3757345\n",
            "Moving Average (Training): 1484.95, Success: 0\n",
            "Episode: 41138, Total Reward: 2136.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3757536\n",
            "Moving Average (Training): 1494.84, Success: 0\n",
            "Episode: 41139, Total Reward: 1143.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3757643\n",
            "Moving Average (Training): 1484.48, Success: 0\n",
            "Episode: 41140, Total Reward: 1167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3757752\n",
            "Moving Average (Training): 1483.96, Success: 0\n",
            "Episode: 41141, Total Reward: 1233.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3757866\n",
            "Moving Average (Training): 1484.82, Success: 0\n",
            "Episode: 41142, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3757974\n",
            "Moving Average (Training): 1484.1, Success: 0\n",
            "Episode: 41143, Total Reward: 2186.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 208, Step Count: 3758182\n",
            "Moving Average (Training): 1484.17, Success: 1\n",
            "Episode: 41144, Total Reward: 2167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3758375\n",
            "Moving Average (Training): 1494.39, Success: 1\n",
            "Episode: 41145, Total Reward: 2099.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 207, Step Count: 3758582\n",
            "Moving Average (Training): 1511.51, Success: 0\n",
            "Episode: 41146, Total Reward: 169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 31, Step Count: 3758613\n",
            "Moving Average (Training): 1494.37, Success: 0\n",
            "Episode: 41147, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3758818\n",
            "Moving Average (Training): 1504.19, Success: 0\n",
            "Episode: 41148, Total Reward: 2134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 187, Step Count: 3759005\n",
            "Moving Average (Training): 1504.23, Success: 0\n",
            "Episode: 41149, Total Reward: 1897.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 182, Step Count: 3759187\n",
            "Moving Average (Training): 1513.35, Success: 0\n",
            "Episode: 41150, Total Reward: 1127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 122, Step Count: 3759309\n",
            "Moving Average (Training): 1503.48, Success: 0\n",
            "Episode: 41151, Total Reward: 2168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 209, Step Count: 3759518\n",
            "Moving Average (Training): 1503.88, Success: 1\n",
            "Episode: 41152, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3759708\n",
            "Moving Average (Training): 1512.81, Success: 0\n",
            "Episode: 41153, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3759905\n",
            "Moving Average (Training): 1522.67, Success: 0\n",
            "Episode: 41154, Total Reward: 171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 29, Step Count: 3759934\n",
            "Moving Average (Training): 1502.5, Success: 0\n",
            "Episode: 41155, Total Reward: 1169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3760041\n",
            "Moving Average (Training): 1492.32, Success: 0\n",
            "Episode: 41156, Total Reward: 1296.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 136, Step Count: 3760177\n",
            "Moving Average (Training): 1484.02, Success: 0\n",
            "Episode: 41157, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3760284\n",
            "Moving Average (Training): 1490.64, Success: 0\n",
            "Episode: 41158, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3760391\n",
            "Moving Average (Training): 1490.19, Success: 0\n",
            "Episode: 41159, Total Reward: 1143.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3760504\n",
            "Moving Average (Training): 1496.7, Success: 0\n",
            "Episode: 41160, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3760692\n",
            "Moving Average (Training): 1513.24, Success: 0\n",
            "Episode: 41161, Total Reward: 1132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3760808\n",
            "Moving Average (Training): 1519.71, Success: 0\n",
            "Episode: 41162, Total Reward: 1903.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 176, Step Count: 3760984\n",
            "Moving Average (Training): 1527.29, Success: 0\n",
            "Episode: 41163, Total Reward: 2182.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3761187\n",
            "Moving Average (Training): 1542.26, Success: 1\n",
            "Episode: 41164, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3761390\n",
            "Moving Average (Training): 1551.96, Success: 1\n",
            "Episode: 41165, Total Reward: 2169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3761594\n",
            "Moving Average (Training): 1552.33, Success: 1\n",
            "Episode: 41166, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3761703\n",
            "Moving Average (Training): 1543.28, Success: 0\n",
            "Episode: 41167, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 117, Step Count: 3761820\n",
            "Moving Average (Training): 1534.47, Success: 0\n",
            "Episode: 41168, Total Reward: 2066.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3762009\n",
            "Moving Average (Training): 1536.56, Success: 0\n",
            "Episode: 41169, Total Reward: 1887.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 180, Step Count: 3762189\n",
            "Moving Average (Training): 1534.44, Success: 0\n",
            "Episode: 41170, Total Reward: 393.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 45, Step Count: 3762234\n",
            "Moving Average (Training): 1517.59, Success: 0\n",
            "Episode: 41171, Total Reward: 2061.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 837, Step Count: 3763071\n",
            "Moving Average (Training): 1516.42, Success: 1\n",
            "Episode: 41172, Total Reward: 2185.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 208, Step Count: 3763279\n",
            "Moving Average (Training): 1526.07, Success: 1\n",
            "Episode: 41173, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3763390\n",
            "Moving Average (Training): 1515.99, Success: 0\n",
            "Episode: 41174, Total Reward: 1220.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3763504\n",
            "Moving Average (Training): 1506.31, Success: 0\n",
            "Episode: 41175, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3763708\n",
            "Moving Average (Training): 1506.81, Success: 1\n",
            "Episode: 41176, Total Reward: 2126.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3763899\n",
            "Moving Average (Training): 1523.21, Success: 0\n",
            "Episode: 41177, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3764009\n",
            "Moving Average (Training): 1522.74, Success: 0\n",
            "Episode: 41178, Total Reward: 1171.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3764120\n",
            "Moving Average (Training): 1522.73, Success: 0\n",
            "Episode: 41179, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3764231\n",
            "Moving Average (Training): 1516.15, Success: 0\n",
            "Episode: 41180, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3764340\n",
            "Moving Average (Training): 1516.12, Success: 0\n",
            "Episode: 41181, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3764454\n",
            "Moving Average (Training): 1506.46, Success: 0\n",
            "Episode: 41182, Total Reward: 1221.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3764565\n",
            "Moving Average (Training): 1507.32, Success: 0\n",
            "Episode: 41183, Total Reward: 487.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3764619\n",
            "Moving Average (Training): 1497.16, Success: 0\n",
            "Episode: 41184, Total Reward: 1141.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3764727\n",
            "Moving Average (Training): 1498.87, Success: 0\n",
            "Episode: 41185, Total Reward: 2165.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3764930\n",
            "Moving Average (Training): 1498.67, Success: 1\n",
            "Episode: 41186, Total Reward: 670.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 67, Step Count: 3764997\n",
            "Moving Average (Training): 1493.18, Success: 0\n",
            "Episode: 41187, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3765103\n",
            "Moving Average (Training): 1483.65, Success: 0\n",
            "Episode: 41188, Total Reward: 1164.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3765214\n",
            "Moving Average (Training): 1483.6, Success: 0\n",
            "Episode: 41189, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3765326\n",
            "Moving Average (Training): 1484.08, Success: 0\n",
            "Episode: 41190, Total Reward: 1144.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3765433\n",
            "Moving Average (Training): 1484.08, Success: 0\n",
            "Episode: 41191, Total Reward: 2097.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 187, Step Count: 3765620\n",
            "Moving Average (Training): 1493.59, Success: 0\n",
            "Episode: 41192, Total Reward: 2184.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 210, Step Count: 3765830\n",
            "Moving Average (Training): 1494.11, Success: 1\n",
            "Episode: 41193, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3765938\n",
            "Moving Average (Training): 1484.55, Success: 0\n",
            "Episode: 41194, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3766042\n",
            "Moving Average (Training): 1474.66, Success: 0\n",
            "Episode: 41195, Total Reward: 673.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 63, Step Count: 3766105\n",
            "Moving Average (Training): 1469.94, Success: 0\n",
            "Episode: 41196, Total Reward: 489.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3766160\n",
            "Moving Average (Training): 1453.04, Success: 0\n",
            "Episode: 41197, Total Reward: 1236.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3766274\n",
            "Moving Average (Training): 1443.58, Success: 0\n",
            "Episode: 41198, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3766467\n",
            "Moving Average (Training): 1463.11, Success: 0\n",
            "Episode: 41199, Total Reward: 1124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 120, Step Count: 3766587\n",
            "Moving Average (Training): 1462.75, Success: 0\n",
            "Episode: 41200, Total Reward: 172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3766615\n",
            "Moving Average (Training): 1443.23, Success: 0\n",
            "Episode: 41201, Total Reward: 2131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 187, Step Count: 3766802\n",
            "Moving Average (Training): 1442.71, Success: 0\n",
            "Episode: 41202, Total Reward: 381.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 50, Step Count: 3766852\n",
            "Moving Average (Training): 1436.85, Success: 0\n",
            "Episode: 41203, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3766961\n",
            "Moving Average (Training): 1437.11, Success: 0\n",
            "Episode: 41204, Total Reward: 1759.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 194, Step Count: 3767155\n",
            "Moving Average (Training): 1432.82, Success: 0\n",
            "Episode: 41205, Total Reward: 489.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3767210\n",
            "Moving Average (Training): 1432.89, Success: 0\n",
            "Episode: 41206, Total Reward: 1900.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 180, Step Count: 3767390\n",
            "Moving Average (Training): 1432.06, Success: 0\n",
            "Episode: 41207, Total Reward: 700.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 69, Step Count: 3767459\n",
            "Moving Average (Training): 1434.2, Success: 0\n",
            "Episode: 41208, Total Reward: 487.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 58, Step Count: 3767517\n",
            "Moving Average (Training): 1426.72, Success: 0\n",
            "Episode: 41209, Total Reward: 392.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 47, Step Count: 3767564\n",
            "Moving Average (Training): 1419.2, Success: 0\n",
            "Episode: 41210, Total Reward: 1164.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3767671\n",
            "Moving Average (Training): 1409.87, Success: 0\n",
            "Episode: 41211, Total Reward: 1133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3767784\n",
            "Moving Average (Training): 1408.85, Success: 0\n",
            "Episode: 41212, Total Reward: 1124.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 119, Step Count: 3767903\n",
            "Moving Average (Training): 1410.36, Success: 0\n",
            "Episode: 41213, Total Reward: 982.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 93, Step Count: 3767996\n",
            "Moving Average (Training): 1398.48, Success: 0\n",
            "Episode: 41214, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 207, Step Count: 3768203\n",
            "Moving Average (Training): 1401.25, Success: 0\n",
            "Episode: 41215, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3768404\n",
            "Moving Average (Training): 1417.64, Success: 0\n",
            "Episode: 41216, Total Reward: 1102.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 123, Step Count: 3768527\n",
            "Moving Average (Training): 1407.39, Success: 0\n",
            "Episode: 41217, Total Reward: 1234.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3768639\n",
            "Moving Average (Training): 1397.94, Success: 0\n",
            "Episode: 41218, Total Reward: 170.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 29, Step Count: 3768668\n",
            "Moving Average (Training): 1390.03, Success: 0\n",
            "Episode: 41219, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3768868\n",
            "Moving Average (Training): 1410.09, Success: 1\n",
            "Episode: 41220, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3769061\n",
            "Moving Average (Training): 1410.57, Success: 0\n",
            "Episode: 41221, Total Reward: 2108.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 208, Step Count: 3769269\n",
            "Moving Average (Training): 1409.85, Success: 0\n",
            "Episode: 41222, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 57, Step Count: 3769326\n",
            "Moving Average (Training): 1402.51, Success: 0\n",
            "Episode: 41223, Total Reward: 1155.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3769431\n",
            "Moving Average (Training): 1392.74, Success: 0\n",
            "Episode: 41224, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3769535\n",
            "Moving Average (Training): 1383.0, Success: 0\n",
            "Episode: 41225, Total Reward: 1131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3769649\n",
            "Moving Average (Training): 1382.09, Success: 0\n",
            "Episode: 41226, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3769755\n",
            "Moving Average (Training): 1382.08, Success: 0\n",
            "Episode: 41227, Total Reward: 1225.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 116, Step Count: 3769871\n",
            "Moving Average (Training): 1382.14, Success: 0\n",
            "Episode: 41228, Total Reward: 389.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3769925\n",
            "Moving Average (Training): 1376.32, Success: 0\n",
            "Episode: 41229, Total Reward: 2132.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3770118\n",
            "Moving Average (Training): 1392.76, Success: 0\n",
            "Episode: 41230, Total Reward: 488.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3770173\n",
            "Moving Average (Training): 1395.92, Success: 0\n",
            "Episode: 41231, Total Reward: 485.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3770227\n",
            "Moving Average (Training): 1389.26, Success: 0\n",
            "Episode: 41232, Total Reward: 2110.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3770430\n",
            "Moving Average (Training): 1398.17, Success: 0\n",
            "Episode: 41233, Total Reward: 179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3770458\n",
            "Moving Average (Training): 1378.8, Success: 0\n",
            "Episode: 41234, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3770570\n",
            "Moving Average (Training): 1369.67, Success: 0\n",
            "Episode: 41235, Total Reward: 495.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3770624\n",
            "Moving Average (Training): 1352.75, Success: 0\n",
            "Episode: 41236, Total Reward: 2126.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3770817\n",
            "Moving Average (Training): 1354.31, Success: 0\n",
            "Episode: 41237, Total Reward: 482.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 57, Step Count: 3770874\n",
            "Moving Average (Training): 1347.78, Success: 0\n",
            "Episode: 41238, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3770980\n",
            "Moving Average (Training): 1338.14, Success: 0\n",
            "Episode: 41239, Total Reward: 1141.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3771088\n",
            "Moving Average (Training): 1338.12, Success: 0\n",
            "Episode: 41240, Total Reward: 484.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 58, Step Count: 3771146\n",
            "Moving Average (Training): 1331.29, Success: 0\n",
            "Episode: 41241, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3771254\n",
            "Moving Average (Training): 1330.41, Success: 0\n",
            "Episode: 41242, Total Reward: 2121.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3771454\n",
            "Moving Average (Training): 1340.17, Success: 0\n",
            "Episode: 41243, Total Reward: 1172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3771562\n",
            "Moving Average (Training): 1330.03, Success: 0\n",
            "Episode: 41244, Total Reward: 2172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3771762\n",
            "Moving Average (Training): 1330.08, Success: 1\n",
            "Episode: 41245, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3771870\n",
            "Moving Average (Training): 1320.54, Success: 0\n",
            "Episode: 41246, Total Reward: 2127.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3772061\n",
            "Moving Average (Training): 1340.12, Success: 0\n",
            "Episode: 41247, Total Reward: 1143.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3772168\n",
            "Moving Average (Training): 1330.27, Success: 0\n",
            "Episode: 41248, Total Reward: 2189.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3772367\n",
            "Moving Average (Training): 1330.82, Success: 1\n",
            "Episode: 41249, Total Reward: 2168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3772570\n",
            "Moving Average (Training): 1333.53, Success: 1\n",
            "Episode: 41250, Total Reward: 2098.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 194, Step Count: 3772764\n",
            "Moving Average (Training): 1343.24, Success: 0\n",
            "Episode: 41251, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3772963\n",
            "Moving Average (Training): 1343.44, Success: 1\n",
            "Episode: 41252, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3773163\n",
            "Moving Average (Training): 1343.96, Success: 1\n",
            "Episode: 41253, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3773268\n",
            "Moving Average (Training): 1334.12, Success: 0\n",
            "Episode: 41254, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3773372\n",
            "Moving Average (Training): 1343.87, Success: 0\n",
            "Episode: 41255, Total Reward: 1236.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3773483\n",
            "Moving Average (Training): 1344.54, Success: 0\n",
            "Episode: 41256, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3773588\n",
            "Moving Average (Training): 1343.04, Success: 0\n",
            "Episode: 41257, Total Reward: 486.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3773642\n",
            "Moving Average (Training): 1336.45, Success: 0\n",
            "Episode: 41258, Total Reward: 480.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 60, Step Count: 3773702\n",
            "Moving Average (Training): 1329.53, Success: 0\n",
            "Episode: 41259, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 192, Step Count: 3773894\n",
            "Moving Average (Training): 1339.98, Success: 1\n",
            "Episode: 41260, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 199, Step Count: 3774093\n",
            "Moving Average (Training): 1340.57, Success: 1\n",
            "Episode: 41261, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3774208\n",
            "Moving Average (Training): 1341.44, Success: 0\n",
            "Episode: 41262, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3774408\n",
            "Moving Average (Training): 1343.69, Success: 0\n",
            "Episode: 41263, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3774598\n",
            "Moving Average (Training): 1343.17, Success: 0\n",
            "Episode: 41264, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3774796\n",
            "Moving Average (Training): 1343.1, Success: 1\n",
            "Episode: 41265, Total Reward: 2182.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3774994\n",
            "Moving Average (Training): 1343.23, Success: 1\n",
            "Episode: 41266, Total Reward: 2169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3775197\n",
            "Moving Average (Training): 1353.2, Success: 1\n",
            "Episode: 41267, Total Reward: 2168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3775399\n",
            "Moving Average (Training): 1362.7, Success: 1\n",
            "Episode: 41268, Total Reward: 2172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 198, Step Count: 3775597\n",
            "Moving Average (Training): 1363.76, Success: 1\n",
            "Episode: 41269, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 205, Step Count: 3775802\n",
            "Moving Average (Training): 1366.68, Success: 1\n",
            "Episode: 41270, Total Reward: 1147.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3775906\n",
            "Moving Average (Training): 1374.22, Success: 0\n",
            "Episode: 41271, Total Reward: 2120.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3776096\n",
            "Moving Average (Training): 1374.81, Success: 0\n",
            "Episode: 41272, Total Reward: 1153.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3776207\n",
            "Moving Average (Training): 1364.49, Success: 0\n",
            "Episode: 41273, Total Reward: 1236.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3776319\n",
            "Moving Average (Training): 1365.14, Success: 0\n",
            "Episode: 41274, Total Reward: 1232.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3776430\n",
            "Moving Average (Training): 1365.26, Success: 0\n",
            "Episode: 41275, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3776458\n",
            "Moving Average (Training): 1345.25, Success: 0\n",
            "Episode: 41276, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3776486\n",
            "Moving Average (Training): 1325.77, Success: 0\n",
            "Episode: 41277, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3776514\n",
            "Moving Average (Training): 1315.83, Success: 0\n",
            "Episode: 41278, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3776542\n",
            "Moving Average (Training): 1305.9, Success: 0\n",
            "Episode: 41279, Total Reward: 1221.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3776657\n",
            "Moving Average (Training): 1305.93, Success: 0\n",
            "Episode: 41280, Total Reward: 2183.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 215, Step Count: 3776872\n",
            "Moving Average (Training): 1316.04, Success: 1\n",
            "Episode: 41281, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3776985\n",
            "Moving Average (Training): 1315.31, Success: 0\n",
            "Episode: 41282, Total Reward: 2179.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 206, Step Count: 3777191\n",
            "Moving Average (Training): 1324.89, Success: 1\n",
            "Episode: 41283, Total Reward: 1147.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3777295\n",
            "Moving Average (Training): 1331.49, Success: 0\n",
            "Episode: 41284, Total Reward: 1232.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3777406\n",
            "Moving Average (Training): 1332.4, Success: 0\n",
            "Episode: 41285, Total Reward: 1131.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3777519\n",
            "Moving Average (Training): 1322.06, Success: 0\n",
            "Episode: 41286, Total Reward: 1145.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3777627\n",
            "Moving Average (Training): 1326.81, Success: 0\n",
            "Episode: 41287, Total Reward: 1221.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3777740\n",
            "Moving Average (Training): 1327.3, Success: 0\n",
            "Episode: 41288, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3777941\n",
            "Moving Average (Training): 1337.54, Success: 1\n",
            "Episode: 41289, Total Reward: 1757.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 188, Step Count: 3778129\n",
            "Moving Average (Training): 1342.92, Success: 0\n",
            "Episode: 41290, Total Reward: 1295.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 135, Step Count: 3778264\n",
            "Moving Average (Training): 1344.43, Success: 0\n",
            "Episode: 41291, Total Reward: 172.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 29, Step Count: 3778293\n",
            "Moving Average (Training): 1325.18, Success: 0\n",
            "Episode: 41292, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 112, Step Count: 3778405\n",
            "Moving Average (Training): 1315.57, Success: 0\n",
            "Episode: 41293, Total Reward: 2177.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 206, Step Count: 3778611\n",
            "Moving Average (Training): 1325.62, Success: 1\n",
            "Episode: 41294, Total Reward: 1144.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3778722\n",
            "Moving Average (Training): 1325.61, Success: 0\n",
            "Episode: 41295, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 190, Step Count: 3778912\n",
            "Moving Average (Training): 1340.18, Success: 0\n",
            "Episode: 41296, Total Reward: 2088.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 200, Step Count: 3779112\n",
            "Moving Average (Training): 1356.17, Success: 0\n",
            "Episode: 41297, Total Reward: 394.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 45, Step Count: 3779157\n",
            "Moving Average (Training): 1347.75, Success: 0\n",
            "Episode: 41298, Total Reward: 2130.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3779354\n",
            "Moving Average (Training): 1347.73, Success: 0\n",
            "Episode: 41299, Total Reward: 2128.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3779547\n",
            "Moving Average (Training): 1357.77, Success: 0\n",
            "Episode: 41300, Total Reward: 1158.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3779654\n",
            "Moving Average (Training): 1367.63, Success: 0\n",
            "Episode: 41301, Total Reward: 2169.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3779858\n",
            "Moving Average (Training): 1368.01, Success: 1\n",
            "Episode: 41302, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3780062\n",
            "Moving Average (Training): 1386.08, Success: 1\n",
            "Episode: 41303, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3780175\n",
            "Moving Average (Training): 1386.55, Success: 0\n",
            "Episode: 41304, Total Reward: 1163.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 110, Step Count: 3780285\n",
            "Moving Average (Training): 1380.59, Success: 0\n",
            "Episode: 41305, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3780399\n",
            "Moving Average (Training): 1387.88, Success: 0\n",
            "Episode: 41306, Total Reward: 1147.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 104, Step Count: 3780503\n",
            "Moving Average (Training): 1380.35, Success: 0\n",
            "Episode: 41307, Total Reward: 904.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 87, Step Count: 3780590\n",
            "Moving Average (Training): 1382.39, Success: 0\n",
            "Episode: 41308, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3780704\n",
            "Moving Average (Training): 1389.75, Success: 0\n",
            "Episode: 41309, Total Reward: 1121.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3780819\n",
            "Moving Average (Training): 1397.04, Success: 0\n",
            "Episode: 41310, Total Reward: 670.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 67, Step Count: 3780886\n",
            "Moving Average (Training): 1392.1, Success: 0\n",
            "Episode: 41311, Total Reward: 967.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3780991\n",
            "Moving Average (Training): 1390.44, Success: 0\n",
            "Episode: 41312, Total Reward: 486.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3781045\n",
            "Moving Average (Training): 1384.06, Success: 0\n",
            "Episode: 41313, Total Reward: 2183.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 210, Step Count: 3781255\n",
            "Moving Average (Training): 1396.07, Success: 1\n",
            "Episode: 41314, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 29, Step Count: 3781284\n",
            "Moving Average (Training): 1376.58, Success: 0\n",
            "Episode: 41315, Total Reward: 2134.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 189, Step Count: 3781473\n",
            "Moving Average (Training): 1376.65, Success: 0\n",
            "Episode: 41316, Total Reward: 697.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 69, Step Count: 3781542\n",
            "Moving Average (Training): 1372.6, Success: 0\n",
            "Episode: 41317, Total Reward: 173.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3781570\n",
            "Moving Average (Training): 1361.99, Success: 0\n",
            "Episode: 41318, Total Reward: 1220.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3781684\n",
            "Moving Average (Training): 1372.49, Success: 0\n",
            "Episode: 41319, Total Reward: 2133.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 193, Step Count: 3781877\n",
            "Moving Average (Training): 1372.03, Success: 0\n",
            "Episode: 41320, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3781992\n",
            "Moving Average (Training): 1362.93, Success: 0\n",
            "Episode: 41321, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3782106\n",
            "Moving Average (Training): 1354.08, Success: 0\n",
            "Episode: 41322, Total Reward: 2189.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 196, Step Count: 3782302\n",
            "Moving Average (Training): 1371.12, Success: 1\n",
            "Episode: 41323, Total Reward: 2181.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3782505\n",
            "Moving Average (Training): 1381.38, Success: 1\n",
            "Episode: 41324, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3782707\n",
            "Moving Average (Training): 1391.79, Success: 1\n",
            "Episode: 41325, Total Reward: 903.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 85, Step Count: 3782792\n",
            "Moving Average (Training): 1389.51, Success: 0\n",
            "Episode: 41326, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3782820\n",
            "Moving Average (Training): 1379.84, Success: 0\n",
            "Episode: 41327, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 203, Step Count: 3783023\n",
            "Moving Average (Training): 1389.47, Success: 1\n",
            "Episode: 41328, Total Reward: 673.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 65, Step Count: 3783088\n",
            "Moving Average (Training): 1392.31, Success: 0\n",
            "Episode: 41329, Total Reward: 2168.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3783292\n",
            "Moving Average (Training): 1392.67, Success: 1\n",
            "Episode: 41330, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3783494\n",
            "Moving Average (Training): 1409.59, Success: 1\n",
            "Episode: 41331, Total Reward: 2189.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3783691\n",
            "Moving Average (Training): 1426.63, Success: 1\n",
            "Episode: 41332, Total Reward: 1891.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 178, Step Count: 3783869\n",
            "Moving Average (Training): 1424.44, Success: 0\n",
            "Episode: 41333, Total Reward: 1864.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 180, Step Count: 3784049\n",
            "Moving Average (Training): 1441.29, Success: 0\n",
            "Episode: 41334, Total Reward: 167.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 27, Step Count: 3784076\n",
            "Moving Average (Training): 1430.78, Success: 0\n",
            "Episode: 41335, Total Reward: 2187.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 202, Step Count: 3784278\n",
            "Moving Average (Training): 1447.7, Success: 1\n",
            "Episode: 41336, Total Reward: 1139.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3784391\n",
            "Moving Average (Training): 1437.83, Success: 0\n",
            "Episode: 41337, Total Reward: 470.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 54, Step Count: 3784445\n",
            "Moving Average (Training): 1437.71, Success: 0\n",
            "Episode: 41338, Total Reward: 371.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 40, Step Count: 3784485\n",
            "Moving Average (Training): 1429.7, Success: 0\n",
            "Episode: 41339, Total Reward: 2100.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 197, Step Count: 3784682\n",
            "Moving Average (Training): 1439.29, Success: 0\n",
            "Episode: 41340, Total Reward: 1156.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3784789\n",
            "Moving Average (Training): 1446.01, Success: 0\n",
            "Episode: 41341, Total Reward: 1364.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 125, Step Count: 3784914\n",
            "Moving Average (Training): 1448.2, Success: 0\n",
            "Episode: 41342, Total Reward: 177.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3784942\n",
            "Moving Average (Training): 1428.76, Success: 0\n",
            "Episode: 41343, Total Reward: 977.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 91, Step Count: 3785033\n",
            "Moving Average (Training): 1426.81, Success: 0\n",
            "Episode: 41344, Total Reward: 1129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 115, Step Count: 3785148\n",
            "Moving Average (Training): 1416.38, Success: 0\n",
            "Episode: 41345, Total Reward: 2163.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 210, Step Count: 3785358\n",
            "Moving Average (Training): 1426.56, Success: 1\n",
            "Episode: 41346, Total Reward: 1141.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 108, Step Count: 3785466\n",
            "Moving Average (Training): 1416.7, Success: 0\n",
            "Episode: 41347, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3785580\n",
            "Moving Average (Training): 1417.45, Success: 0\n",
            "Episode: 41348, Total Reward: 1222.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 118, Step Count: 3785698\n",
            "Moving Average (Training): 1407.78, Success: 0\n",
            "Episode: 41349, Total Reward: 2129.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 191, Step Count: 3785889\n",
            "Moving Average (Training): 1407.39, Success: 0\n",
            "Episode: 41350, Total Reward: 2180.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3786090\n",
            "Moving Average (Training): 1408.21, Success: 1\n",
            "Episode: 41351, Total Reward: 2188.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 204, Step Count: 3786294\n",
            "Moving Average (Training): 1408.21, Success: 1\n",
            "Episode: 41352, Total Reward: 2175.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 211, Step Count: 3786505\n",
            "Moving Average (Training): 1408.15, Success: 1\n",
            "Episode: 41353, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3786619\n",
            "Moving Average (Training): 1408.87, Success: 0\n",
            "Episode: 41354, Total Reward: 470.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 55, Step Count: 3786674\n",
            "Moving Average (Training): 1402.11, Success: 0\n",
            "Episode: 41355, Total Reward: 479.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 58, Step Count: 3786732\n",
            "Moving Average (Training): 1394.54, Success: 0\n",
            "Episode: 41356, Total Reward: 178.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 28, Step Count: 3786760\n",
            "Moving Average (Training): 1384.86, Success: 0\n",
            "Episode: 41357, Total Reward: 481.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 69, Step Count: 3786829\n",
            "Moving Average (Training): 1384.81, Success: 0\n",
            "Episode: 41358, Total Reward: 1896.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 177, Step Count: 3787006\n",
            "Moving Average (Training): 1398.97, Success: 0\n",
            "Episode: 41359, Total Reward: 1218.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3787119\n",
            "Moving Average (Training): 1389.27, Success: 0\n",
            "Episode: 41360, Total Reward: 1165.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 105, Step Count: 3787224\n",
            "Moving Average (Training): 1379.05, Success: 0\n",
            "Episode: 41361, Total Reward: 1219.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 114, Step Count: 3787338\n",
            "Moving Average (Training): 1379.05, Success: 0\n",
            "Episode: 41362, Total Reward: 1223.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 113, Step Count: 3787451\n",
            "Moving Average (Training): 1370.0, Success: 0\n",
            "Episode: 41363, Total Reward: 1236.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3787562\n",
            "Moving Average (Training): 1361.06, Success: 0\n",
            "Episode: 41364, Total Reward: 1236.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 111, Step Count: 3787673\n",
            "Moving Average (Training): 1351.61, Success: 0\n",
            "Episode: 41365, Total Reward: 1136.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3787782\n",
            "Moving Average (Training): 1341.15, Success: 0\n",
            "Episode: 41366, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 107, Step Count: 3787889\n",
            "Moving Average (Training): 1330.92, Success: 0\n",
            "Episode: 41367, Total Reward: 2106.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 196, Step Count: 3788085\n",
            "Moving Average (Training): 1330.3, Success: 0\n",
            "Episode: 41368, Total Reward: 1146.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 109, Step Count: 3788194\n",
            "Moving Average (Training): 1320.04, Success: 0\n",
            "Episode: 41369, Total Reward: 978.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 102, Step Count: 3788296\n",
            "Moving Average (Training): 1308.03, Success: 0\n",
            "Episode: 41370, Total Reward: 1164.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 106, Step Count: 3788402\n",
            "Moving Average (Training): 1308.2, Success: 0\n",
            "Episode: 41371, Total Reward: 2174.0, Epsilon: 0.02\n",
            "Replay Buffer Memory: 300000, Episode Length: 201, Step Count: 3788603\n",
            "Moving Average (Training): 1308.74, Success: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-322361dea0d3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# Tensor conversion for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for episode in range(start_episode, num_episodes):\n",
        "    # --- Training loop ---\n",
        "    state, _ = env.reset()\n",
        "    state = preprocess_state(state)\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    frame_count = 0\n",
        "    episode_length = 0\n",
        "    x_pos_last = 40\n",
        "    time_last = 400\n",
        "    #standing_still_counter = 0\n",
        "\n",
        "    while not done:\n",
        "        action = select_action(state, epsilon)\n",
        "        if episode > start_learning:\n",
        "            epsilon = max(epsilon * epsilon_decay, epsilon_min)\n",
        "\n",
        "        next_state, reward, terminated, truncated, next_info = env.step(action)\n",
        "        next_state = preprocess_state(next_state)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        total_reward += reward\n",
        "\n",
        "        replayBuffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "        if len(replayBuffer) > batch_size and episode > start_learning:\n",
        "            batch = random.sample(replayBuffer, batch_size)\n",
        "            states, actions, rewards, next_states, dones = zip(*batch)\n",
        "\n",
        "            # Tensor conversion for training\n",
        "            states = torch.cat(states)\n",
        "            actions = torch.tensor(actions, dtype=torch.int64).to(device)\n",
        "            rewards = torch.tensor(rewards).to(device)\n",
        "            next_states = torch.cat(next_states)\n",
        "            dones = torch.tensor(dones, dtype=torch.float32).to(device)\n",
        "\n",
        "            # Compute Q-values and loss\n",
        "            current_q_values = policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
        "            next_state_actions = policy_net(next_states).argmax(dim=1)\n",
        "            next_q_values = target_net(next_states).gather(1, next_state_actions.unsqueeze(1)).squeeze(1)\n",
        "            expected_q_values = rewards + gamma * next_q_values * (1 - dones)\n",
        "\n",
        "            loss = loss_fn(current_q_values, expected_q_values.detach())\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        step_count += 1\n",
        "        episode_length += 1\n",
        "\n",
        "\n",
        "        if done:\n",
        "            # Save training rewards and calculate moving averages\n",
        "            training_rewards.append(total_reward)\n",
        "            moving_average_training.append(np.mean(training_rewards[-100:]))\n",
        "            min_training_rewards.append(np.min(training_rewards[-100:]))\n",
        "            max_training_rewards.append(np.max(training_rewards[-100:]))\n",
        "            min_moving_average_training.append(np.min(moving_average_training[-100:]))\n",
        "            max_moving_average_training.append(np.max(moving_average_training[-100:]))\n",
        "\n",
        "            # Check if Mario completed the level\n",
        "            if next_info['flag_get']:\n",
        "                success = 1  # Mario successfully completed the level\n",
        "            else:\n",
        "                success = 0  # Mario did not complete the level\n",
        "\n",
        "            # Output information about the episode\n",
        "            print(f\"Episode: {episode}, Total Reward: {total_reward}, Epsilon: {epsilon}\")\n",
        "            print(f\"Replay Buffer Memory: {len(replayBuffer)}, Episode Length: {episode_length}, Step Count: {step_count}\")\n",
        "            print(f\"Moving Average (Training): {moving_average_training[-1]}, Success: {success}\")\n",
        "\n",
        "            # Write episode data to log file\n",
        "            with open(file_path, 'a') as file:\n",
        "                file.write(f\"{episode},{total_reward},{moving_average_training[-1]},{episode_length},{step_count},{success}\\n\")\n",
        "\n",
        "    if step_count % 7500 == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "      # --- Save model weights ---\n",
        "    if episode % save_weights == 0:\n",
        "        policy_weight_filename = f'policy_net_weights_{episode}.pth'\n",
        "        target_weight_filename = f'target_net_weights_{episode}.pth'\n",
        "        torch.save(policy_net.state_dict(), policy_weight_filename)\n",
        "        torch.save(target_net.state_dict(), target_weight_filename)\n",
        "\n",
        "# Save weights after training\n",
        "torch.save(policy_net.state_dict(), 'policy_net_weights.pth')\n",
        "torch.save(target_net.state_dict(), 'target_net_weights.pth')\n",
        "\n",
        "files.download('policy_net_weights.pth')\n",
        "files.download('target_net_weights.pth')\n",
        "\n",
        "# Save rewards and moving averages to files for later analysis\n",
        "np.save('training_rewards.npy', training_rewards)\n",
        "#np.save('evaluation_rewards.npy', evaluation_rewards)\n",
        "np.save('moving_average_training.npy', moving_average_training)\n",
        "#np.save('moving_average_evaluation.npy', moving_average_evaluation)\n",
        "\n",
        "files.download('training_rewards.npy')\n",
        "files.download('moving_average_training.npy')\n",
        "\n",
        "# Plotting Moving Averages with min and max\n",
        "episodes = range(len(moving_average_training))\n",
        "\n",
        "# Plot the result\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot smoothed Training Moving Average with sliding min and max\n",
        "plt.plot(episodes, moving_average_training, 'b-', label='Avg (Last 100 Episodes)', linewidth=2)\n",
        "plt.plot(episodes, min_moving_average_training, 'r-', linewidth=1.5, label='Min (Last 100 episodes)')\n",
        "plt.plot(episodes, max_moving_average_training, 'g-', linewidth=1.5, label='Max (Last 100 episodes)')\n",
        "\n",
        "# Fill the area between min and max with lighter transparency\n",
        "plt.fill_between(episodes, min_moving_average_training, max_moving_average_training, facecolor='blue', alpha=0.07)\n",
        "\n",
        "# Titles and labels\n",
        "plt.title('Dueling DQN Moving Average Rewards (Training)')\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylabel('Reward Value')\n",
        "plt.legend(loc='upper left')\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "plt.show()\n",
        "\n",
        "env.close()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}